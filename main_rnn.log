2017-10-09 02:45:26,574: INFO: Summary name Run Information is illegal; using Run_Information instead.
2017-10-09 02:45:26,577: INFO: n_epochs: 1
2017-10-09 02:45:26,577: INFO: n_hidden: 16
2017-10-09 02:45:26,577: INFO: batch_size: 5
2017-10-09 02:45:26,577: INFO: dropout_enabled: False
2017-10-09 02:45:26,578: INFO: multi_layers_enabled: False
2017-10-09 02:45:26,578: INFO: n_layers: 1
2017-10-09 02:45:26,578: INFO: exp_decay_enabled: False
2017-10-09 02:45:26,578: INFO: reg_enabled: False

2017-10-09 02:45:28,706: INFO: The training shall begin.
2017-10-09 02:45:28,707: DEBUG: Step 0
2017-10-09 02:45:32,234: INFO: Iter: 0, Loss: 2.034, Accuracy: 0.000, Learning Rate: 0.001
2017-10-09 02:45:32,628: DEBUG: Step 1
2017-10-09 02:45:35,963: INFO: Iter: 5, Loss: 1.728, Accuracy: 0.200, Learning Rate: 0.001
2017-10-09 02:45:36,343: DEBUG: Step 2
2017-10-09 02:45:39,673: INFO: Iter: 10, Loss: 1.263, Accuracy: 0.400, Learning Rate: 0.001
2017-10-09 02:45:40,292: INFO: The training is done.
2017-10-09 02:45:49,792: INFO: n_epochs: 1
2017-10-09 02:45:49,792: INFO: n_hidden: 16
2017-10-09 02:45:49,792: INFO: batch_size: 5
2017-10-09 02:45:49,792: INFO: dropout_enabled: False
2017-10-09 02:45:49,793: INFO: multi_layers_enabled: False
2017-10-09 02:45:49,793: INFO: n_layers: 1
2017-10-09 02:45:49,793: INFO: exp_decay_enabled: False
2017-10-09 02:45:49,793: INFO: reg_enabled: False

2017-10-09 02:45:51,854: INFO: The training shall begin.
2017-10-09 02:45:51,855: DEBUG: Step 0
2017-10-09 02:45:55,270: INFO: Iter: 0, Loss: 1.080, Accuracy: 0.400, Learning Rate: 0.001
2017-10-09 02:45:55,639: DEBUG: Step 1
2017-10-09 02:45:59,043: INFO: Iter: 5, Loss: 1.473, Accuracy: 0.000, Learning Rate: 0.001
2017-10-09 02:45:59,397: DEBUG: Step 2
2017-10-09 02:46:02,634: INFO: Iter: 10, Loss: 1.106, Accuracy: 0.600, Learning Rate: 0.001
2017-10-09 02:46:02,974: INFO: The training is done.
2017-10-09 02:46:40,546: INFO: n_epochs: 1
2017-10-09 02:46:40,547: INFO: n_hidden: 16
2017-10-09 02:46:40,547: INFO: batch_size: 5
2017-10-09 02:46:40,547: INFO: dropout_enabled: False
2017-10-09 02:46:40,548: INFO: multi_layers_enabled: False
2017-10-09 02:46:40,548: INFO: n_layers: 1
2017-10-09 02:46:40,548: INFO: exp_decay_enabled: False
2017-10-09 02:46:40,548: INFO: reg_enabled: False

2017-10-09 02:46:42,778: INFO: The training shall begin.
2017-10-09 02:46:42,778: DEBUG: Step 0
2017-10-09 02:46:45,845: INFO: Iter: 0, Loss: 1.816, Accuracy: 0.000, Learning Rate: 0.001
2017-10-09 02:46:46,311: DEBUG: Step 1
2017-10-09 02:46:48,758: INFO: Iter: 5, Loss: 1.153, Accuracy: 0.400, Learning Rate: 0.001
2017-10-09 02:46:49,248: DEBUG: Step 2
2017-10-09 02:46:52,224: INFO: Iter: 10, Loss: 1.290, Accuracy: 0.200, Learning Rate: 0.001
2017-10-09 02:46:52,603: INFO: The training is done.
2017-10-10 00:36:21,674: INFO: n_epochs: 1
2017-10-10 00:36:21,675: INFO: n_hidden: 16
2017-10-10 00:36:21,676: INFO: batch_size: 5
2017-10-10 00:36:21,676: INFO: dropout_enabled: False
2017-10-10 00:36:21,677: INFO: multi_layers_enabled: False
2017-10-10 00:36:21,677: INFO: n_layers: 1
2017-10-10 00:36:21,677: INFO: exp_decay_enabled: False
2017-10-10 00:36:21,678: INFO: reg_enabled: False

2017-10-10 00:36:23,924: INFO: The training shall begin.
2017-10-10 00:36:23,924: DEBUG: Step 0
2017-10-10 00:36:27,152: INFO: Iter: 0, Loss: 1.175, Accuracy: 0.200, Learning Rate: 0.001
2017-10-10 00:36:27,520: DEBUG: Step 1
2017-10-10 00:36:30,882: INFO: Iter: 5, Loss: 1.252, Accuracy: 0.000, Learning Rate: 0.001
2017-10-10 00:36:31,233: INFO: The training is done.
2017-10-10 00:39:06,567: INFO: n_epochs: 1
2017-10-10 00:39:06,568: INFO: n_hidden: 16
2017-10-10 00:39:06,568: INFO: batch_size: 5
2017-10-10 00:39:06,568: INFO: dropout_enabled: False
2017-10-10 00:39:06,569: INFO: multi_layers_enabled: False
2017-10-10 00:39:06,569: INFO: n_layers: 1
2017-10-10 00:39:06,569: INFO: exp_decay_enabled: False
2017-10-10 00:39:06,569: INFO: reg_enabled: False

2017-10-10 00:39:08,680: INFO: The training shall begin.
2017-10-10 00:39:08,680: DEBUG: Step 0
2017-10-10 00:39:11,897: INFO: Iter: 0, Loss: 1.617, Accuracy: 0.200, Learning Rate: 0.001
2017-10-10 00:39:12,191: DEBUG: Step 1
2017-10-10 00:39:15,270: INFO: Iter: 5, Loss: 1.250, Accuracy: 0.400, Learning Rate: 0.001
2017-10-10 00:39:15,640: INFO: The training is done.
2017-10-10 00:43:11,344: INFO: n_epochs: 1
2017-10-10 00:43:11,345: INFO: n_hidden: 16
2017-10-10 00:43:11,345: INFO: batch_size: 5
2017-10-10 00:43:11,345: INFO: dropout_enabled: False
2017-10-10 00:43:11,346: INFO: multi_layers_enabled: False
2017-10-10 00:43:11,346: INFO: n_layers: 1
2017-10-10 00:43:11,346: INFO: exp_decay_enabled: False
2017-10-10 00:43:11,346: INFO: reg_enabled: False

2017-10-10 00:43:13,411: INFO: The training shall begin.
2017-10-10 00:43:13,412: DEBUG: Step 0
2017-10-10 00:43:16,875: INFO: Iter: 0, Loss: 1.107, Accuracy: 0.600, Learning Rate: 0.001
2017-10-10 00:43:17,260: DEBUG: Step 1
2017-10-10 00:43:20,453: INFO: Iter: 5, Loss: 1.138, Accuracy: 0.200, Learning Rate: 0.001
2017-10-10 00:43:20,819: INFO: The training is done.
2017-10-10 00:43:23,370: INFO: n_epochs: 1
2017-10-10 00:43:23,370: INFO: n_hidden: 16
2017-10-10 00:43:23,370: INFO: batch_size: 5
2017-10-10 00:43:23,371: INFO: dropout_enabled: True
2017-10-10 00:43:23,371: INFO: multi_layers_enabled: False
2017-10-10 00:43:23,371: INFO: n_layers: 1
2017-10-10 00:43:23,371: INFO: exp_decay_enabled: False
2017-10-10 00:43:23,371: INFO: reg_enabled: False

2017-10-10 00:43:25,797: INFO: The training shall begin.
2017-10-10 00:43:25,797: DEBUG: Step 0
2017-10-10 00:43:30,475: INFO: Iter: 0, Loss: 1.080, Accuracy: 0.400, Learning Rate: 0.001
2017-10-10 00:43:31,084: DEBUG: Step 1
2017-10-10 00:43:35,752: INFO: Iter: 5, Loss: 1.109, Accuracy: 0.400, Learning Rate: 0.001
2017-10-10 00:43:36,384: INFO: The training is done.
2017-10-10 00:43:37,658: INFO: n_epochs: 1
2017-10-10 00:43:37,658: INFO: n_hidden: 16
2017-10-10 00:43:37,659: INFO: batch_size: 5
2017-10-10 00:43:37,659: INFO: dropout_enabled: True
2017-10-10 00:43:37,659: INFO: multi_layers_enabled: False
2017-10-10 00:43:37,659: INFO: n_layers: 1
2017-10-10 00:43:37,659: INFO: exp_decay_enabled: False
2017-10-10 00:43:37,659: INFO: reg_enabled: True

2017-10-10 00:43:40,205: INFO: The training shall begin.
2017-10-10 00:43:40,206: DEBUG: Step 0
2017-10-10 00:43:45,714: INFO: Iter: 0, Loss: 1.196, Accuracy: 0.400, Learning Rate: 0.001
2017-10-10 00:43:46,642: DEBUG: Step 1
2017-10-10 00:43:51,950: INFO: Iter: 5, Loss: 0.737, Accuracy: 0.800, Learning Rate: 0.001
2017-10-10 00:43:52,590: INFO: The training is done.
2017-10-10 00:43:54,525: INFO: n_epochs: 2
2017-10-10 00:43:54,525: INFO: n_hidden: 16
2017-10-10 00:43:54,526: INFO: batch_size: 5
2017-10-10 00:43:54,526: INFO: dropout_enabled: True
2017-10-10 00:43:54,526: INFO: multi_layers_enabled: False
2017-10-10 00:43:54,527: INFO: n_layers: 1
2017-10-10 00:43:54,528: INFO: exp_decay_enabled: False
2017-10-10 00:43:54,529: INFO: reg_enabled: True

2017-10-10 00:43:56,966: INFO: The training shall begin.
2017-10-10 00:43:56,966: DEBUG: Step 0
2017-10-10 00:44:01,973: INFO: Iter: 0, Loss: 1.507, Accuracy: 0.200, Learning Rate: 0.001
2017-10-10 00:44:02,565: DEBUG: Step 1
2017-10-10 00:44:07,804: INFO: Iter: 5, Loss: 1.856, Accuracy: 0.000, Learning Rate: 0.001
2017-10-10 00:44:08,433: INFO: The training is done.
2017-10-10 01:02:08,061: INFO: filename: trained_model_2017.10.10-01.02.07
2017-10-10 01:02:08,062: INFO: n_epochs: 1
2017-10-10 01:02:08,062: INFO: n_hidden: 16
2017-10-10 01:02:08,062: INFO: batch_size: 5
2017-10-10 01:02:08,063: INFO: dropout_enabled: False
2017-10-10 01:02:08,063: INFO: multi_layers_enabled: False
2017-10-10 01:02:08,063: INFO: n_layers: 1
2017-10-10 01:02:08,064: INFO: exp_decay_enabled: False
2017-10-10 01:02:08,064: INFO: reg_enabled: False

2017-10-10 01:02:10,078: INFO: The training shall begin.
2017-10-10 01:02:10,078: DEBUG: Step 0
2017-10-10 01:02:13,401: INFO: Iter: 0, Loss: 1.029, Accuracy: 0.600, Learning Rate: 0.001
2017-10-10 01:02:13,825: DEBUG: Step 1
2017-10-10 01:02:16,918: INFO: Iter: 5, Loss: 1.381, Accuracy: 0.200, Learning Rate: 0.001
2017-10-10 01:02:17,267: INFO: The training is done.
2017-10-10 01:02:20,062: INFO: filename: trained_model_2017.10.10-01.02.19
2017-10-10 01:02:20,062: INFO: n_epochs: 1
2017-10-10 01:02:20,063: INFO: n_hidden: 16
2017-10-10 01:02:20,063: INFO: batch_size: 5
2017-10-10 01:02:20,063: INFO: dropout_enabled: True
2017-10-10 01:02:20,063: INFO: multi_layers_enabled: False
2017-10-10 01:02:20,064: INFO: n_layers: 1
2017-10-10 01:02:20,064: INFO: exp_decay_enabled: False
2017-10-10 01:02:20,064: INFO: reg_enabled: False

2017-10-10 01:02:22,360: INFO: The training shall begin.
2017-10-10 01:02:22,361: DEBUG: Step 0
2017-10-10 01:02:27,094: INFO: Iter: 0, Loss: 0.894, Accuracy: 0.400, Learning Rate: 0.001
2017-10-10 01:02:27,737: DEBUG: Step 1
2017-10-10 01:02:32,555: INFO: Iter: 5, Loss: 1.285, Accuracy: 0.200, Learning Rate: 0.001
2017-10-10 01:02:33,249: INFO: The training is done.
2017-10-10 01:02:34,843: INFO: filename: trained_model_2017.10.10-01.02.34
2017-10-10 01:02:34,843: INFO: n_epochs: 1
2017-10-10 01:02:34,843: INFO: n_hidden: 16
2017-10-10 01:02:34,843: INFO: batch_size: 5
2017-10-10 01:02:34,844: INFO: dropout_enabled: True
2017-10-10 01:02:34,844: INFO: multi_layers_enabled: False
2017-10-10 01:02:34,844: INFO: n_layers: 1
2017-10-10 01:02:34,844: INFO: exp_decay_enabled: False
2017-10-10 01:02:34,844: INFO: reg_enabled: True

2017-10-10 01:02:37,377: INFO: The training shall begin.
2017-10-10 01:02:37,377: DEBUG: Step 0
2017-10-10 01:02:43,047: INFO: Iter: 0, Loss: 0.787, Accuracy: 1.000, Learning Rate: 0.001
2017-10-10 01:02:43,720: DEBUG: Step 1
2017-10-10 01:02:49,289: INFO: Iter: 5, Loss: 1.458, Accuracy: 0.400, Learning Rate: 0.001
2017-10-10 01:02:49,909: INFO: The training is done.
2017-10-10 01:02:51,486: INFO: filename: trained_model_2017.10.10-01.02.51
2017-10-10 01:02:51,487: INFO: n_epochs: 2
2017-10-10 01:02:51,487: INFO: n_hidden: 16
2017-10-10 01:02:51,487: INFO: batch_size: 5
2017-10-10 01:02:51,487: INFO: dropout_enabled: True
2017-10-10 01:02:51,487: INFO: multi_layers_enabled: False
2017-10-10 01:02:51,487: INFO: n_layers: 1
2017-10-10 01:02:51,487: INFO: exp_decay_enabled: False
2017-10-10 01:02:51,488: INFO: reg_enabled: True

2017-10-10 01:02:54,462: INFO: The training shall begin.
2017-10-10 01:02:54,463: DEBUG: Step 0
2017-10-10 01:03:00,160: INFO: Iter: 0, Loss: 1.173, Accuracy: 0.200, Learning Rate: 0.001
2017-10-10 01:03:00,837: DEBUG: Step 1
2017-10-10 01:03:06,073: INFO: Iter: 5, Loss: 1.230, Accuracy: 0.000, Learning Rate: 0.001
2017-10-10 01:03:06,632: INFO: The training is done.
2017-10-14 13:37:37,754: INFO: *** NEW RUN ***
2017-10-14 13:37:37,754: INFO: filename: trained_model_2017.10.14-13.37.37
2017-10-14 13:37:37,755: INFO: n_epochs: 1
2017-10-14 13:37:37,755: INFO: n_hidden: 16
2017-10-14 13:37:37,755: INFO: batch_size: 5
2017-10-14 13:37:37,755: INFO: dropout_enabled: False
2017-10-14 13:37:37,755: INFO: multi_layers_enabled: False
2017-10-14 13:37:37,756: INFO: n_layers: 1
2017-10-14 13:37:37,756: INFO: exp_decay_enabled: False
2017-10-14 13:37:37,756: INFO: reg_enabled: False

2017-10-14 13:37:39,736: INFO: The training shall begin.
2017-10-14 13:37:39,736: DEBUG: Step 0
2017-10-14 13:37:43,269: INFO: Iter: 0, Loss: 1.198, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 13:37:43,645: DEBUG: Step 1
2017-10-14 13:37:45,764: DEBUG: Step 2
2017-10-14 13:37:47,953: DEBUG: Step 3
2017-10-14 13:37:50,179: DEBUG: Step 4
2017-10-14 13:37:52,420: DEBUG: Step 5
2017-10-14 13:37:54,621: DEBUG: Step 6
2017-10-14 13:37:56,777: DEBUG: Step 7
2017-10-14 13:37:58,981: DEBUG: Step 8
2017-10-14 13:38:01,004: DEBUG: Step 9
2017-10-14 13:38:03,194: DEBUG: Step 10
2017-10-14 13:38:06,554: INFO: Iter: 50, Loss: 1.102, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 13:38:06,918: DEBUG: Step 11
2017-10-14 13:38:08,769: INFO: Keyboard Interrupt? Gracefully quitting
2017-10-14 13:38:08,769: INFO: The training is done.

2017-10-14 13:38:11,511: INFO: *** NEW RUN ***
2017-10-14 13:38:11,511: INFO: filename: trained_model_2017.10.14-13.38.11
2017-10-14 13:38:11,512: INFO: n_epochs: 1
2017-10-14 13:38:11,512: INFO: n_hidden: 16
2017-10-14 13:38:11,512: INFO: batch_size: 5
2017-10-14 13:38:11,512: INFO: dropout_enabled: True
2017-10-14 13:38:11,513: INFO: multi_layers_enabled: False
2017-10-14 13:38:11,513: INFO: n_layers: 1
2017-10-14 13:38:11,513: INFO: exp_decay_enabled: False
2017-10-14 13:38:11,513: INFO: reg_enabled: False

2017-10-14 13:38:13,642: INFO: The training shall begin.
2017-10-14 13:38:13,643: DEBUG: Step 0
2017-10-14 13:38:16,936: INFO: Keyboard Interrupt? Gracefully quitting
2017-10-14 13:38:16,936: INFO: The training is done.

2017-10-14 13:38:18,251: INFO: *** NEW RUN ***
2017-10-14 13:38:18,251: INFO: filename: trained_model_2017.10.14-13.38.18
2017-10-14 13:38:18,251: INFO: n_epochs: 1
2017-10-14 13:38:18,252: INFO: n_hidden: 16
2017-10-14 13:38:18,252: INFO: batch_size: 5
2017-10-14 13:38:18,252: INFO: dropout_enabled: True
2017-10-14 13:38:18,252: INFO: multi_layers_enabled: False
2017-10-14 13:38:18,252: INFO: n_layers: 1
2017-10-14 13:38:18,253: INFO: exp_decay_enabled: False
2017-10-14 13:38:18,253: INFO: reg_enabled: True

2017-10-14 13:38:20,600: INFO: The training shall begin.
2017-10-14 13:38:20,600: DEBUG: Step 0
2017-10-14 13:38:26,582: INFO: Iter: 0, Loss: 1.261, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 13:38:27,413: DEBUG: Step 1
2017-10-14 13:38:31,100: DEBUG: Step 2
2017-10-14 13:38:34,585: DEBUG: Step 3
2017-10-14 13:38:38,084: DEBUG: Step 4
2017-10-14 13:38:41,621: DEBUG: Step 5
2017-10-14 13:38:45,149: DEBUG: Step 6
2017-10-14 13:38:48,691: DEBUG: Step 7
2017-10-14 13:38:52,181: DEBUG: Step 8
2017-10-14 13:38:55,735: DEBUG: Step 9
2017-10-14 13:38:59,182: DEBUG: Step 10
2017-10-14 13:39:02,074: INFO: The training is done.

2017-10-14 14:00:36,209: INFO: *** NEW RUN ***
2017-10-14 14:00:36,209: INFO: filename: trained_model_2017.10.14-14.00.36
2017-10-14 14:00:36,209: INFO: n_epochs: 1
2017-10-14 14:00:36,210: INFO: n_hidden: 16
2017-10-14 14:00:36,210: INFO: batch_size: 5
2017-10-14 14:00:36,210: INFO: dropout_enabled: False
2017-10-14 14:00:36,210: INFO: multi_layers_enabled: False
2017-10-14 14:00:36,211: INFO: n_layers: 1
2017-10-14 14:00:36,211: INFO: exp_decay_enabled: False
2017-10-14 14:00:36,211: INFO: reg_enabled: False

2017-10-14 14:00:38,260: INFO: The training shall begin.
2017-10-14 14:00:41,956: INFO: Iter: 0, Loss: 1.218, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:01:04,880: INFO: Iter: 50, Loss: 1.141, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:01:29,588: INFO: Iter: 100, Loss: 0.952, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:01:29,970: INFO: Cycled through epochs 1 times
2017-10-14 14:01:29,970: INFO: The training is done.

2017-10-14 14:01:32,641: INFO: *** NEW RUN ***
2017-10-14 14:01:32,641: INFO: filename: trained_model_2017.10.14-14.01.32
2017-10-14 14:01:32,641: INFO: n_epochs: 1
2017-10-14 14:01:32,641: INFO: n_hidden: 16
2017-10-14 14:01:32,641: INFO: batch_size: 5
2017-10-14 14:01:32,642: INFO: dropout_enabled: True
2017-10-14 14:01:32,642: INFO: multi_layers_enabled: False
2017-10-14 14:01:32,642: INFO: n_layers: 1
2017-10-14 14:01:32,642: INFO: exp_decay_enabled: False
2017-10-14 14:01:32,642: INFO: reg_enabled: False

2017-10-14 14:01:34,923: INFO: The training shall begin.
2017-10-14 14:01:40,075: INFO: Iter: 0, Loss: 1.141, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:02:15,954: INFO: Iter: 50, Loss: 1.272, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:02:32,258: INFO: Keyboard Interrupt? Gracefully quitting
2017-10-14 14:02:32,259: INFO: The training is done.

2017-10-14 14:02:33,641: INFO: *** NEW RUN ***
2017-10-14 14:02:33,641: INFO: filename: trained_model_2017.10.14-14.02.33
2017-10-14 14:02:33,641: INFO: n_epochs: 1
2017-10-14 14:02:33,641: INFO: n_hidden: 16
2017-10-14 14:02:33,642: INFO: batch_size: 5
2017-10-14 14:02:33,642: INFO: dropout_enabled: True
2017-10-14 14:02:33,642: INFO: multi_layers_enabled: False
2017-10-14 14:02:33,642: INFO: n_layers: 1
2017-10-14 14:02:33,643: INFO: exp_decay_enabled: False
2017-10-14 14:02:33,643: INFO: reg_enabled: True

2017-10-14 14:02:36,034: INFO: The training shall begin.
2017-10-14 14:02:41,115: INFO: Iter: 0, Loss: 1.021, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:03:17,764: INFO: Iter: 50, Loss: 0.986, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:03:38,904: INFO: Keyboard Interrupt? Gracefully quitting
2017-10-14 14:03:38,904: INFO: The training is done.

2017-10-14 14:03:40,203: INFO: *** NEW RUN ***
2017-10-14 14:03:40,203: INFO: filename: trained_model_2017.10.14-14.03.40
2017-10-14 14:03:40,203: INFO: n_epochs: 2
2017-10-14 14:03:40,203: INFO: n_hidden: 16
2017-10-14 14:03:40,203: INFO: batch_size: 5
2017-10-14 14:03:40,203: INFO: dropout_enabled: True
2017-10-14 14:03:40,204: INFO: multi_layers_enabled: False
2017-10-14 14:03:40,204: INFO: n_layers: 1
2017-10-14 14:03:40,204: INFO: exp_decay_enabled: False
2017-10-14 14:03:40,204: INFO: reg_enabled: True

2017-10-14 14:03:42,521: INFO: The training shall begin.
2017-10-14 14:03:45,545: INFO: Keyboard Interrupt? Gracefully quitting
2017-10-14 14:03:45,545: INFO: The training is done.

2017-10-14 14:03:51,324: INFO: *** NEW RUN ***
2017-10-14 14:03:51,325: INFO: filename: trained_model_2017.10.14-14.03.51
2017-10-14 14:03:51,325: INFO: n_epochs: 1
2017-10-14 14:03:51,325: INFO: n_hidden: 16
2017-10-14 14:03:51,325: INFO: batch_size: 5
2017-10-14 14:03:51,325: INFO: dropout_enabled: False
2017-10-14 14:03:51,326: INFO: multi_layers_enabled: False
2017-10-14 14:03:51,326: INFO: n_layers: 1
2017-10-14 14:03:51,326: INFO: exp_decay_enabled: False
2017-10-14 14:03:51,326: INFO: reg_enabled: False

2017-10-14 14:03:53,356: INFO: The training shall begin.
2017-10-14 14:03:57,203: INFO: Iter: 0, Loss: 1.560, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 14:04:21,631: INFO: Iter: 50, Loss: 0.787, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 14:04:47,224: INFO: Iter: 100, Loss: 0.802, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 14:04:47,587: INFO: Cycled through epochs 1 times
2017-10-14 14:04:47,588: INFO: The training is done.

2017-10-14 14:04:51,278: INFO: *** NEW RUN ***
2017-10-14 14:04:51,278: INFO: filename: trained_model_2017.10.14-14.04.50
2017-10-14 14:04:51,278: INFO: n_epochs: 1
2017-10-14 14:04:51,279: INFO: n_hidden: 16
2017-10-14 14:04:51,279: INFO: batch_size: 5
2017-10-14 14:04:51,279: INFO: dropout_enabled: True
2017-10-14 14:04:51,279: INFO: multi_layers_enabled: False
2017-10-14 14:04:51,279: INFO: n_layers: 1
2017-10-14 14:04:51,279: INFO: exp_decay_enabled: False
2017-10-14 14:04:51,279: INFO: reg_enabled: False

2017-10-14 14:04:54,201: INFO: The training shall begin.
2017-10-14 14:05:01,959: INFO: Iter: 0, Loss: 1.082, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:05:37,980: INFO: Iter: 50, Loss: 1.119, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:06:13,647: INFO: Iter: 100, Loss: 1.092, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:06:14,198: INFO: Cycled through epochs 1 times
2017-10-14 14:06:14,198: INFO: The training is done.

2017-10-14 14:06:15,663: INFO: *** NEW RUN ***
2017-10-14 14:06:15,663: INFO: filename: trained_model_2017.10.14-14.06.15
2017-10-14 14:06:15,664: INFO: n_epochs: 1
2017-10-14 14:06:15,664: INFO: n_hidden: 16
2017-10-14 14:06:15,664: INFO: batch_size: 5
2017-10-14 14:06:15,664: INFO: dropout_enabled: True
2017-10-14 14:06:15,664: INFO: multi_layers_enabled: False
2017-10-14 14:06:15,664: INFO: n_layers: 1
2017-10-14 14:06:15,665: INFO: exp_decay_enabled: False
2017-10-14 14:06:15,665: INFO: reg_enabled: True

2017-10-14 14:06:18,401: INFO: The training shall begin.
2017-10-14 14:06:24,286: INFO: Iter: 0, Loss: 0.951, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:07:03,115: INFO: Iter: 50, Loss: 0.875, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:07:41,878: INFO: Iter: 100, Loss: 1.121, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:07:42,483: INFO: Cycled through epochs 1 times
2017-10-14 14:07:42,483: INFO: The training is done.

2017-10-14 14:07:43,864: INFO: *** NEW RUN ***
2017-10-14 14:07:43,864: INFO: filename: trained_model_2017.10.14-14.07.43
2017-10-14 14:07:43,865: INFO: n_epochs: 2
2017-10-14 14:07:43,865: INFO: n_hidden: 16
2017-10-14 14:07:43,865: INFO: batch_size: 5
2017-10-14 14:07:43,865: INFO: dropout_enabled: True
2017-10-14 14:07:43,866: INFO: multi_layers_enabled: False
2017-10-14 14:07:43,866: INFO: n_layers: 1
2017-10-14 14:07:43,866: INFO: exp_decay_enabled: False
2017-10-14 14:07:43,866: INFO: reg_enabled: True

2017-10-14 14:07:46,455: INFO: The training shall begin.
2017-10-14 14:07:51,622: INFO: Iter: 0, Loss: 1.501, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 14:08:13,861: INFO: Keyboard Interrupt? Gracefully quitting
2017-10-14 14:08:13,861: INFO: The training is done.

2017-10-14 14:10:15,419: INFO: *** NEW RUN ***
2017-10-14 14:10:15,419: INFO: filename: trained_model_2017.10.14-14.10.15
2017-10-14 14:10:15,420: INFO: n_epochs: 2500
2017-10-14 14:10:15,420: INFO: n_hidden: 16
2017-10-14 14:10:15,420: INFO: batch_size: 5
2017-10-14 14:10:15,420: INFO: dropout_enabled: False
2017-10-14 14:10:15,420: INFO: multi_layers_enabled: False
2017-10-14 14:10:15,421: INFO: n_layers: 1
2017-10-14 14:10:15,421: INFO: exp_decay_enabled: False
2017-10-14 14:10:15,421: INFO: reg_enabled: False

2017-10-14 14:10:18,532: INFO: The training shall begin.
2017-10-14 14:10:22,297: INFO: Iter: 0, Loss: 1.295, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:10:46,940: INFO: Iter: 50, Loss: 1.105, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:11:11,692: INFO: Iter: 100, Loss: 1.054, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:11:35,751: INFO: Iter: 150, Loss: 1.563, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 14:11:59,883: INFO: Iter: 200, Loss: 1.210, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 14:12:24,357: INFO: Iter: 250, Loss: 1.203, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:12:48,654: INFO: Iter: 300, Loss: 1.128, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:13:12,990: INFO: Iter: 350, Loss: 1.082, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:13:37,502: INFO: Iter: 400, Loss: 1.176, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:14:01,747: INFO: Iter: 450, Loss: 1.152, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:14:25,961: INFO: Iter: 500, Loss: 0.936, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:14:50,034: INFO: Iter: 550, Loss: 1.232, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:15:14,257: INFO: Iter: 600, Loss: 1.169, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:15:38,615: INFO: Iter: 650, Loss: 1.045, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:16:02,900: INFO: Iter: 700, Loss: 1.297, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:16:27,249: INFO: Iter: 750, Loss: 1.153, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:16:51,649: INFO: Iter: 800, Loss: 1.093, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:17:15,460: INFO: Iter: 850, Loss: 1.121, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:17:39,617: INFO: Iter: 900, Loss: 0.945, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:18:03,794: INFO: Iter: 950, Loss: 1.119, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:18:28,194: INFO: Iter: 1000, Loss: 1.103, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:18:52,371: INFO: Iter: 1050, Loss: 1.252, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:19:16,497: INFO: Iter: 1100, Loss: 0.813, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 14:19:40,724: INFO: Iter: 1150, Loss: 0.913, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:20:05,067: INFO: Iter: 1200, Loss: 0.923, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:20:29,551: INFO: Iter: 1250, Loss: 0.849, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 14:20:53,778: INFO: Iter: 1300, Loss: 1.012, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:21:18,344: INFO: Iter: 1350, Loss: 1.146, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:21:42,721: INFO: Iter: 1400, Loss: 0.819, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 14:22:06,808: INFO: Iter: 1450, Loss: 0.976, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:22:31,082: INFO: Iter: 1500, Loss: 1.083, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:22:55,548: INFO: Iter: 1550, Loss: 0.882, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 14:23:19,825: INFO: Iter: 1600, Loss: 1.083, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:23:44,053: INFO: Iter: 1650, Loss: 0.846, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 14:24:08,560: INFO: Iter: 1700, Loss: 1.112, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:24:33,034: INFO: Iter: 1750, Loss: 1.255, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:24:57,255: INFO: Iter: 1800, Loss: 0.883, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 14:25:21,439: INFO: Iter: 1850, Loss: 0.971, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:25:45,640: INFO: Iter: 1900, Loss: 1.034, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:26:10,165: INFO: Iter: 1950, Loss: 1.050, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:26:34,412: INFO: Iter: 2000, Loss: 0.983, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:26:58,681: INFO: Iter: 2050, Loss: 0.988, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:27:22,857: INFO: Iter: 2100, Loss: 0.911, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:27:47,011: INFO: Iter: 2150, Loss: 1.025, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:28:11,372: INFO: Iter: 2200, Loss: 0.974, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:28:35,747: INFO: Iter: 2250, Loss: 0.955, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:28:59,988: INFO: Iter: 2300, Loss: 0.981, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:29:24,294: INFO: Iter: 2350, Loss: 1.011, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:29:48,441: INFO: Iter: 2400, Loss: 1.111, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:30:13,049: INFO: Iter: 2450, Loss: 0.981, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:30:37,193: INFO: Iter: 2500, Loss: 0.752, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 14:31:01,697: INFO: Iter: 2550, Loss: 0.970, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:31:26,181: INFO: Iter: 2600, Loss: 1.028, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:31:50,516: INFO: Iter: 2650, Loss: 0.926, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:32:14,587: INFO: Iter: 2700, Loss: 0.860, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 14:32:38,723: INFO: Iter: 2750, Loss: 1.276, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:33:02,771: INFO: Iter: 2800, Loss: 1.136, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:33:27,064: INFO: Iter: 2850, Loss: 1.220, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:33:51,469: INFO: Iter: 2900, Loss: 1.238, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:34:15,565: INFO: Iter: 2950, Loss: 0.999, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:34:39,750: INFO: Iter: 3000, Loss: 1.183, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:35:03,908: INFO: Iter: 3050, Loss: 0.985, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:35:28,247: INFO: Iter: 3100, Loss: 1.202, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:35:52,499: INFO: Iter: 3150, Loss: 1.171, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:36:16,866: INFO: Iter: 3200, Loss: 1.017, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:36:40,970: INFO: Iter: 3250, Loss: 1.081, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:37:05,046: INFO: Iter: 3300, Loss: 1.128, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:37:29,421: INFO: Iter: 3350, Loss: 1.411, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 14:37:53,788: INFO: Iter: 3400, Loss: 1.193, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:38:17,950: INFO: Iter: 3450, Loss: 1.017, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:38:42,309: INFO: Iter: 3500, Loss: 1.222, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:39:06,657: INFO: Iter: 3550, Loss: 1.166, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:39:31,154: INFO: Iter: 3600, Loss: 1.077, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:39:55,612: INFO: Iter: 3650, Loss: 1.016, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:40:20,354: INFO: Iter: 3700, Loss: 1.103, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:40:44,658: INFO: Iter: 3750, Loss: 1.111, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:41:08,875: INFO: Iter: 3800, Loss: 1.096, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:41:33,031: INFO: Iter: 3850, Loss: 1.118, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:41:57,317: INFO: Iter: 3900, Loss: 0.986, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:42:21,820: INFO: Iter: 3950, Loss: 0.683, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 14:42:45,969: INFO: Iter: 4000, Loss: 0.953, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:43:10,270: INFO: Iter: 4050, Loss: 1.261, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:43:34,479: INFO: Iter: 4100, Loss: 1.111, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:43:58,927: INFO: Iter: 4150, Loss: 1.224, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:44:23,299: INFO: Iter: 4200, Loss: 1.105, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:44:47,566: INFO: Iter: 4250, Loss: 1.004, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:45:11,934: INFO: Iter: 4300, Loss: 1.133, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:45:36,378: INFO: Iter: 4350, Loss: 0.994, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:46:00,583: INFO: Iter: 4400, Loss: 1.333, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 14:46:24,884: INFO: Iter: 4450, Loss: 0.879, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 14:46:49,361: INFO: Iter: 4500, Loss: 1.113, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:47:13,795: INFO: Iter: 4550, Loss: 1.333, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 14:47:38,025: INFO: Iter: 4600, Loss: 1.099, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:48:02,293: INFO: Iter: 4650, Loss: 1.114, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:48:26,843: INFO: Iter: 4700, Loss: 1.072, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:48:51,160: INFO: Iter: 4750, Loss: 1.107, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:49:15,426: INFO: Iter: 4800, Loss: 1.078, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:49:39,803: INFO: Iter: 4850, Loss: 1.071, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:50:04,112: INFO: Iter: 4900, Loss: 1.149, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:50:28,539: INFO: Iter: 4950, Loss: 0.948, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:50:52,888: INFO: Iter: 5000, Loss: 1.310, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:51:17,303: INFO: Iter: 5050, Loss: 0.968, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:51:41,467: INFO: Iter: 5100, Loss: 0.982, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:52:05,791: INFO: Iter: 5150, Loss: 0.861, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 14:52:30,016: INFO: Iter: 5200, Loss: 1.108, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:52:54,379: INFO: Iter: 5250, Loss: 1.126, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:53:18,700: INFO: Iter: 5300, Loss: 0.979, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:53:43,043: INFO: Iter: 5350, Loss: 0.985, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:54:07,476: INFO: Iter: 5400, Loss: 1.111, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:54:31,927: INFO: Iter: 5450, Loss: 1.238, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:54:56,319: INFO: Iter: 5500, Loss: 0.968, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:55:20,555: INFO: Iter: 5550, Loss: 0.795, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 14:55:44,909: INFO: Iter: 5600, Loss: 1.014, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:56:09,063: INFO: Iter: 5650, Loss: 0.829, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 14:56:33,522: INFO: Iter: 5700, Loss: 1.258, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 14:56:57,691: INFO: Iter: 5750, Loss: 0.913, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 14:57:21,982: INFO: Iter: 5800, Loss: 1.110, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:57:46,072: INFO: Iter: 5850, Loss: 0.897, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 14:58:10,163: INFO: Iter: 5900, Loss: 1.173, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:58:34,415: INFO: Iter: 5950, Loss: 1.061, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:58:58,795: INFO: Iter: 6000, Loss: 1.106, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 14:59:23,096: INFO: Iter: 6050, Loss: 0.990, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 14:59:47,560: INFO: Iter: 6100, Loss: 1.093, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:00:11,927: INFO: Iter: 6150, Loss: 1.208, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 15:00:36,374: INFO: Iter: 6200, Loss: 0.807, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 15:01:00,583: INFO: Iter: 6250, Loss: 1.089, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:01:25,025: INFO: Iter: 6300, Loss: 1.326, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 15:01:49,642: INFO: Iter: 6350, Loss: 0.961, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:02:13,884: INFO: Iter: 6400, Loss: 1.210, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:02:38,136: INFO: Iter: 6450, Loss: 1.236, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 15:03:02,591: INFO: Iter: 6500, Loss: 1.049, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:03:27,148: INFO: Iter: 6550, Loss: 1.146, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:03:51,585: INFO: Iter: 6600, Loss: 0.814, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 15:04:15,730: INFO: Iter: 6650, Loss: 1.063, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:04:40,249: INFO: Iter: 6700, Loss: 1.228, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 15:05:04,652: INFO: Iter: 6750, Loss: 0.926, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:05:29,158: INFO: Iter: 6800, Loss: 1.139, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:05:53,576: INFO: Iter: 6850, Loss: 1.124, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:06:17,927: INFO: Iter: 6900, Loss: 0.832, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 15:06:42,364: INFO: Iter: 6950, Loss: 1.228, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 15:07:06,669: INFO: Iter: 7000, Loss: 0.715, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 15:07:31,072: INFO: Iter: 7050, Loss: 1.115, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:07:55,520: INFO: Iter: 7100, Loss: 1.114, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:08:19,816: INFO: Iter: 7150, Loss: 1.091, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:08:44,078: INFO: Iter: 7200, Loss: 1.106, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:09:08,520: INFO: Iter: 7250, Loss: 1.033, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:09:33,017: INFO: Iter: 7300, Loss: 0.768, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 15:09:57,405: INFO: Iter: 7350, Loss: 0.925, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:10:21,599: INFO: Iter: 7400, Loss: 1.130, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:10:45,983: INFO: Iter: 7450, Loss: 0.900, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 15:11:10,305: INFO: Iter: 7500, Loss: 1.132, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:11:34,482: INFO: Iter: 7550, Loss: 0.996, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:11:58,976: INFO: Iter: 7600, Loss: 0.939, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 15:12:23,425: INFO: Iter: 7650, Loss: 1.047, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:12:47,877: INFO: Iter: 7700, Loss: 1.023, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:13:11,746: INFO: Iter: 7750, Loss: 1.154, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 15:13:36,201: INFO: Iter: 7800, Loss: 0.776, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 15:14:00,579: INFO: Iter: 7850, Loss: 1.158, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:14:25,007: INFO: Iter: 7900, Loss: 1.096, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:14:49,254: INFO: Iter: 7950, Loss: 1.094, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:15:13,618: INFO: Iter: 8000, Loss: 0.947, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:15:37,907: INFO: Iter: 8050, Loss: 1.146, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:16:02,069: INFO: Iter: 8100, Loss: 1.007, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:16:26,614: INFO: Iter: 8150, Loss: 1.165, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 15:16:50,523: INFO: Iter: 8200, Loss: 0.967, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:17:14,751: INFO: Iter: 8250, Loss: 0.972, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:17:39,207: INFO: Iter: 8300, Loss: 1.318, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 15:18:03,408: INFO: Iter: 8350, Loss: 1.110, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:18:27,852: INFO: Iter: 8400, Loss: 1.061, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:18:52,089: INFO: Iter: 8450, Loss: 0.941, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:19:16,399: INFO: Iter: 8500, Loss: 1.073, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:19:40,874: INFO: Iter: 8550, Loss: 1.067, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:20:05,209: INFO: Iter: 8600, Loss: 1.007, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:20:29,544: INFO: Iter: 8650, Loss: 1.126, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:20:53,761: INFO: Iter: 8700, Loss: 1.065, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:21:18,147: INFO: Iter: 8750, Loss: 1.119, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:21:42,654: INFO: Iter: 8800, Loss: 1.175, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 15:22:07,183: INFO: Iter: 8850, Loss: 1.008, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:22:31,542: INFO: Iter: 8900, Loss: 0.921, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:22:55,829: INFO: Iter: 8950, Loss: 1.084, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:23:20,204: INFO: Iter: 9000, Loss: 1.004, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:23:44,718: INFO: Iter: 9050, Loss: 0.974, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:24:08,981: INFO: Iter: 9100, Loss: 0.995, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:24:33,587: INFO: Iter: 9150, Loss: 1.072, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:24:58,122: INFO: Iter: 9200, Loss: 0.831, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 15:25:22,594: INFO: Iter: 9250, Loss: 1.255, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 15:25:46,937: INFO: Iter: 9300, Loss: 1.028, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:26:11,171: INFO: Iter: 9350, Loss: 0.818, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 15:26:35,394: INFO: Iter: 9400, Loss: 0.777, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 15:27:00,012: INFO: Iter: 9450, Loss: 1.084, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:27:24,476: INFO: Iter: 9500, Loss: 1.016, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:27:48,719: INFO: Iter: 9550, Loss: 1.081, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:28:13,006: INFO: Iter: 9600, Loss: 0.891, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 15:28:37,237: INFO: Iter: 9650, Loss: 1.154, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 15:29:01,841: INFO: Iter: 9700, Loss: 0.938, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:29:26,341: INFO: Iter: 9750, Loss: 0.977, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:29:50,715: INFO: Iter: 9800, Loss: 0.788, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 15:30:14,890: INFO: Iter: 9850, Loss: 0.909, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:30:39,063: INFO: Iter: 9900, Loss: 1.299, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 15:31:03,341: INFO: Iter: 9950, Loss: 1.108, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:31:27,723: INFO: Iter: 10000, Loss: 1.110, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:31:52,158: INFO: Iter: 10050, Loss: 0.954, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:32:16,542: INFO: Iter: 10100, Loss: 1.009, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:32:40,824: INFO: Iter: 10150, Loss: 1.021, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:33:04,969: INFO: Iter: 10200, Loss: 0.944, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:33:29,362: INFO: Iter: 10250, Loss: 1.136, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:33:53,514: INFO: Iter: 10300, Loss: 1.049, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:34:18,041: INFO: Iter: 10350, Loss: 0.966, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:34:42,123: INFO: Iter: 10400, Loss: 0.976, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:35:06,643: INFO: Iter: 10450, Loss: 0.970, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:35:31,122: INFO: Iter: 10500, Loss: 1.086, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:35:55,581: INFO: Iter: 10550, Loss: 1.223, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 15:36:19,935: INFO: Iter: 10600, Loss: 1.093, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:36:44,237: INFO: Iter: 10650, Loss: 1.247, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 15:37:08,863: INFO: Iter: 10700, Loss: 1.256, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 15:37:32,941: INFO: Iter: 10750, Loss: 0.945, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:37:57,449: INFO: Iter: 10800, Loss: 0.866, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 15:38:21,730: INFO: Iter: 10850, Loss: 1.224, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 15:38:45,970: INFO: Iter: 10900, Loss: 1.061, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:39:10,282: INFO: Iter: 10950, Loss: 1.058, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:39:34,656: INFO: Iter: 11000, Loss: 0.972, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:39:59,095: INFO: Iter: 11050, Loss: 1.279, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 15:40:23,241: INFO: Iter: 11100, Loss: 0.715, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 15:40:47,761: INFO: Iter: 11150, Loss: 1.129, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 15:41:12,199: INFO: Iter: 11200, Loss: 0.972, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:41:36,590: INFO: Iter: 11250, Loss: 1.077, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:42:00,985: INFO: Iter: 11300, Loss: 0.933, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 15:42:25,532: INFO: Iter: 11350, Loss: 1.129, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 15:42:49,848: INFO: Iter: 11400, Loss: 1.240, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 15:43:13,885: INFO: Iter: 11450, Loss: 1.006, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:43:38,216: INFO: Iter: 11500, Loss: 0.962, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:44:02,581: INFO: Iter: 11550, Loss: 1.040, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:44:27,050: INFO: Iter: 11600, Loss: 0.845, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 15:44:51,423: INFO: Iter: 11650, Loss: 1.013, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:45:15,881: INFO: Iter: 11700, Loss: 1.287, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 15:45:40,384: INFO: Iter: 11750, Loss: 1.267, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 15:46:04,974: INFO: Iter: 11800, Loss: 0.967, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:46:29,602: INFO: Iter: 11850, Loss: 1.069, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 15:46:53,957: INFO: Iter: 11900, Loss: 1.085, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:47:18,275: INFO: Iter: 11950, Loss: 1.136, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:47:42,352: INFO: Iter: 12000, Loss: 1.210, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 15:48:06,631: INFO: Iter: 12050, Loss: 0.999, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:48:30,975: INFO: Iter: 12100, Loss: 1.107, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 15:48:55,393: INFO: Iter: 12150, Loss: 1.012, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:49:19,770: INFO: Iter: 12200, Loss: 0.870, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 15:49:44,060: INFO: Iter: 12250, Loss: 1.047, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:50:08,308: INFO: Iter: 12300, Loss: 0.940, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:50:32,786: INFO: Iter: 12350, Loss: 1.002, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:50:57,393: INFO: Iter: 12400, Loss: 0.824, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 15:51:21,856: INFO: Iter: 12450, Loss: 0.965, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:51:46,176: INFO: Iter: 12500, Loss: 0.937, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:52:10,566: INFO: Iter: 12550, Loss: 1.033, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:52:34,696: INFO: Iter: 12600, Loss: 0.906, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:52:58,882: INFO: Iter: 12650, Loss: 0.849, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 15:53:22,968: INFO: Iter: 12700, Loss: 0.966, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:53:47,403: INFO: Iter: 12750, Loss: 0.842, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 15:54:11,626: INFO: Iter: 12800, Loss: 1.129, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:54:36,050: INFO: Iter: 12850, Loss: 0.998, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:55:00,258: INFO: Iter: 12900, Loss: 0.736, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 15:55:24,751: INFO: Iter: 12950, Loss: 1.020, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:55:48,996: INFO: Iter: 13000, Loss: 1.143, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:56:13,545: INFO: Iter: 13050, Loss: 1.102, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:56:37,884: INFO: Iter: 13100, Loss: 0.823, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 15:57:02,269: INFO: Iter: 13150, Loss: 1.051, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:57:26,779: INFO: Iter: 13200, Loss: 0.796, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 15:57:51,034: INFO: Iter: 13250, Loss: 1.076, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:58:15,484: INFO: Iter: 13300, Loss: 0.983, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:58:39,728: INFO: Iter: 13350, Loss: 0.832, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 15:59:03,692: INFO: Iter: 13400, Loss: 0.943, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 15:59:28,043: INFO: Iter: 13450, Loss: 1.089, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 15:59:52,752: INFO: Iter: 13500, Loss: 0.979, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:00:17,213: INFO: Iter: 13550, Loss: 1.180, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:00:41,660: INFO: Iter: 13600, Loss: 0.929, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:01:05,907: INFO: Iter: 13650, Loss: 1.135, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:01:30,405: INFO: Iter: 13700, Loss: 1.064, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:01:54,862: INFO: Iter: 13750, Loss: 0.976, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:02:19,285: INFO: Iter: 13800, Loss: 0.839, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 16:02:43,565: INFO: Iter: 13850, Loss: 1.137, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:03:08,138: INFO: Iter: 13900, Loss: 1.137, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:03:32,580: INFO: Iter: 13950, Loss: 1.169, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:03:56,623: INFO: Iter: 14000, Loss: 0.886, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 16:04:20,988: INFO: Iter: 14050, Loss: 1.231, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:04:45,315: INFO: Iter: 14100, Loss: 0.881, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:05:09,699: INFO: Iter: 14150, Loss: 1.207, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:05:34,346: INFO: Iter: 14200, Loss: 0.956, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:05:58,740: INFO: Iter: 14250, Loss: 1.251, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:06:22,858: INFO: Iter: 14300, Loss: 0.834, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 16:06:47,218: INFO: Iter: 14350, Loss: 0.947, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:07:11,718: INFO: Iter: 14400, Loss: 1.089, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:07:36,098: INFO: Iter: 14450, Loss: 1.031, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:08:00,427: INFO: Iter: 14500, Loss: 1.117, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:08:24,628: INFO: Iter: 14550, Loss: 1.066, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:08:48,815: INFO: Iter: 14600, Loss: 1.114, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:09:12,908: INFO: Iter: 14650, Loss: 1.166, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:09:37,454: INFO: Iter: 14700, Loss: 1.014, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:10:01,868: INFO: Iter: 14750, Loss: 1.183, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:10:26,415: INFO: Iter: 14800, Loss: 1.170, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:10:50,631: INFO: Iter: 14850, Loss: 1.189, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:11:14,914: INFO: Iter: 14900, Loss: 1.017, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:11:39,030: INFO: Iter: 14950, Loss: 1.313, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:12:03,088: INFO: Iter: 15000, Loss: 1.120, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:12:27,565: INFO: Iter: 15050, Loss: 1.141, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:12:52,028: INFO: Iter: 15100, Loss: 0.882, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 16:13:16,268: INFO: Iter: 15150, Loss: 1.173, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:13:40,437: INFO: Iter: 15200, Loss: 1.110, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:14:04,848: INFO: Iter: 15250, Loss: 0.803, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 16:14:29,387: INFO: Iter: 15300, Loss: 0.810, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 16:14:53,663: INFO: Iter: 15350, Loss: 1.073, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:15:18,038: INFO: Iter: 15400, Loss: 0.870, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 16:15:42,492: INFO: Iter: 15450, Loss: 1.105, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:16:06,844: INFO: Iter: 15500, Loss: 0.911, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:16:31,106: INFO: Iter: 15550, Loss: 1.325, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 16:16:55,586: INFO: Iter: 15600, Loss: 1.073, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:17:19,789: INFO: Iter: 15650, Loss: 1.102, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:17:44,314: INFO: Iter: 15700, Loss: 0.955, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:18:08,680: INFO: Iter: 15750, Loss: 0.968, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:18:32,758: INFO: Iter: 15800, Loss: 1.093, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:18:57,165: INFO: Iter: 15850, Loss: 1.075, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:19:21,698: INFO: Iter: 15900, Loss: 0.821, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 16:19:45,825: INFO: Iter: 15950, Loss: 0.924, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:20:10,437: INFO: Iter: 16000, Loss: 1.012, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:20:34,659: INFO: Iter: 16050, Loss: 0.986, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:20:59,112: INFO: Iter: 16100, Loss: 1.164, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:21:23,274: INFO: Iter: 16150, Loss: 1.202, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:21:47,758: INFO: Iter: 16200, Loss: 1.134, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:22:12,016: INFO: Iter: 16250, Loss: 1.198, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:22:36,034: INFO: Iter: 16300, Loss: 0.928, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:23:00,357: INFO: Iter: 16350, Loss: 1.173, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:23:24,646: INFO: Iter: 16400, Loss: 1.056, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:23:48,863: INFO: Iter: 16450, Loss: 0.918, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 16:24:13,367: INFO: Iter: 16500, Loss: 1.094, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:24:37,948: INFO: Iter: 16550, Loss: 1.043, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:25:02,404: INFO: Iter: 16600, Loss: 1.032, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:25:26,834: INFO: Iter: 16650, Loss: 1.041, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:25:51,160: INFO: Iter: 16700, Loss: 1.056, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:26:15,311: INFO: Iter: 16750, Loss: 1.410, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 16:26:39,363: INFO: Iter: 16800, Loss: 1.030, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:27:03,144: INFO: Iter: 16850, Loss: 0.883, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:27:27,479: INFO: Iter: 16900, Loss: 0.831, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 16:27:51,699: INFO: Iter: 16950, Loss: 1.017, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:28:15,988: INFO: Iter: 17000, Loss: 1.384, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 16:28:40,320: INFO: Iter: 17050, Loss: 1.035, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:29:04,634: INFO: Iter: 17100, Loss: 0.886, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:29:29,176: INFO: Iter: 17150, Loss: 1.391, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:29:53,474: INFO: Iter: 17200, Loss: 1.053, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:30:17,904: INFO: Iter: 17250, Loss: 1.141, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:30:41,889: INFO: Iter: 17300, Loss: 0.792, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 16:31:06,436: INFO: Iter: 17350, Loss: 1.068, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:31:30,785: INFO: Iter: 17400, Loss: 1.110, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:31:55,075: INFO: Iter: 17450, Loss: 0.885, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:32:19,279: INFO: Iter: 17500, Loss: 1.020, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:32:43,210: INFO: Iter: 17550, Loss: 1.103, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:33:07,452: INFO: Iter: 17600, Loss: 1.209, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:33:31,849: INFO: Iter: 17650, Loss: 1.069, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:33:56,095: INFO: Iter: 17700, Loss: 1.313, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:34:20,651: INFO: Iter: 17750, Loss: 0.987, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:34:45,086: INFO: Iter: 17800, Loss: 1.048, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:35:09,334: INFO: Iter: 17850, Loss: 1.254, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:35:33,593: INFO: Iter: 17900, Loss: 1.219, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:35:58,025: INFO: Iter: 17950, Loss: 1.144, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:36:22,361: INFO: Iter: 18000, Loss: 1.184, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:36:46,734: INFO: Iter: 18050, Loss: 0.982, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:37:11,075: INFO: Iter: 18100, Loss: 1.011, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:37:35,459: INFO: Iter: 18150, Loss: 0.973, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:38:00,109: INFO: Iter: 18200, Loss: 0.785, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 16:38:24,557: INFO: Iter: 18250, Loss: 0.947, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:38:49,047: INFO: Iter: 18300, Loss: 1.376, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:39:12,912: INFO: Iter: 18350, Loss: 0.803, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 16:39:36,655: INFO: Iter: 18400, Loss: 1.132, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:40:00,498: INFO: Iter: 18450, Loss: 0.848, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 16:40:24,293: INFO: Iter: 18500, Loss: 1.077, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:40:48,119: INFO: Iter: 18550, Loss: 0.947, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:41:11,804: INFO: Iter: 18600, Loss: 0.904, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:41:35,476: INFO: Iter: 18650, Loss: 0.900, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:41:59,391: INFO: Iter: 18700, Loss: 1.027, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:42:23,080: INFO: Iter: 18750, Loss: 0.891, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:42:46,701: INFO: Iter: 18800, Loss: 1.288, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:43:10,396: INFO: Iter: 18850, Loss: 0.931, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:43:34,166: INFO: Iter: 18900, Loss: 1.007, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:43:58,099: INFO: Iter: 18950, Loss: 0.845, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:44:21,989: INFO: Iter: 19000, Loss: 1.153, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:44:45,848: INFO: Iter: 19050, Loss: 0.912, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:45:09,679: INFO: Iter: 19100, Loss: 1.134, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:45:33,466: INFO: Iter: 19150, Loss: 1.261, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 16:45:57,070: INFO: Iter: 19200, Loss: 1.056, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:46:20,615: INFO: Iter: 19250, Loss: 0.762, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 16:46:44,116: INFO: Iter: 19300, Loss: 1.088, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:47:07,937: INFO: Iter: 19350, Loss: 0.920, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:47:31,618: INFO: Iter: 19400, Loss: 1.065, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:47:55,535: INFO: Iter: 19450, Loss: 0.781, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:48:19,246: INFO: Iter: 19500, Loss: 1.460, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:48:42,949: INFO: Iter: 19550, Loss: 0.935, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:49:06,693: INFO: Iter: 19600, Loss: 0.974, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:49:30,502: INFO: Iter: 19650, Loss: 1.040, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:49:54,347: INFO: Iter: 19700, Loss: 1.186, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:50:18,087: INFO: Iter: 19750, Loss: 1.025, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:50:41,666: INFO: Iter: 19800, Loss: 0.934, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:51:05,021: INFO: Iter: 19850, Loss: 1.215, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:51:28,754: INFO: Iter: 19900, Loss: 1.092, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:51:52,742: INFO: Iter: 19950, Loss: 0.831, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 16:52:16,179: INFO: Iter: 20000, Loss: 1.102, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:52:40,115: INFO: Iter: 20050, Loss: 0.996, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:53:04,037: INFO: Iter: 20100, Loss: 1.270, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:53:27,871: INFO: Iter: 20150, Loss: 1.035, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:53:51,323: INFO: Iter: 20200, Loss: 1.045, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:54:15,126: INFO: Iter: 20250, Loss: 0.976, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:54:38,929: INFO: Iter: 20300, Loss: 1.138, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:55:02,593: INFO: Iter: 20350, Loss: 0.847, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 16:55:26,412: INFO: Iter: 20400, Loss: 1.184, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:55:50,378: INFO: Iter: 20450, Loss: 1.174, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:56:14,011: INFO: Iter: 20500, Loss: 0.900, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 16:56:37,487: INFO: Iter: 20550, Loss: 0.908, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:57:01,289: INFO: Iter: 20600, Loss: 1.084, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:57:25,040: INFO: Iter: 20650, Loss: 0.800, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 16:57:48,387: INFO: Iter: 20700, Loss: 0.934, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:58:12,313: INFO: Iter: 20750, Loss: 0.960, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 16:58:36,042: INFO: Iter: 20800, Loss: 1.346, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 16:58:59,781: INFO: Iter: 20850, Loss: 1.349, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 16:59:23,544: INFO: Iter: 20900, Loss: 1.189, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 16:59:47,238: INFO: Iter: 20950, Loss: 1.004, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:00:11,083: INFO: Iter: 21000, Loss: 0.932, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:00:34,626: INFO: Iter: 21050, Loss: 0.948, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:00:58,450: INFO: Iter: 21100, Loss: 1.049, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:01:22,410: INFO: Iter: 21150, Loss: 1.119, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:01:45,939: INFO: Iter: 21200, Loss: 0.996, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:02:09,480: INFO: Iter: 21250, Loss: 0.977, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 17:02:32,944: INFO: Iter: 21300, Loss: 0.968, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:02:56,622: INFO: Iter: 21350, Loss: 0.936, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:03:20,195: INFO: Iter: 21400, Loss: 0.836, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:03:43,578: INFO: Iter: 21450, Loss: 1.058, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:04:07,321: INFO: Iter: 21500, Loss: 0.858, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:04:31,161: INFO: Iter: 21550, Loss: 1.281, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 17:04:55,034: INFO: Iter: 21600, Loss: 0.993, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:05:18,453: INFO: Iter: 21650, Loss: 0.885, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:05:42,068: INFO: Iter: 21700, Loss: 0.911, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:06:05,736: INFO: Iter: 21750, Loss: 1.065, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:06:29,464: INFO: Iter: 21800, Loss: 0.922, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:06:53,009: INFO: Iter: 21850, Loss: 1.065, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 17:07:16,949: INFO: Iter: 21900, Loss: 0.827, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:07:40,780: INFO: Iter: 21950, Loss: 1.035, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:08:04,460: INFO: Iter: 22000, Loss: 0.921, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:08:28,197: INFO: Iter: 22050, Loss: 0.940, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:08:52,164: INFO: Iter: 22100, Loss: 0.947, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:09:15,795: INFO: Iter: 22150, Loss: 0.973, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:09:39,349: INFO: Iter: 22200, Loss: 0.946, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:10:03,337: INFO: Iter: 22250, Loss: 1.254, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 17:10:26,998: INFO: Iter: 22300, Loss: 1.021, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:10:50,584: INFO: Iter: 22350, Loss: 0.980, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:11:14,385: INFO: Iter: 22400, Loss: 0.965, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:11:38,067: INFO: Iter: 22450, Loss: 0.805, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:12:01,927: INFO: Iter: 22500, Loss: 0.950, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:12:25,649: INFO: Iter: 22550, Loss: 0.910, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:12:49,219: INFO: Iter: 22600, Loss: 0.958, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:13:12,693: INFO: Iter: 22650, Loss: 0.609, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:13:36,435: INFO: Iter: 22700, Loss: 1.182, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:14:00,312: INFO: Iter: 22750, Loss: 0.960, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:14:24,076: INFO: Iter: 22800, Loss: 1.424, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 17:14:47,798: INFO: Iter: 22850, Loss: 1.262, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 17:15:11,648: INFO: Iter: 22900, Loss: 1.034, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:15:35,460: INFO: Iter: 22950, Loss: 0.889, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:15:59,339: INFO: Iter: 23000, Loss: 1.119, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:16:22,901: INFO: Iter: 23050, Loss: 0.942, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:16:46,476: INFO: Iter: 23100, Loss: 0.905, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:17:09,854: INFO: Iter: 23150, Loss: 1.108, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 17:17:33,598: INFO: Iter: 23200, Loss: 1.369, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 17:17:57,451: INFO: Iter: 23250, Loss: 1.079, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:18:21,082: INFO: Iter: 23300, Loss: 1.027, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 17:18:44,887: INFO: Iter: 23350, Loss: 0.908, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:19:08,519: INFO: Iter: 23400, Loss: 0.799, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:19:32,409: INFO: Iter: 23450, Loss: 1.063, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:19:55,863: INFO: Iter: 23500, Loss: 0.860, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:20:19,752: INFO: Iter: 23550, Loss: 0.920, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:20:43,365: INFO: Iter: 23600, Loss: 1.342, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 17:21:07,150: INFO: Iter: 23650, Loss: 0.920, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:21:30,858: INFO: Iter: 23700, Loss: 1.100, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:21:54,501: INFO: Iter: 23750, Loss: 1.200, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:22:18,268: INFO: Iter: 23800, Loss: 1.320, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 17:22:42,040: INFO: Iter: 23850, Loss: 0.848, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:23:05,559: INFO: Iter: 23900, Loss: 0.675, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 17:23:29,218: INFO: Iter: 23950, Loss: 1.318, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:23:52,911: INFO: Iter: 24000, Loss: 0.783, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 17:24:16,297: INFO: Iter: 24050, Loss: 0.829, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:24:40,003: INFO: Iter: 24100, Loss: 0.739, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:25:03,763: INFO: Iter: 24150, Loss: 0.810, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:25:27,571: INFO: Iter: 24200, Loss: 0.659, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:25:51,309: INFO: Iter: 24250, Loss: 0.829, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:26:14,770: INFO: Iter: 24300, Loss: 1.055, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:26:38,380: INFO: Iter: 24350, Loss: 1.049, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:27:01,887: INFO: Iter: 24400, Loss: 0.839, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:27:25,683: INFO: Iter: 24450, Loss: 0.979, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:27:49,101: INFO: Iter: 24500, Loss: 0.943, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:28:12,813: INFO: Iter: 24550, Loss: 0.919, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:28:36,341: INFO: Iter: 24600, Loss: 0.849, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:29:00,280: INFO: Iter: 24650, Loss: 1.181, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 17:29:23,912: INFO: Iter: 24700, Loss: 0.747, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:29:47,635: INFO: Iter: 24750, Loss: 0.775, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:30:11,195: INFO: Iter: 24800, Loss: 1.201, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 17:30:34,864: INFO: Iter: 24850, Loss: 1.400, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 17:30:58,641: INFO: Iter: 24900, Loss: 0.894, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:31:22,456: INFO: Iter: 24950, Loss: 1.191, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 17:31:46,003: INFO: Iter: 25000, Loss: 0.967, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:32:09,588: INFO: Iter: 25050, Loss: 0.937, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:32:33,348: INFO: Iter: 25100, Loss: 1.072, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:32:56,981: INFO: Iter: 25150, Loss: 0.945, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:33:20,859: INFO: Iter: 25200, Loss: 0.856, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:33:44,709: INFO: Iter: 25250, Loss: 1.002, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:34:08,486: INFO: Iter: 25300, Loss: 1.028, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:34:32,208: INFO: Iter: 25350, Loss: 0.784, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:34:56,025: INFO: Iter: 25400, Loss: 1.064, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:35:19,852: INFO: Iter: 25450, Loss: 0.759, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:35:43,565: INFO: Iter: 25500, Loss: 0.977, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:36:07,076: INFO: Iter: 25550, Loss: 0.812, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:36:30,953: INFO: Iter: 25600, Loss: 0.977, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:36:54,887: INFO: Iter: 25650, Loss: 0.909, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:37:18,413: INFO: Iter: 25700, Loss: 1.075, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 17:37:42,007: INFO: Iter: 25750, Loss: 1.111, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:38:05,817: INFO: Iter: 25800, Loss: 1.417, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 17:38:29,271: INFO: Iter: 25850, Loss: 1.054, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:38:52,897: INFO: Iter: 25900, Loss: 0.871, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:39:16,476: INFO: Iter: 25950, Loss: 0.896, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:39:40,058: INFO: Iter: 26000, Loss: 1.078, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:40:03,739: INFO: Iter: 26050, Loss: 1.126, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:40:31,280: INFO: Iter: 26100, Loss: 0.808, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:41:01,524: INFO: Iter: 26150, Loss: 0.892, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:41:46,330: INFO: Iter: 26200, Loss: 0.807, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:42:15,953: INFO: Iter: 26250, Loss: 0.948, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 17:42:41,246: INFO: Iter: 26300, Loss: 0.900, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:43:06,187: INFO: Iter: 26350, Loss: 1.276, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:43:30,220: INFO: Iter: 26400, Loss: 0.764, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:43:53,989: INFO: Iter: 26450, Loss: 0.567, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 17:44:17,785: INFO: Iter: 26500, Loss: 0.778, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:44:41,354: INFO: Iter: 26550, Loss: 1.154, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 17:45:05,215: INFO: Iter: 26600, Loss: 0.837, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:45:28,873: INFO: Iter: 26650, Loss: 0.885, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:45:52,585: INFO: Iter: 26700, Loss: 0.988, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:46:16,372: INFO: Iter: 26750, Loss: 0.697, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:46:40,234: INFO: Iter: 26800, Loss: 0.937, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:47:04,130: INFO: Iter: 26850, Loss: 0.886, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:47:27,889: INFO: Iter: 26900, Loss: 0.658, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 17:47:51,703: INFO: Iter: 26950, Loss: 1.138, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:48:15,767: INFO: Iter: 27000, Loss: 0.891, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:48:39,666: INFO: Iter: 27050, Loss: 0.940, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:49:03,474: INFO: Iter: 27100, Loss: 0.981, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:49:27,242: INFO: Iter: 27150, Loss: 0.705, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:49:51,177: INFO: Iter: 27200, Loss: 0.674, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 17:50:14,825: INFO: Iter: 27250, Loss: 1.267, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:50:38,809: INFO: Iter: 27300, Loss: 0.914, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:51:02,797: INFO: Iter: 27350, Loss: 0.907, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:51:26,615: INFO: Iter: 27400, Loss: 0.962, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:51:50,309: INFO: Iter: 27450, Loss: 0.923, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:52:14,117: INFO: Iter: 27500, Loss: 0.919, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:52:38,039: INFO: Iter: 27550, Loss: 0.749, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:53:01,126: INFO: Iter: 27600, Loss: 1.265, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 17:53:25,014: INFO: Iter: 27650, Loss: 1.181, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:53:48,581: INFO: Iter: 27700, Loss: 0.852, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:54:12,281: INFO: Iter: 27750, Loss: 0.838, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:54:35,854: INFO: Iter: 27800, Loss: 1.071, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:54:59,484: INFO: Iter: 27850, Loss: 1.086, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:55:23,156: INFO: Iter: 27900, Loss: 0.675, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:55:47,068: INFO: Iter: 27950, Loss: 1.023, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:56:10,791: INFO: Iter: 28000, Loss: 0.818, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:56:34,370: INFO: Iter: 28050, Loss: 0.827, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:56:58,037: INFO: Iter: 28100, Loss: 1.128, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 17:57:21,870: INFO: Iter: 28150, Loss: 1.017, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 17:57:45,588: INFO: Iter: 28200, Loss: 0.868, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:58:09,474: INFO: Iter: 28250, Loss: 0.732, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 17:58:33,081: INFO: Iter: 28300, Loss: 1.095, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 17:58:56,948: INFO: Iter: 28350, Loss: 0.802, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:59:20,514: INFO: Iter: 28400, Loss: 0.544, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 17:59:44,206: INFO: Iter: 28450, Loss: 0.846, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:00:08,137: INFO: Iter: 28500, Loss: 0.933, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:00:32,084: INFO: Iter: 28550, Loss: 0.767, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:00:55,719: INFO: Iter: 28600, Loss: 0.617, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 18:01:19,434: INFO: Iter: 28650, Loss: 0.758, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:01:43,262: INFO: Iter: 28700, Loss: 1.019, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 18:02:06,978: INFO: Iter: 28750, Loss: 1.247, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 18:02:30,582: INFO: Iter: 28800, Loss: 0.787, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:02:54,345: INFO: Iter: 28850, Loss: 0.914, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 18:03:17,879: INFO: Iter: 28900, Loss: 0.740, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:03:41,610: INFO: Iter: 28950, Loss: 0.727, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:04:05,105: INFO: Iter: 29000, Loss: 0.899, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 18:04:28,904: INFO: Iter: 29050, Loss: 0.800, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:04:52,528: INFO: Iter: 29100, Loss: 0.942, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:05:16,091: INFO: Iter: 29150, Loss: 0.552, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 18:05:39,677: INFO: Iter: 29200, Loss: 0.559, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:06:03,439: INFO: Iter: 29250, Loss: 0.908, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:06:27,211: INFO: Iter: 29300, Loss: 0.803, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:06:50,924: INFO: Iter: 29350, Loss: 0.742, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 18:07:14,436: INFO: Iter: 29400, Loss: 0.748, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:07:38,244: INFO: Iter: 29450, Loss: 0.826, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:08:02,052: INFO: Iter: 29500, Loss: 0.941, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 18:08:25,985: INFO: Iter: 29550, Loss: 1.109, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 18:08:49,713: INFO: Iter: 29600, Loss: 0.554, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:09:13,159: INFO: Iter: 29650, Loss: 0.577, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 18:09:36,821: INFO: Iter: 29700, Loss: 0.800, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:10:00,525: INFO: Iter: 29750, Loss: 0.860, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:10:24,271: INFO: Iter: 29800, Loss: 0.844, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:10:48,171: INFO: Iter: 29850, Loss: 1.009, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:11:11,966: INFO: Iter: 29900, Loss: 0.579, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:11:35,608: INFO: Iter: 29950, Loss: 0.553, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:11:59,431: INFO: Iter: 30000, Loss: 0.986, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 18:12:23,096: INFO: Iter: 30050, Loss: 0.875, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 18:12:46,327: INFO: Iter: 30100, Loss: 0.826, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:13:10,166: INFO: Iter: 30150, Loss: 0.858, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:13:33,655: INFO: Iter: 30200, Loss: 0.853, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:13:57,323: INFO: Iter: 30250, Loss: 0.695, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:14:21,016: INFO: Iter: 30300, Loss: 0.596, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:14:44,679: INFO: Iter: 30350, Loss: 1.006, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 18:15:08,324: INFO: Iter: 30400, Loss: 0.484, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:15:32,272: INFO: Iter: 30450, Loss: 0.913, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:15:56,031: INFO: Iter: 30500, Loss: 0.852, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:16:19,647: INFO: Iter: 30550, Loss: 1.053, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 18:16:43,494: INFO: Iter: 30600, Loss: 0.896, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:17:07,175: INFO: Iter: 30650, Loss: 1.204, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 18:17:30,810: INFO: Iter: 30700, Loss: 0.898, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 18:17:54,524: INFO: Iter: 30750, Loss: 0.897, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:18:18,256: INFO: Iter: 30800, Loss: 0.746, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:18:41,851: INFO: Iter: 30850, Loss: 0.683, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:19:05,339: INFO: Iter: 30900, Loss: 0.629, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:19:29,078: INFO: Iter: 30950, Loss: 0.595, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:19:52,735: INFO: Iter: 31000, Loss: 0.617, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:20:16,397: INFO: Iter: 31050, Loss: 0.803, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:20:39,960: INFO: Iter: 31100, Loss: 0.899, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:21:03,903: INFO: Iter: 31150, Loss: 0.999, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 18:21:27,709: INFO: Iter: 31200, Loss: 0.808, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:21:51,297: INFO: Iter: 31250, Loss: 0.600, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 18:22:14,988: INFO: Iter: 31300, Loss: 0.530, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:22:38,940: INFO: Iter: 31350, Loss: 0.920, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:23:02,529: INFO: Iter: 31400, Loss: 1.224, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 18:23:26,375: INFO: Iter: 31450, Loss: 0.411, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 18:23:49,997: INFO: Iter: 31500, Loss: 0.792, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 18:24:13,921: INFO: Iter: 31550, Loss: 0.747, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:24:37,652: INFO: Iter: 31600, Loss: 1.041, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 18:25:01,554: INFO: Iter: 31650, Loss: 0.570, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 18:25:25,307: INFO: Iter: 31700, Loss: 0.936, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:25:48,926: INFO: Iter: 31750, Loss: 0.740, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:26:12,550: INFO: Iter: 31800, Loss: 0.861, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:26:36,230: INFO: Iter: 31850, Loss: 0.921, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:27:00,075: INFO: Iter: 31900, Loss: 0.760, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:27:23,744: INFO: Iter: 31950, Loss: 0.331, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 18:27:47,420: INFO: Iter: 32000, Loss: 1.558, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 18:28:11,065: INFO: Iter: 32050, Loss: 0.971, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:28:34,875: INFO: Iter: 32100, Loss: 0.774, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:28:58,595: INFO: Iter: 32150, Loss: 0.717, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:29:22,405: INFO: Iter: 32200, Loss: 1.518, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 18:29:45,899: INFO: Iter: 32250, Loss: 0.758, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:30:09,738: INFO: Iter: 32300, Loss: 1.534, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 18:30:33,423: INFO: Iter: 32350, Loss: 0.929, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:30:57,172: INFO: Iter: 32400, Loss: 0.868, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:31:20,977: INFO: Iter: 32450, Loss: 0.689, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:31:44,798: INFO: Iter: 32500, Loss: 1.077, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 18:32:08,183: INFO: Iter: 32550, Loss: 0.978, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:32:31,777: INFO: Iter: 32600, Loss: 0.810, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:32:55,741: INFO: Iter: 32650, Loss: 0.802, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:33:19,357: INFO: Iter: 32700, Loss: 0.839, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:33:43,142: INFO: Iter: 32750, Loss: 0.480, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 18:34:06,877: INFO: Iter: 32800, Loss: 0.853, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:34:30,583: INFO: Iter: 32850, Loss: 0.721, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:34:54,134: INFO: Iter: 32900, Loss: 0.710, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:35:17,940: INFO: Iter: 32950, Loss: 0.554, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:35:41,480: INFO: Iter: 33000, Loss: 0.489, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 18:36:05,131: INFO: Iter: 33050, Loss: 0.633, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:36:28,935: INFO: Iter: 33100, Loss: 1.143, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 18:36:52,515: INFO: Iter: 33150, Loss: 0.986, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:37:16,204: INFO: Iter: 33200, Loss: 1.124, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 18:37:39,755: INFO: Iter: 33250, Loss: 0.745, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:38:03,473: INFO: Iter: 33300, Loss: 0.929, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:38:27,434: INFO: Iter: 33350, Loss: 1.012, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:38:51,035: INFO: Iter: 33400, Loss: 0.595, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:39:14,733: INFO: Iter: 33450, Loss: 0.702, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:39:38,533: INFO: Iter: 33500, Loss: 0.467, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 18:40:02,396: INFO: Iter: 33550, Loss: 0.817, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:40:26,270: INFO: Iter: 33600, Loss: 0.816, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:40:49,776: INFO: Iter: 33650, Loss: 0.824, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 18:41:13,696: INFO: Iter: 33700, Loss: 0.723, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:41:37,104: INFO: Iter: 33750, Loss: 0.614, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 18:42:00,893: INFO: Iter: 33800, Loss: 1.038, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 18:42:24,614: INFO: Iter: 33850, Loss: 0.759, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:42:48,286: INFO: Iter: 33900, Loss: 1.121, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 18:43:12,657: INFO: Iter: 33950, Loss: 0.585, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:43:36,405: INFO: Iter: 34000, Loss: 0.805, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:44:00,299: INFO: Iter: 34050, Loss: 0.771, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:44:23,900: INFO: Iter: 34100, Loss: 0.617, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:44:47,742: INFO: Iter: 34150, Loss: 0.684, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:45:11,382: INFO: Iter: 34200, Loss: 0.721, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:45:34,986: INFO: Iter: 34250, Loss: 1.070, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 18:45:58,705: INFO: Iter: 34300, Loss: 0.730, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:46:22,656: INFO: Iter: 34350, Loss: 0.851, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:46:46,006: INFO: Iter: 34400, Loss: 0.644, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:47:10,383: INFO: Iter: 34450, Loss: 0.757, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:47:34,578: INFO: Iter: 34500, Loss: 0.827, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:47:59,089: INFO: Iter: 34550, Loss: 0.878, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:48:24,776: INFO: Iter: 34600, Loss: 0.610, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:48:50,254: INFO: Iter: 34650, Loss: 0.737, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:49:14,949: INFO: Iter: 34700, Loss: 0.720, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:49:39,542: INFO: Iter: 34750, Loss: 0.919, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:50:04,270: INFO: Iter: 34800, Loss: 1.057, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 18:50:28,426: INFO: Iter: 34850, Loss: 0.743, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:50:53,020: INFO: Iter: 34900, Loss: 0.759, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:51:17,277: INFO: Iter: 34950, Loss: 0.543, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:51:43,054: INFO: Iter: 35000, Loss: 0.798, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:52:08,726: INFO: Iter: 35050, Loss: 0.872, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:52:34,824: INFO: Iter: 35100, Loss: 0.876, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:52:59,226: INFO: Iter: 35150, Loss: 0.723, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:53:23,937: INFO: Iter: 35200, Loss: 0.453, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 18:53:48,468: INFO: Iter: 35250, Loss: 0.762, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 18:54:12,260: INFO: Iter: 35300, Loss: 0.422, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 18:54:35,967: INFO: Iter: 35350, Loss: 0.925, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:55:00,525: INFO: Iter: 35400, Loss: 0.820, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:55:25,408: INFO: Iter: 35450, Loss: 0.735, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:55:50,069: INFO: Iter: 35500, Loss: 1.063, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:56:15,355: INFO: Iter: 35550, Loss: 0.648, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:56:39,129: INFO: Iter: 35600, Loss: 0.412, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 18:57:03,029: INFO: Iter: 35650, Loss: 0.806, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:57:26,843: INFO: Iter: 35700, Loss: 0.644, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 18:57:51,015: INFO: Iter: 35750, Loss: 0.949, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 18:58:16,111: INFO: Iter: 35800, Loss: 0.429, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 18:58:40,014: INFO: Iter: 35850, Loss: 0.903, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:59:04,374: INFO: Iter: 35900, Loss: 0.712, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 18:59:29,152: INFO: Iter: 35950, Loss: 0.703, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 18:59:52,997: INFO: Iter: 36000, Loss: 0.612, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:00:16,786: INFO: Iter: 36050, Loss: 0.466, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:00:41,315: INFO: Iter: 36100, Loss: 0.518, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:01:06,898: INFO: Iter: 36150, Loss: 0.478, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:01:31,089: INFO: Iter: 36200, Loss: 0.516, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:01:54,915: INFO: Iter: 36250, Loss: 0.834, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:02:18,534: INFO: Iter: 36300, Loss: 0.841, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:02:42,250: INFO: Iter: 36350, Loss: 0.516, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:03:06,185: INFO: Iter: 36400, Loss: 1.014, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 19:03:30,076: INFO: Iter: 36450, Loss: 0.484, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:03:53,783: INFO: Iter: 36500, Loss: 1.189, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 19:04:17,394: INFO: Iter: 36550, Loss: 0.435, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:04:41,231: INFO: Iter: 36600, Loss: 0.803, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:05:05,490: INFO: Iter: 36650, Loss: 0.654, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:05:30,779: INFO: Iter: 36700, Loss: 0.763, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:05:55,366: INFO: Iter: 36750, Loss: 1.091, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 19:06:19,542: INFO: Iter: 36800, Loss: 0.584, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:06:44,305: INFO: Iter: 36850, Loss: 0.802, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:07:08,415: INFO: Iter: 36900, Loss: 0.446, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:07:33,404: INFO: Iter: 36950, Loss: 0.977, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 19:07:59,174: INFO: Iter: 37000, Loss: 0.602, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:08:25,184: INFO: Iter: 37050, Loss: 0.677, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 19:08:50,043: INFO: Iter: 37100, Loss: 0.752, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:09:14,295: INFO: Iter: 37150, Loss: 0.745, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:09:39,217: INFO: Iter: 37200, Loss: 0.440, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:10:03,647: INFO: Iter: 37250, Loss: 0.527, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:10:30,013: INFO: Iter: 37300, Loss: 0.573, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:10:53,938: INFO: Iter: 37350, Loss: 0.816, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:11:17,643: INFO: Iter: 37400, Loss: 0.305, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:11:41,754: INFO: Iter: 37450, Loss: 0.598, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:12:05,599: INFO: Iter: 37500, Loss: 0.883, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 19:12:29,346: INFO: Iter: 37550, Loss: 0.786, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:12:53,002: INFO: Iter: 37600, Loss: 0.610, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:13:17,472: INFO: Iter: 37650, Loss: 0.236, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:13:41,338: INFO: Iter: 37700, Loss: 0.240, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:14:05,164: INFO: Iter: 37750, Loss: 0.488, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:14:29,042: INFO: Iter: 37800, Loss: 0.593, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:14:53,237: INFO: Iter: 37850, Loss: 0.474, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:15:17,277: INFO: Iter: 37900, Loss: 0.441, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:15:41,344: INFO: Iter: 37950, Loss: 0.382, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:16:05,283: INFO: Iter: 38000, Loss: 0.649, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:16:29,327: INFO: Iter: 38050, Loss: 0.991, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 19:16:53,282: INFO: Iter: 38100, Loss: 0.590, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:17:17,182: INFO: Iter: 38150, Loss: 0.476, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:17:41,094: INFO: Iter: 38200, Loss: 1.137, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 19:18:05,040: INFO: Iter: 38250, Loss: 1.166, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 19:18:29,159: INFO: Iter: 38300, Loss: 0.740, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:18:53,213: INFO: Iter: 38350, Loss: 0.701, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:19:17,108: INFO: Iter: 38400, Loss: 0.954, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:19:40,997: INFO: Iter: 38450, Loss: 0.698, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:20:04,966: INFO: Iter: 38500, Loss: 1.431, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 19:20:29,270: INFO: Iter: 38550, Loss: 0.495, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:20:52,961: INFO: Iter: 38600, Loss: 0.552, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:21:16,989: INFO: Iter: 38650, Loss: 0.736, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:21:40,706: INFO: Iter: 38700, Loss: 0.636, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:22:04,742: INFO: Iter: 38750, Loss: 0.457, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:22:28,536: INFO: Iter: 38800, Loss: 0.441, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:22:52,555: INFO: Iter: 38850, Loss: 0.622, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:23:16,347: INFO: Iter: 38900, Loss: 0.425, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:23:40,422: INFO: Iter: 38950, Loss: 0.803, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 19:24:04,592: INFO: Iter: 39000, Loss: 0.585, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:24:28,715: INFO: Iter: 39050, Loss: 0.881, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:24:52,505: INFO: Iter: 39100, Loss: 0.644, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:25:16,496: INFO: Iter: 39150, Loss: 0.692, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:25:40,426: INFO: Iter: 39200, Loss: 0.808, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:26:04,471: INFO: Iter: 39250, Loss: 0.611, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:26:28,503: INFO: Iter: 39300, Loss: 0.883, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 19:26:52,688: INFO: Iter: 39350, Loss: 0.729, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:27:16,606: INFO: Iter: 39400, Loss: 0.888, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:27:40,765: INFO: Iter: 39450, Loss: 0.785, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 19:28:04,786: INFO: Iter: 39500, Loss: 0.431, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:28:28,559: INFO: Iter: 39550, Loss: 0.499, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:28:52,541: INFO: Iter: 39600, Loss: 0.240, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:29:16,519: INFO: Iter: 39650, Loss: 0.676, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:29:40,411: INFO: Iter: 39700, Loss: 0.360, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:30:04,074: INFO: Iter: 39750, Loss: 0.587, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:30:28,100: INFO: Iter: 39800, Loss: 0.345, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:30:52,077: INFO: Iter: 39850, Loss: 1.181, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:31:16,139: INFO: Iter: 39900, Loss: 0.480, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:31:40,123: INFO: Iter: 39950, Loss: 0.751, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:32:03,954: INFO: Iter: 40000, Loss: 0.438, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:32:28,099: INFO: Iter: 40050, Loss: 0.343, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:32:51,849: INFO: Iter: 40100, Loss: 0.582, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:33:15,863: INFO: Iter: 40150, Loss: 0.843, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:33:39,593: INFO: Iter: 40200, Loss: 0.276, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:34:03,239: INFO: Iter: 40250, Loss: 0.389, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:34:27,165: INFO: Iter: 40300, Loss: 0.863, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:34:51,295: INFO: Iter: 40350, Loss: 0.586, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:35:15,267: INFO: Iter: 40400, Loss: 0.719, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:35:39,239: INFO: Iter: 40450, Loss: 0.653, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:36:02,887: INFO: Iter: 40500, Loss: 0.573, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:36:26,892: INFO: Iter: 40550, Loss: 0.191, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:36:50,830: INFO: Iter: 40600, Loss: 1.134, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:37:14,785: INFO: Iter: 40650, Loss: 0.700, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:37:38,982: INFO: Iter: 40700, Loss: 0.671, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:38:02,543: INFO: Iter: 40750, Loss: 0.878, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:38:26,313: INFO: Iter: 40800, Loss: 0.866, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 19:38:50,281: INFO: Iter: 40850, Loss: 0.386, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:39:14,202: INFO: Iter: 40900, Loss: 0.667, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:39:38,006: INFO: Iter: 40950, Loss: 0.634, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:40:02,223: INFO: Iter: 41000, Loss: 0.459, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:40:26,442: INFO: Iter: 41050, Loss: 0.562, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:40:50,366: INFO: Iter: 41100, Loss: 0.415, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:41:14,207: INFO: Iter: 41150, Loss: 0.446, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:41:38,339: INFO: Iter: 41200, Loss: 0.217, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:42:02,292: INFO: Iter: 41250, Loss: 0.756, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:42:26,420: INFO: Iter: 41300, Loss: 0.532, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:42:50,338: INFO: Iter: 41350, Loss: 0.635, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:43:14,936: INFO: Iter: 41400, Loss: 0.919, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:43:39,279: INFO: Iter: 41450, Loss: 0.872, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:44:03,137: INFO: Iter: 41500, Loss: 0.504, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:44:27,283: INFO: Iter: 41550, Loss: 0.552, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:44:51,196: INFO: Iter: 41600, Loss: 0.636, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:45:15,347: INFO: Iter: 41650, Loss: 0.589, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:45:39,386: INFO: Iter: 41700, Loss: 0.493, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:46:03,180: INFO: Iter: 41750, Loss: 0.872, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:46:27,270: INFO: Iter: 41800, Loss: 1.108, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 19:46:51,253: INFO: Iter: 41850, Loss: 0.532, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:47:15,358: INFO: Iter: 41900, Loss: 0.655, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:47:39,360: INFO: Iter: 41950, Loss: 0.928, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 19:48:03,127: INFO: Iter: 42000, Loss: 0.587, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:48:26,844: INFO: Iter: 42050, Loss: 1.848, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 19:48:50,664: INFO: Iter: 42100, Loss: 0.426, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:49:14,380: INFO: Iter: 42150, Loss: 0.978, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:49:37,839: INFO: Iter: 42200, Loss: 0.327, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:50:01,738: INFO: Iter: 42250, Loss: 0.770, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:50:25,677: INFO: Iter: 42300, Loss: 0.534, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:50:49,850: INFO: Iter: 42350, Loss: 1.130, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 19:51:13,857: INFO: Iter: 42400, Loss: 0.470, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:51:37,846: INFO: Iter: 42450, Loss: 0.444, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:52:01,994: INFO: Iter: 42500, Loss: 0.543, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:52:26,283: INFO: Iter: 42550, Loss: 0.505, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:52:50,400: INFO: Iter: 42600, Loss: 0.804, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:53:14,175: INFO: Iter: 42650, Loss: 0.366, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:53:38,082: INFO: Iter: 42700, Loss: 0.925, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 19:54:02,066: INFO: Iter: 42750, Loss: 0.703, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:54:26,184: INFO: Iter: 42800, Loss: 0.622, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:54:50,358: INFO: Iter: 42850, Loss: 0.785, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:55:14,276: INFO: Iter: 42900, Loss: 0.922, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 19:55:38,398: INFO: Iter: 42950, Loss: 1.568, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 19:56:02,621: INFO: Iter: 43000, Loss: 0.808, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:56:26,594: INFO: Iter: 43050, Loss: 1.100, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 19:56:50,463: INFO: Iter: 43100, Loss: 0.995, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:57:14,050: INFO: Iter: 43150, Loss: 0.606, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 19:57:37,712: INFO: Iter: 43200, Loss: 1.547, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 19:58:01,570: INFO: Iter: 43250, Loss: 0.575, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:58:25,642: INFO: Iter: 43300, Loss: 0.464, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:58:49,797: INFO: Iter: 43350, Loss: 0.514, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 19:59:13,882: INFO: Iter: 43400, Loss: 0.612, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 19:59:37,795: INFO: Iter: 43450, Loss: 0.885, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:00:01,940: INFO: Iter: 43500, Loss: 0.582, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:00:25,997: INFO: Iter: 43550, Loss: 0.561, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:00:50,086: INFO: Iter: 43600, Loss: 0.529, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:01:13,937: INFO: Iter: 43650, Loss: 0.515, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:01:37,841: INFO: Iter: 43700, Loss: 1.119, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 20:02:02,100: INFO: Iter: 43750, Loss: 0.714, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:02:26,143: INFO: Iter: 43800, Loss: 0.769, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:02:49,968: INFO: Iter: 43850, Loss: 0.617, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:03:13,879: INFO: Iter: 43900, Loss: 0.919, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:03:37,544: INFO: Iter: 43950, Loss: 0.604, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:04:01,596: INFO: Iter: 44000, Loss: 0.404, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:04:25,569: INFO: Iter: 44050, Loss: 0.607, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:04:49,329: INFO: Iter: 44100, Loss: 0.675, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:05:12,962: INFO: Iter: 44150, Loss: 0.636, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:05:36,573: INFO: Iter: 44200, Loss: 0.527, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:06:00,351: INFO: Iter: 44250, Loss: 0.410, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:06:24,209: INFO: Iter: 44300, Loss: 0.683, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:06:48,257: INFO: Iter: 44350, Loss: 0.281, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:07:11,933: INFO: Iter: 44400, Loss: 0.436, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:07:35,828: INFO: Iter: 44450, Loss: 0.305, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:07:59,721: INFO: Iter: 44500, Loss: 0.574, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:08:23,501: INFO: Iter: 44550, Loss: 0.467, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:08:47,394: INFO: Iter: 44600, Loss: 0.487, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:09:11,650: INFO: Iter: 44650, Loss: 0.432, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:09:35,542: INFO: Iter: 44700, Loss: 0.224, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:09:59,460: INFO: Iter: 44750, Loss: 0.621, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:10:23,144: INFO: Iter: 44800, Loss: 0.382, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:10:46,914: INFO: Iter: 44850, Loss: 0.971, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:11:10,711: INFO: Iter: 44900, Loss: 0.625, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:11:34,791: INFO: Iter: 44950, Loss: 0.378, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:11:58,877: INFO: Iter: 45000, Loss: 0.685, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:12:23,287: INFO: Iter: 45050, Loss: 1.084, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:12:47,217: INFO: Iter: 45100, Loss: 0.346, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:13:11,322: INFO: Iter: 45150, Loss: 0.139, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:13:35,446: INFO: Iter: 45200, Loss: 0.740, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:13:59,383: INFO: Iter: 45250, Loss: 0.514, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:14:23,527: INFO: Iter: 45300, Loss: 0.458, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:14:47,320: INFO: Iter: 45350, Loss: 0.423, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:15:11,489: INFO: Iter: 45400, Loss: 0.961, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 20:15:35,584: INFO: Iter: 45450, Loss: 0.661, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:15:59,484: INFO: Iter: 45500, Loss: 0.621, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:16:23,241: INFO: Iter: 45550, Loss: 0.493, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:16:47,225: INFO: Iter: 45600, Loss: 0.539, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:17:11,073: INFO: Iter: 45650, Loss: 0.619, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:17:34,921: INFO: Iter: 45700, Loss: 0.648, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:17:58,852: INFO: Iter: 45750, Loss: 0.233, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:18:22,751: INFO: Iter: 45800, Loss: 0.597, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:18:46,450: INFO: Iter: 45850, Loss: 0.442, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:19:10,349: INFO: Iter: 45900, Loss: 0.734, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:19:33,788: INFO: Iter: 45950, Loss: 0.406, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:19:58,044: INFO: Iter: 46000, Loss: 0.440, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:20:21,911: INFO: Iter: 46050, Loss: 0.494, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:20:45,829: INFO: Iter: 46100, Loss: 0.392, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:21:09,774: INFO: Iter: 46150, Loss: 0.293, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:21:33,803: INFO: Iter: 46200, Loss: 0.327, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:21:57,757: INFO: Iter: 46250, Loss: 0.206, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:22:21,723: INFO: Iter: 46300, Loss: 0.555, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:22:45,420: INFO: Iter: 46350, Loss: 0.736, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:23:09,323: INFO: Iter: 46400, Loss: 0.341, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:23:33,113: INFO: Iter: 46450, Loss: 0.156, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:23:57,171: INFO: Iter: 46500, Loss: 0.908, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:24:21,174: INFO: Iter: 46550, Loss: 0.832, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 20:24:45,152: INFO: Iter: 46600, Loss: 0.729, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:25:08,861: INFO: Iter: 46650, Loss: 0.804, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:25:32,625: INFO: Iter: 46700, Loss: 0.444, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:25:56,598: INFO: Iter: 46750, Loss: 0.592, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:26:20,494: INFO: Iter: 46800, Loss: 0.324, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:26:44,423: INFO: Iter: 46850, Loss: 0.554, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:27:08,302: INFO: Iter: 46900, Loss: 0.202, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:27:32,571: INFO: Iter: 46950, Loss: 0.691, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:27:56,501: INFO: Iter: 47000, Loss: 0.239, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:28:20,549: INFO: Iter: 47050, Loss: 0.639, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:28:44,538: INFO: Iter: 47100, Loss: 0.231, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:29:08,549: INFO: Iter: 47150, Loss: 0.321, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:29:32,609: INFO: Iter: 47200, Loss: 0.724, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:29:56,548: INFO: Iter: 47250, Loss: 0.747, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:30:20,690: INFO: Iter: 47300, Loss: 0.448, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:30:44,802: INFO: Iter: 47350, Loss: 0.815, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:31:08,533: INFO: Iter: 47400, Loss: 0.520, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:31:32,822: INFO: Iter: 47450, Loss: 0.292, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:31:56,805: INFO: Iter: 47500, Loss: 0.501, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:32:20,729: INFO: Iter: 47550, Loss: 0.719, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:32:44,556: INFO: Iter: 47600, Loss: 0.238, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:33:08,529: INFO: Iter: 47650, Loss: 1.020, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 20:33:32,580: INFO: Iter: 47700, Loss: 1.104, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 20:33:56,577: INFO: Iter: 47750, Loss: 0.566, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:34:20,921: INFO: Iter: 47800, Loss: 0.476, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:34:44,738: INFO: Iter: 47850, Loss: 0.449, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:35:08,756: INFO: Iter: 47900, Loss: 0.262, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:35:32,690: INFO: Iter: 47950, Loss: 0.519, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:35:56,790: INFO: Iter: 48000, Loss: 0.465, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:36:20,819: INFO: Iter: 48050, Loss: 0.356, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:36:44,703: INFO: Iter: 48100, Loss: 0.297, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:37:08,656: INFO: Iter: 48150, Loss: 0.770, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:37:32,670: INFO: Iter: 48200, Loss: 0.436, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:37:56,615: INFO: Iter: 48250, Loss: 0.518, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:38:20,594: INFO: Iter: 48300, Loss: 0.337, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:38:44,451: INFO: Iter: 48350, Loss: 0.453, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:39:08,398: INFO: Iter: 48400, Loss: 0.983, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:39:32,469: INFO: Iter: 48450, Loss: 0.127, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:39:56,483: INFO: Iter: 48500, Loss: 0.491, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:40:20,522: INFO: Iter: 48550, Loss: 0.395, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:40:44,225: INFO: Iter: 48600, Loss: 0.229, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:41:07,623: INFO: Iter: 48650, Loss: 0.197, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:41:31,536: INFO: Iter: 48700, Loss: 0.181, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:41:55,186: INFO: Iter: 48750, Loss: 0.797, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 20:42:18,854: INFO: Iter: 48800, Loss: 0.351, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:42:42,962: INFO: Iter: 48850, Loss: 0.518, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:43:07,143: INFO: Iter: 48900, Loss: 0.311, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:43:31,171: INFO: Iter: 48950, Loss: 0.635, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:43:54,984: INFO: Iter: 49000, Loss: 0.658, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:44:18,804: INFO: Iter: 49050, Loss: 0.351, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:44:42,573: INFO: Iter: 49100, Loss: 0.863, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:45:06,223: INFO: Iter: 49150, Loss: 0.582, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:45:30,153: INFO: Iter: 49200, Loss: 0.619, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:45:54,214: INFO: Iter: 49250, Loss: 0.237, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:46:18,201: INFO: Iter: 49300, Loss: 0.260, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:46:42,033: INFO: Iter: 49350, Loss: 0.344, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:47:05,519: INFO: Iter: 49400, Loss: 0.283, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:47:29,781: INFO: Iter: 49450, Loss: 0.400, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:47:53,726: INFO: Iter: 49500, Loss: 0.459, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:48:17,572: INFO: Iter: 49550, Loss: 0.193, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:48:41,526: INFO: Iter: 49600, Loss: 0.727, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:49:05,262: INFO: Iter: 49650, Loss: 0.224, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:49:29,186: INFO: Iter: 49700, Loss: 0.308, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:49:53,172: INFO: Iter: 49750, Loss: 0.975, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:50:16,945: INFO: Iter: 49800, Loss: 0.486, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:50:40,840: INFO: Iter: 49850, Loss: 0.520, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:51:04,715: INFO: Iter: 49900, Loss: 0.816, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 20:51:28,593: INFO: Iter: 49950, Loss: 0.490, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:51:52,358: INFO: Iter: 50000, Loss: 0.728, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:52:16,216: INFO: Iter: 50050, Loss: 0.357, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:52:40,075: INFO: Iter: 50100, Loss: 0.764, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:53:04,353: INFO: Iter: 50150, Loss: 0.779, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 20:53:28,237: INFO: Iter: 50200, Loss: 0.689, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:53:52,242: INFO: Iter: 50250, Loss: 0.697, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:54:16,314: INFO: Iter: 50300, Loss: 0.988, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 20:54:40,081: INFO: Iter: 50350, Loss: 0.471, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:55:03,974: INFO: Iter: 50400, Loss: 0.410, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:55:28,018: INFO: Iter: 50450, Loss: 0.807, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:55:51,737: INFO: Iter: 50500, Loss: 0.394, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:56:15,625: INFO: Iter: 50550, Loss: 0.323, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:56:39,576: INFO: Iter: 50600, Loss: 0.674, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:57:03,568: INFO: Iter: 50650, Loss: 0.343, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:57:27,260: INFO: Iter: 50700, Loss: 0.710, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 20:57:51,265: INFO: Iter: 50750, Loss: 0.698, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:58:15,177: INFO: Iter: 50800, Loss: 0.488, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 20:58:39,271: INFO: Iter: 50850, Loss: 0.795, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 20:59:03,319: INFO: Iter: 50900, Loss: 0.636, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:59:27,342: INFO: Iter: 50950, Loss: 0.360, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 20:59:51,069: INFO: Iter: 51000, Loss: 0.695, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:00:14,994: INFO: Iter: 51050, Loss: 0.658, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:00:39,007: INFO: Iter: 51100, Loss: 0.878, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:01:02,827: INFO: Iter: 51150, Loss: 0.367, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:01:26,557: INFO: Iter: 51200, Loss: 0.875, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:01:50,248: INFO: Iter: 51250, Loss: 0.244, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 21:02:14,300: INFO: Iter: 51300, Loss: 0.182, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 21:02:38,127: INFO: Iter: 51350, Loss: 0.178, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 21:03:02,129: INFO: Iter: 51400, Loss: 0.437, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 21:03:26,342: INFO: Iter: 51450, Loss: 0.783, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:03:50,315: INFO: Iter: 51500, Loss: 0.334, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 21:04:14,073: INFO: Iter: 51550, Loss: 0.180, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 21:04:37,989: INFO: Iter: 51600, Loss: 0.388, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:05:01,916: INFO: Iter: 51650, Loss: 0.498, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:05:25,954: INFO: Iter: 51700, Loss: 0.278, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 21:05:49,842: INFO: Iter: 51750, Loss: 0.346, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:06:13,637: INFO: Iter: 51800, Loss: 0.847, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:06:37,809: INFO: Iter: 51850, Loss: 0.813, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:07:01,950: INFO: Iter: 51900, Loss: 0.352, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:07:25,826: INFO: Iter: 51950, Loss: 0.569, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:07:51,451: INFO: Iter: 52000, Loss: 0.598, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:08:17,095: INFO: Iter: 52050, Loss: 1.600, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 21:08:42,360: INFO: Iter: 52100, Loss: 1.072, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:09:08,161: INFO: Iter: 52150, Loss: 1.875, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 21:09:32,139: INFO: Iter: 52200, Loss: 1.024, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:09:56,160: INFO: Iter: 52250, Loss: 2.032, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 21:10:19,930: INFO: Iter: 52300, Loss: 1.409, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:10:44,108: INFO: Iter: 52350, Loss: 1.799, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 21:11:07,860: INFO: Iter: 52400, Loss: 1.130, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:11:31,968: INFO: Iter: 52450, Loss: 0.969, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:11:56,057: INFO: Iter: 52500, Loss: 1.289, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:12:19,852: INFO: Iter: 52550, Loss: 0.914, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:12:44,001: INFO: Iter: 52600, Loss: 1.502, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:13:07,852: INFO: Iter: 52650, Loss: 0.961, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:13:31,993: INFO: Iter: 52700, Loss: 0.973, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:13:55,911: INFO: Iter: 52750, Loss: 0.796, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:14:19,503: INFO: Iter: 52800, Loss: 0.869, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:14:43,560: INFO: Iter: 52850, Loss: 1.026, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:15:07,270: INFO: Iter: 52900, Loss: 1.279, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 21:15:31,395: INFO: Iter: 52950, Loss: 0.777, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:15:55,419: INFO: Iter: 53000, Loss: 0.898, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:16:19,610: INFO: Iter: 53050, Loss: 1.439, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 21:16:43,712: INFO: Iter: 53100, Loss: 1.375, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 21:17:07,505: INFO: Iter: 53150, Loss: 0.894, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:17:31,580: INFO: Iter: 53200, Loss: 1.488, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 21:17:55,620: INFO: Iter: 53250, Loss: 1.134, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:18:19,640: INFO: Iter: 53300, Loss: 1.022, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:18:43,522: INFO: Iter: 53350, Loss: 1.266, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:19:07,357: INFO: Iter: 53400, Loss: 0.798, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:19:31,236: INFO: Iter: 53450, Loss: 0.875, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:19:55,334: INFO: Iter: 53500, Loss: 0.915, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:20:18,980: INFO: Iter: 53550, Loss: 0.591, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:20:42,939: INFO: Iter: 53600, Loss: 0.936, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 21:21:07,192: INFO: Iter: 53650, Loss: 0.812, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:21:31,054: INFO: Iter: 53700, Loss: 1.088, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:21:54,877: INFO: Iter: 53750, Loss: 0.789, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:22:18,501: INFO: Iter: 53800, Loss: 0.955, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:22:42,274: INFO: Iter: 53850, Loss: 0.665, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:23:06,320: INFO: Iter: 53900, Loss: 1.327, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 21:23:30,386: INFO: Iter: 53950, Loss: 0.885, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:23:54,279: INFO: Iter: 54000, Loss: 0.905, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:24:18,372: INFO: Iter: 54050, Loss: 1.550, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 21:24:41,752: INFO: Iter: 54100, Loss: 0.799, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:25:05,502: INFO: Iter: 54150, Loss: 1.159, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:25:29,547: INFO: Iter: 54200, Loss: 1.086, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:25:53,534: INFO: Iter: 54250, Loss: 1.424, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 21:26:17,635: INFO: Iter: 54300, Loss: 0.988, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:26:41,677: INFO: Iter: 54350, Loss: 1.275, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 21:27:05,348: INFO: Iter: 54400, Loss: 1.264, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 21:27:29,599: INFO: Iter: 54450, Loss: 0.765, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:27:53,625: INFO: Iter: 54500, Loss: 0.502, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:28:17,679: INFO: Iter: 54550, Loss: 1.038, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:28:41,694: INFO: Iter: 54600, Loss: 1.217, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 21:29:05,172: INFO: Iter: 54650, Loss: 1.027, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:29:29,075: INFO: Iter: 54700, Loss: 1.112, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:29:52,986: INFO: Iter: 54750, Loss: 1.151, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 21:30:16,722: INFO: Iter: 54800, Loss: 0.606, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:30:40,358: INFO: Iter: 54850, Loss: 0.949, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:31:04,336: INFO: Iter: 54900, Loss: 0.527, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 21:31:28,241: INFO: Iter: 54950, Loss: 1.007, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:31:52,196: INFO: Iter: 55000, Loss: 0.858, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:32:16,076: INFO: Iter: 55050, Loss: 0.852, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:32:40,084: INFO: Iter: 55100, Loss: 0.847, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:33:03,915: INFO: Iter: 55150, Loss: 1.266, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:33:27,773: INFO: Iter: 55200, Loss: 1.483, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 21:33:51,751: INFO: Iter: 55250, Loss: 0.920, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:34:15,707: INFO: Iter: 55300, Loss: 0.517, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:34:39,661: INFO: Iter: 55350, Loss: 0.760, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:35:03,375: INFO: Iter: 55400, Loss: 0.977, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:35:27,317: INFO: Iter: 55450, Loss: 0.807, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:35:51,164: INFO: Iter: 55500, Loss: 0.975, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:36:15,221: INFO: Iter: 55550, Loss: 1.067, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:36:39,263: INFO: Iter: 55600, Loss: 1.417, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 21:37:03,063: INFO: Iter: 55650, Loss: 0.903, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:37:26,967: INFO: Iter: 55700, Loss: 0.708, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:37:50,949: INFO: Iter: 55750, Loss: 0.808, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:38:14,765: INFO: Iter: 55800, Loss: 1.297, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 21:38:38,631: INFO: Iter: 55850, Loss: 0.732, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:39:02,533: INFO: Iter: 55900, Loss: 0.995, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:39:26,407: INFO: Iter: 55950, Loss: 0.573, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 21:39:50,000: INFO: Iter: 56000, Loss: 1.090, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:40:14,191: INFO: Iter: 56050, Loss: 0.781, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:40:38,530: INFO: Iter: 56100, Loss: 0.891, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:41:02,618: INFO: Iter: 56150, Loss: 0.667, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:41:26,717: INFO: Iter: 56200, Loss: 0.883, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:41:50,742: INFO: Iter: 56250, Loss: 0.728, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:42:14,615: INFO: Iter: 56300, Loss: 0.790, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:42:38,791: INFO: Iter: 56350, Loss: 0.995, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:43:02,838: INFO: Iter: 56400, Loss: 1.371, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:43:26,708: INFO: Iter: 56450, Loss: 1.471, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 21:43:50,771: INFO: Iter: 56500, Loss: 0.781, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:44:14,666: INFO: Iter: 56550, Loss: 0.932, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:44:38,376: INFO: Iter: 56600, Loss: 1.057, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:45:02,491: INFO: Iter: 56650, Loss: 1.221, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 21:45:26,372: INFO: Iter: 56700, Loss: 0.718, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:45:50,393: INFO: Iter: 56750, Loss: 1.155, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:46:14,297: INFO: Iter: 56800, Loss: 0.775, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:46:38,280: INFO: Iter: 56850, Loss: 0.562, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 21:47:02,290: INFO: Iter: 56900, Loss: 0.688, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:47:26,174: INFO: Iter: 56950, Loss: 0.900, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:47:50,314: INFO: Iter: 57000, Loss: 0.880, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:48:13,938: INFO: Iter: 57050, Loss: 0.782, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:48:37,926: INFO: Iter: 57100, Loss: 1.380, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 21:49:01,816: INFO: Iter: 57150, Loss: 0.621, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:49:25,714: INFO: Iter: 57200, Loss: 0.848, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:49:49,687: INFO: Iter: 57250, Loss: 0.551, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:50:13,778: INFO: Iter: 57300, Loss: 0.634, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:50:37,583: INFO: Iter: 57350, Loss: 1.172, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:51:01,741: INFO: Iter: 57400, Loss: 0.411, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 21:51:25,951: INFO: Iter: 57450, Loss: 0.879, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:51:49,641: INFO: Iter: 57500, Loss: 0.730, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:52:13,474: INFO: Iter: 57550, Loss: 0.947, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:52:37,234: INFO: Iter: 57600, Loss: 0.294, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 21:53:01,110: INFO: Iter: 57650, Loss: 0.599, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 21:53:24,948: INFO: Iter: 57700, Loss: 0.999, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:53:48,693: INFO: Iter: 57750, Loss: 0.881, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:54:12,524: INFO: Iter: 57800, Loss: 0.819, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:54:36,614: INFO: Iter: 57850, Loss: 0.592, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:55:00,686: INFO: Iter: 57900, Loss: 1.077, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 21:55:24,616: INFO: Iter: 57950, Loss: 0.734, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:55:48,818: INFO: Iter: 58000, Loss: 0.511, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 21:56:12,717: INFO: Iter: 58050, Loss: 0.899, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:56:36,839: INFO: Iter: 58100, Loss: 0.541, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:57:00,800: INFO: Iter: 58150, Loss: 0.907, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 21:57:24,660: INFO: Iter: 58200, Loss: 0.734, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:57:48,906: INFO: Iter: 58250, Loss: 0.634, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:58:13,090: INFO: Iter: 58300, Loss: 0.390, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 21:58:36,914: INFO: Iter: 58350, Loss: 0.482, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 21:59:01,108: INFO: Iter: 58400, Loss: 0.675, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 21:59:25,010: INFO: Iter: 58450, Loss: 0.688, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 21:59:48,820: INFO: Iter: 58500, Loss: 0.742, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:00:12,719: INFO: Iter: 58550, Loss: 0.937, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 22:00:36,733: INFO: Iter: 58600, Loss: 0.720, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:01:00,534: INFO: Iter: 58650, Loss: 0.499, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:01:24,587: INFO: Iter: 58700, Loss: 0.419, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:01:48,667: INFO: Iter: 58750, Loss: 0.339, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:02:12,628: INFO: Iter: 58800, Loss: 0.430, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:02:36,677: INFO: Iter: 58850, Loss: 0.552, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:03:00,838: INFO: Iter: 58900, Loss: 0.339, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:03:25,023: INFO: Iter: 58950, Loss: 0.591, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:03:48,868: INFO: Iter: 59000, Loss: 0.666, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:04:12,748: INFO: Iter: 59050, Loss: 0.318, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:04:36,724: INFO: Iter: 59100, Loss: 0.444, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:05:00,872: INFO: Iter: 59150, Loss: 0.435, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:05:24,987: INFO: Iter: 59200, Loss: 0.491, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:05:48,673: INFO: Iter: 59250, Loss: 0.467, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:06:12,644: INFO: Iter: 59300, Loss: 0.392, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:06:36,463: INFO: Iter: 59350, Loss: 0.735, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:07:00,394: INFO: Iter: 59400, Loss: 0.528, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:07:24,443: INFO: Iter: 59450, Loss: 0.264, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:07:48,493: INFO: Iter: 59500, Loss: 0.644, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:08:12,672: INFO: Iter: 59550, Loss: 0.286, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:08:36,765: INFO: Iter: 59600, Loss: 0.445, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:09:00,688: INFO: Iter: 59650, Loss: 0.529, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:09:24,609: INFO: Iter: 59700, Loss: 0.709, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:09:48,803: INFO: Iter: 59750, Loss: 1.508, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 22:10:12,695: INFO: Iter: 59800, Loss: 0.520, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:10:36,446: INFO: Iter: 59850, Loss: 0.554, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:11:00,533: INFO: Iter: 59900, Loss: 0.852, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 22:11:24,545: INFO: Iter: 59950, Loss: 0.801, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:11:48,316: INFO: Iter: 60000, Loss: 0.487, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:12:11,917: INFO: Iter: 60050, Loss: 0.387, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:12:35,723: INFO: Iter: 60100, Loss: 0.230, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:12:59,659: INFO: Iter: 60150, Loss: 0.430, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:13:23,699: INFO: Iter: 60200, Loss: 0.552, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:13:47,822: INFO: Iter: 60250, Loss: 0.562, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:14:11,848: INFO: Iter: 60300, Loss: 0.536, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:14:35,951: INFO: Iter: 60350, Loss: 0.640, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:15:00,047: INFO: Iter: 60400, Loss: 0.928, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:15:24,313: INFO: Iter: 60450, Loss: 0.354, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:15:48,622: INFO: Iter: 60500, Loss: 0.571, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:16:12,809: INFO: Iter: 60550, Loss: 0.516, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:16:36,602: INFO: Iter: 60600, Loss: 0.456, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:17:00,955: INFO: Iter: 60650, Loss: 0.845, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:17:24,793: INFO: Iter: 60700, Loss: 0.194, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:17:48,897: INFO: Iter: 60750, Loss: 0.723, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:18:12,862: INFO: Iter: 60800, Loss: 0.472, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:18:36,570: INFO: Iter: 60850, Loss: 0.920, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:19:00,618: INFO: Iter: 60900, Loss: 0.857, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:19:24,629: INFO: Iter: 60950, Loss: 0.634, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:19:48,467: INFO: Iter: 61000, Loss: 0.480, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:20:12,712: INFO: Iter: 61050, Loss: 0.696, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:20:36,619: INFO: Iter: 61100, Loss: 0.964, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:21:00,742: INFO: Iter: 61150, Loss: 0.636, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:21:24,472: INFO: Iter: 61200, Loss: 0.474, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:21:48,678: INFO: Iter: 61250, Loss: 0.322, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:22:12,702: INFO: Iter: 61300, Loss: 0.650, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:22:36,698: INFO: Iter: 61350, Loss: 0.548, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:23:00,533: INFO: Iter: 61400, Loss: 0.476, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:23:24,520: INFO: Iter: 61450, Loss: 0.476, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:23:48,769: INFO: Iter: 61500, Loss: 0.804, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 22:24:12,732: INFO: Iter: 61550, Loss: 0.710, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:24:36,747: INFO: Iter: 61600, Loss: 0.547, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:25:00,820: INFO: Iter: 61650, Loss: 0.870, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:25:24,825: INFO: Iter: 61700, Loss: 0.241, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:25:48,768: INFO: Iter: 61750, Loss: 0.306, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:26:13,759: INFO: Iter: 61800, Loss: 0.403, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:26:38,355: INFO: Iter: 61850, Loss: 0.749, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:27:03,084: INFO: Iter: 61900, Loss: 0.287, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:27:27,360: INFO: Iter: 61950, Loss: 0.758, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:27:51,648: INFO: Iter: 62000, Loss: 0.502, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:28:15,661: INFO: Iter: 62050, Loss: 0.552, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:28:39,612: INFO: Iter: 62100, Loss: 0.539, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:29:03,445: INFO: Iter: 62150, Loss: 0.529, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:29:27,395: INFO: Iter: 62200, Loss: 0.587, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:29:51,146: INFO: Iter: 62250, Loss: 0.181, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:30:14,958: INFO: Iter: 62300, Loss: 0.171, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:30:38,744: INFO: Iter: 62350, Loss: 0.843, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 22:31:02,619: INFO: Iter: 62400, Loss: 0.528, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:31:26,356: INFO: Iter: 62450, Loss: 0.543, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:31:50,133: INFO: Iter: 62500, Loss: 0.264, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:32:13,817: INFO: Iter: 62550, Loss: 0.322, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:32:37,444: INFO: Iter: 62600, Loss: 0.626, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:33:01,245: INFO: Iter: 62650, Loss: 1.138, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:33:25,033: INFO: Iter: 62700, Loss: 1.075, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:33:48,706: INFO: Iter: 62750, Loss: 0.937, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:34:12,403: INFO: Iter: 62800, Loss: 0.558, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:34:35,977: INFO: Iter: 62850, Loss: 0.647, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:34:59,700: INFO: Iter: 62900, Loss: 1.079, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:35:23,254: INFO: Iter: 62950, Loss: 0.278, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:35:46,887: INFO: Iter: 63000, Loss: 0.959, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 22:36:10,534: INFO: Iter: 63050, Loss: 0.496, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:36:34,418: INFO: Iter: 63100, Loss: 0.445, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:36:58,428: INFO: Iter: 63150, Loss: 0.481, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:37:22,038: INFO: Iter: 63200, Loss: 0.536, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:37:45,705: INFO: Iter: 63250, Loss: 0.487, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:38:09,704: INFO: Iter: 63300, Loss: 0.823, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:38:33,464: INFO: Iter: 63350, Loss: 0.396, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:38:57,350: INFO: Iter: 63400, Loss: 0.363, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:39:21,084: INFO: Iter: 63450, Loss: 0.363, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:39:44,804: INFO: Iter: 63500, Loss: 0.612, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:40:08,559: INFO: Iter: 63550, Loss: 0.457, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:40:31,471: INFO: Iter: 63600, Loss: 0.360, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:40:55,294: INFO: Iter: 63650, Loss: 0.629, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:41:19,247: INFO: Iter: 63700, Loss: 0.121, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:41:43,084: INFO: Iter: 63750, Loss: 0.334, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:42:06,842: INFO: Iter: 63800, Loss: 0.544, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:42:30,564: INFO: Iter: 63850, Loss: 0.298, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:42:54,275: INFO: Iter: 63900, Loss: 0.794, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:43:17,912: INFO: Iter: 63950, Loss: 0.428, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:43:41,575: INFO: Iter: 64000, Loss: 0.403, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:44:05,123: INFO: Iter: 64050, Loss: 0.352, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:44:28,994: INFO: Iter: 64100, Loss: 0.213, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:44:52,578: INFO: Iter: 64150, Loss: 0.583, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:45:16,492: INFO: Iter: 64200, Loss: 0.593, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:45:40,084: INFO: Iter: 64250, Loss: 0.436, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:46:03,887: INFO: Iter: 64300, Loss: 0.388, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:46:27,745: INFO: Iter: 64350, Loss: 0.446, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:46:51,181: INFO: Iter: 64400, Loss: 0.655, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:47:15,002: INFO: Iter: 64450, Loss: 0.377, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:47:38,776: INFO: Iter: 64500, Loss: 0.269, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:48:02,693: INFO: Iter: 64550, Loss: 0.742, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:48:26,503: INFO: Iter: 64600, Loss: 0.288, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:48:50,185: INFO: Iter: 64650, Loss: 0.164, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:49:13,912: INFO: Iter: 64700, Loss: 0.299, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:49:37,580: INFO: Iter: 64750, Loss: 0.085, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:50:01,465: INFO: Iter: 64800, Loss: 0.603, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:50:25,057: INFO: Iter: 64850, Loss: 0.208, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:50:48,809: INFO: Iter: 64900, Loss: 0.465, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:51:12,306: INFO: Iter: 64950, Loss: 0.194, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:51:35,988: INFO: Iter: 65000, Loss: 0.191, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:51:59,661: INFO: Iter: 65050, Loss: 0.148, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:52:23,379: INFO: Iter: 65100, Loss: 0.396, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:52:47,076: INFO: Iter: 65150, Loss: 0.478, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:53:10,880: INFO: Iter: 65200, Loss: 0.122, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:53:34,378: INFO: Iter: 65250, Loss: 0.310, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:53:58,311: INFO: Iter: 65300, Loss: 0.355, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:54:21,913: INFO: Iter: 65350, Loss: 0.281, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:54:45,492: INFO: Iter: 65400, Loss: 0.612, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:55:09,364: INFO: Iter: 65450, Loss: 0.694, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:55:33,090: INFO: Iter: 65500, Loss: 0.486, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:55:56,862: INFO: Iter: 65550, Loss: 0.209, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 22:56:20,625: INFO: Iter: 65600, Loss: 0.780, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 22:56:44,541: INFO: Iter: 65650, Loss: 0.454, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 22:57:07,928: INFO: Iter: 65700, Loss: 1.353, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 22:57:31,624: INFO: Iter: 65750, Loss: 1.406, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 22:57:55,245: INFO: Iter: 65800, Loss: 1.226, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 22:58:18,672: INFO: Iter: 65850, Loss: 1.588, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 22:58:42,503: INFO: Iter: 65900, Loss: 1.174, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 22:59:06,461: INFO: Iter: 65950, Loss: 1.692, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 22:59:30,215: INFO: Iter: 66000, Loss: 1.197, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 22:59:53,913: INFO: Iter: 66050, Loss: 1.181, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 23:00:17,701: INFO: Iter: 66100, Loss: 2.724, Accuracy: 0.000, Learning Rate: 0.001
2017-10-14 23:00:41,557: INFO: Iter: 66150, Loss: 0.600, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 23:01:05,329: INFO: Iter: 66200, Loss: 0.430, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 23:01:28,898: INFO: Iter: 66250, Loss: 1.353, Accuracy: 0.200, Learning Rate: 0.001
2017-10-14 23:01:52,824: INFO: Iter: 66300, Loss: 0.924, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 23:02:16,652: INFO: Iter: 66350, Loss: 0.909, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 23:02:40,035: INFO: Iter: 66400, Loss: 0.460, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 23:03:03,713: INFO: Iter: 66450, Loss: 1.131, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 23:03:27,554: INFO: Iter: 66500, Loss: 0.895, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 23:03:51,176: INFO: Iter: 66550, Loss: 1.090, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 23:04:14,710: INFO: Iter: 66600, Loss: 1.335, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 23:04:38,752: INFO: Iter: 66650, Loss: 0.309, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 23:05:02,608: INFO: Iter: 66700, Loss: 1.418, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 23:05:26,508: INFO: Iter: 66750, Loss: 0.463, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 23:05:50,076: INFO: Iter: 66800, Loss: 0.358, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 23:06:13,624: INFO: Iter: 66850, Loss: 0.789, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 23:06:37,294: INFO: Iter: 66900, Loss: 1.151, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 23:07:01,186: INFO: Iter: 66950, Loss: 0.847, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 23:07:24,851: INFO: Iter: 67000, Loss: 0.859, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 23:07:48,898: INFO: Iter: 67050, Loss: 0.547, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 23:08:12,385: INFO: Iter: 67100, Loss: 0.462, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 23:08:36,211: INFO: Iter: 67150, Loss: 0.334, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 23:09:00,138: INFO: Iter: 67200, Loss: 0.164, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 23:09:23,855: INFO: Iter: 67250, Loss: 0.558, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 23:09:47,619: INFO: Iter: 67300, Loss: 0.202, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 23:10:11,256: INFO: Iter: 67350, Loss: 0.252, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 23:10:34,993: INFO: Iter: 67400, Loss: 1.077, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 23:10:59,077: INFO: Iter: 67450, Loss: 1.035, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 23:11:22,757: INFO: Iter: 67500, Loss: 0.674, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 23:11:46,612: INFO: Iter: 67550, Loss: 0.700, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 23:12:10,308: INFO: Iter: 67600, Loss: 0.795, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 23:12:33,797: INFO: Iter: 67650, Loss: 0.426, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 23:12:57,731: INFO: Iter: 67700, Loss: 0.376, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 23:13:21,230: INFO: Iter: 67750, Loss: 0.677, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 23:13:44,682: INFO: Iter: 67800, Loss: 0.791, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 23:14:08,162: INFO: Iter: 67850, Loss: 0.473, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 23:14:31,850: INFO: Iter: 67900, Loss: 1.198, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 23:14:55,600: INFO: Iter: 67950, Loss: 0.521, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 23:15:19,368: INFO: Iter: 68000, Loss: 0.219, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 23:15:43,246: INFO: Iter: 68050, Loss: 0.928, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 23:16:06,974: INFO: Iter: 68100, Loss: 0.774, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 23:16:30,693: INFO: Iter: 68150, Loss: 0.423, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 23:16:54,596: INFO: Iter: 68200, Loss: 0.675, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 23:17:18,136: INFO: Iter: 68250, Loss: 0.418, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 23:17:41,987: INFO: Iter: 68300, Loss: 0.659, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 23:18:05,850: INFO: Iter: 68350, Loss: 0.295, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 23:18:29,755: INFO: Iter: 68400, Loss: 0.723, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 23:18:53,539: INFO: Iter: 68450, Loss: 0.369, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 23:19:17,104: INFO: Iter: 68500, Loss: 0.859, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 23:19:40,896: INFO: Iter: 68550, Loss: 0.882, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 23:20:04,828: INFO: Iter: 68600, Loss: 0.358, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 23:20:28,622: INFO: Iter: 68650, Loss: 0.469, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 23:20:52,366: INFO: Iter: 68700, Loss: 0.678, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 23:21:16,109: INFO: Iter: 68750, Loss: 0.718, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 23:21:39,055: INFO: Iter: 68800, Loss: 0.592, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 23:22:02,397: INFO: Iter: 68850, Loss: 0.326, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 23:22:26,751: INFO: Iter: 68900, Loss: 0.175, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 23:22:51,105: INFO: Iter: 68950, Loss: 0.463, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 23:23:14,844: INFO: Iter: 69000, Loss: 0.227, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 23:23:38,641: INFO: Iter: 69050, Loss: 0.362, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 23:24:02,233: INFO: Iter: 69100, Loss: 0.343, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 23:24:26,093: INFO: Iter: 69150, Loss: 0.860, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 23:24:49,850: INFO: Iter: 69200, Loss: 1.050, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 23:25:13,672: INFO: Iter: 69250, Loss: 0.500, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 23:25:37,493: INFO: Iter: 69300, Loss: 0.538, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 23:26:01,269: INFO: Iter: 69350, Loss: 0.282, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 23:26:24,921: INFO: Iter: 69400, Loss: 0.658, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 23:26:48,643: INFO: Iter: 69450, Loss: 0.131, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 23:27:12,231: INFO: Iter: 69500, Loss: 0.445, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 23:27:35,808: INFO: Iter: 69550, Loss: 0.197, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 23:27:59,584: INFO: Iter: 69600, Loss: 0.448, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 23:28:23,300: INFO: Iter: 69650, Loss: 0.325, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 23:28:46,897: INFO: Iter: 69700, Loss: 0.184, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 23:29:10,193: INFO: Iter: 69750, Loss: 0.362, Accuracy: 0.800, Learning Rate: 0.001
2017-10-14 23:29:34,992: INFO: Iter: 69800, Loss: 0.547, Accuracy: 0.600, Learning Rate: 0.001
2017-10-14 23:29:59,898: INFO: Iter: 69850, Loss: 0.977, Accuracy: 0.400, Learning Rate: 0.001
2017-10-14 23:30:24,475: INFO: Iter: 69900, Loss: 0.273, Accuracy: 1.000, Learning Rate: 0.001
2017-10-14 23:30:48,798: INFO: Iter: 69950, Loss: 0.159, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 12:29:01,374: INFO: Iter: 70000, Loss: 0.432, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 12:29:30,844: INFO: Iter: 70050, Loss: 0.374, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 12:36:16,599: INFO: Iter: 70100, Loss: 0.314, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 12:36:57,422: INFO: Iter: 70150, Loss: 0.133, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 12:37:28,413: INFO: Iter: 70200, Loss: 0.584, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 12:37:59,443: INFO: Iter: 70250, Loss: 0.240, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 12:38:30,508: INFO: Iter: 70300, Loss: 0.709, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 12:39:01,313: INFO: Iter: 70350, Loss: 0.498, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 12:39:32,439: INFO: Iter: 70400, Loss: 0.171, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 12:40:04,036: INFO: Iter: 70450, Loss: 0.666, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 12:40:35,170: INFO: Iter: 70500, Loss: 0.818, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 12:41:06,402: INFO: Iter: 70550, Loss: 0.235, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 12:41:37,474: INFO: Iter: 70600, Loss: 0.740, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 12:42:08,863: INFO: Iter: 70650, Loss: 0.298, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 12:42:40,378: INFO: Iter: 70700, Loss: 0.422, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 12:43:11,899: INFO: Iter: 70750, Loss: 0.405, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 12:43:43,636: INFO: Iter: 70800, Loss: 0.219, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 12:44:14,759: INFO: Iter: 70850, Loss: 0.224, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 12:44:46,684: INFO: Iter: 70900, Loss: 0.633, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 12:45:18,253: INFO: Iter: 70950, Loss: 0.275, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 12:45:50,100: INFO: Iter: 71000, Loss: 0.389, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 12:46:21,600: INFO: Iter: 71050, Loss: 0.080, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 12:47:13,198: INFO: Iter: 71100, Loss: 0.137, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 12:48:13,534: INFO: Iter: 71150, Loss: 0.223, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 12:48:48,621: INFO: Iter: 71200, Loss: 0.357, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 12:50:01,820: INFO: Iter: 71250, Loss: 0.328, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 12:51:01,004: INFO: Iter: 71300, Loss: 0.106, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 12:51:56,655: INFO: Iter: 71350, Loss: 0.798, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 12:53:17,192: INFO: Iter: 71400, Loss: 0.317, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 12:54:23,145: INFO: Iter: 71450, Loss: 0.492, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 12:55:35,637: INFO: Iter: 71500, Loss: 0.356, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 12:56:55,223: INFO: Iter: 71550, Loss: 0.376, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 12:58:14,839: INFO: Iter: 71600, Loss: 0.381, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 12:59:34,567: INFO: Iter: 71650, Loss: 0.287, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 13:00:54,438: INFO: Iter: 71700, Loss: 0.484, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 13:02:14,407: INFO: Iter: 71750, Loss: 0.508, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 13:03:33,744: INFO: Iter: 71800, Loss: 0.334, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 13:04:53,474: INFO: Iter: 71850, Loss: 0.338, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 13:17:56,826: INFO: Iter: 71900, Loss: 0.683, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 13:18:25,851: INFO: Iter: 71950, Loss: 0.257, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 13:18:57,218: INFO: Iter: 72000, Loss: 0.445, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 13:19:28,358: INFO: Iter: 72050, Loss: 0.408, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 13:19:59,868: INFO: Iter: 72100, Loss: 0.466, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 13:20:31,338: INFO: Iter: 72150, Loss: 0.341, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 13:51:08,636: INFO: Iter: 72200, Loss: 0.131, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 13:51:38,513: INFO: Iter: 72250, Loss: 0.108, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 13:52:10,324: INFO: Iter: 72300, Loss: 0.524, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 13:52:41,945: INFO: Iter: 72350, Loss: 0.251, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 13:53:13,401: INFO: Iter: 72400, Loss: 0.507, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 13:53:44,868: INFO: Iter: 72450, Loss: 1.023, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 13:54:16,352: INFO: Iter: 72500, Loss: 0.117, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 13:54:48,259: INFO: Iter: 72550, Loss: 0.496, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 13:55:19,966: INFO: Iter: 72600, Loss: 0.973, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 13:56:19,538: INFO: Iter: 72650, Loss: 0.398, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 13:57:37,930: INFO: Iter: 72700, Loss: 0.449, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 13:58:58,152: INFO: Iter: 72750, Loss: 0.453, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 14:00:06,314: INFO: Iter: 72800, Loss: 0.635, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 14:00:59,381: INFO: Iter: 72850, Loss: 0.862, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 14:02:20,222: INFO: Iter: 72900, Loss: 0.867, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 14:03:39,730: INFO: Iter: 72950, Loss: 0.644, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 14:04:47,188: INFO: Iter: 73000, Loss: 0.289, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 14:06:07,160: INFO: Iter: 73050, Loss: 0.732, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 14:07:27,389: INFO: Iter: 73100, Loss: 0.838, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 14:08:46,198: INFO: Iter: 73150, Loss: 0.448, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 14:10:05,092: INFO: Iter: 73200, Loss: 0.509, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 14:11:25,069: INFO: Iter: 73250, Loss: 0.462, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 14:12:44,001: INFO: Iter: 73300, Loss: 0.625, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 14:14:03,774: INFO: Iter: 73350, Loss: 0.458, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 14:15:22,335: INFO: Iter: 73400, Loss: 0.727, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 14:16:42,669: INFO: Iter: 73450, Loss: 0.533, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 14:18:02,518: INFO: Iter: 73500, Loss: 1.342, Accuracy: 0.000, Learning Rate: 0.001
2017-10-15 14:19:22,442: INFO: Iter: 73550, Loss: 0.685, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 14:20:42,305: INFO: Iter: 73600, Loss: 0.339, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 14:27:47,576: INFO: Iter: 73650, Loss: 0.345, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 14:28:17,892: INFO: Iter: 73700, Loss: 1.252, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 14:28:50,078: INFO: Iter: 73750, Loss: 0.382, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 14:29:21,972: INFO: Iter: 73800, Loss: 0.495, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 14:29:53,611: INFO: Iter: 73850, Loss: 0.430, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 14:30:25,331: INFO: Iter: 73900, Loss: 0.207, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 14:30:57,324: INFO: Iter: 73950, Loss: 0.315, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 14:32:12,103: INFO: Iter: 74000, Loss: 0.532, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 14:33:31,050: INFO: Iter: 74050, Loss: 0.287, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 14:34:51,059: INFO: Iter: 74100, Loss: 0.265, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 14:36:10,490: INFO: Iter: 74150, Loss: 0.971, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 14:37:29,851: INFO: Iter: 74200, Loss: 0.318, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 14:38:49,896: INFO: Iter: 74250, Loss: 0.358, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 14:40:10,220: INFO: Iter: 74300, Loss: 0.602, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 14:41:30,727: INFO: Iter: 74350, Loss: 0.410, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 14:42:50,563: INFO: Iter: 74400, Loss: 0.272, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 14:44:08,954: INFO: Iter: 74450, Loss: 0.750, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 14:45:28,320: INFO: Iter: 74500, Loss: 0.269, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 14:46:46,701: INFO: Iter: 74550, Loss: 0.502, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 14:48:06,274: INFO: Iter: 74600, Loss: 1.012, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 14:49:25,758: INFO: Iter: 74650, Loss: 0.232, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 14:50:44,347: INFO: Iter: 74700, Loss: 1.068, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 14:52:04,183: INFO: Iter: 74750, Loss: 0.297, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 14:53:24,345: INFO: Iter: 74800, Loss: 0.551, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 14:54:43,628: INFO: Iter: 74850, Loss: 1.296, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 14:56:03,307: INFO: Iter: 74900, Loss: 1.257, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 14:57:22,808: INFO: Iter: 74950, Loss: 2.195, Accuracy: 0.000, Learning Rate: 0.001
2017-10-15 15:07:11,898: INFO: Iter: 75000, Loss: 1.271, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:07:43,611: INFO: Iter: 75050, Loss: 1.171, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:08:14,874: INFO: Iter: 75100, Loss: 0.893, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:08:46,012: INFO: Iter: 75150, Loss: 1.664, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:09:17,614: INFO: Iter: 75200, Loss: 1.768, Accuracy: 0.000, Learning Rate: 0.001
2017-10-15 15:09:49,117: INFO: Iter: 75250, Loss: 1.087, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:10:20,928: INFO: Iter: 75300, Loss: 0.490, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 15:11:20,622: INFO: Iter: 75350, Loss: 0.769, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 15:12:40,644: INFO: Iter: 75400, Loss: 1.340, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:13:45,825: INFO: Iter: 75450, Loss: 1.564, Accuracy: 0.000, Learning Rate: 0.001
2017-10-15 15:14:11,592: INFO: Iter: 75500, Loss: 1.418, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:14:36,620: INFO: Iter: 75550, Loss: 1.248, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:15:00,941: INFO: Iter: 75600, Loss: 0.832, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:15:25,740: INFO: Iter: 75650, Loss: 1.133, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:15:50,316: INFO: Iter: 75700, Loss: 1.162, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:16:14,830: INFO: Iter: 75750, Loss: 1.442, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:16:39,938: INFO: Iter: 75800, Loss: 1.224, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:17:04,776: INFO: Iter: 75850, Loss: 1.196, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:17:29,859: INFO: Iter: 75900, Loss: 1.315, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:17:55,016: INFO: Iter: 75950, Loss: 0.894, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:18:20,233: INFO: Iter: 76000, Loss: 1.104, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:18:45,384: INFO: Iter: 76050, Loss: 1.066, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:19:10,453: INFO: Iter: 76100, Loss: 1.234, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:19:35,073: INFO: Iter: 76150, Loss: 1.439, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:19:59,301: INFO: Iter: 76200, Loss: 1.746, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:20:23,596: INFO: Iter: 76250, Loss: 0.588, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 15:20:47,676: INFO: Iter: 76300, Loss: 1.349, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:21:11,516: INFO: Iter: 76350, Loss: 0.756, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 15:21:35,307: INFO: Iter: 76400, Loss: 0.695, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:21:59,237: INFO: Iter: 76450, Loss: 0.610, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 15:22:23,008: INFO: Iter: 76500, Loss: 1.271, Accuracy: 0.000, Learning Rate: 0.001
2017-10-15 15:22:47,009: INFO: Iter: 76550, Loss: 0.713, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 15:23:10,778: INFO: Iter: 76600, Loss: 1.218, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:23:34,785: INFO: Iter: 76650, Loss: 0.919, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:23:58,888: INFO: Iter: 76700, Loss: 0.742, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:24:22,745: INFO: Iter: 76750, Loss: 1.028, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:24:46,670: INFO: Iter: 76800, Loss: 0.889, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:25:10,805: INFO: Iter: 76850, Loss: 1.249, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:25:34,810: INFO: Iter: 76900, Loss: 1.701, Accuracy: 0.000, Learning Rate: 0.001
2017-10-15 15:25:58,748: INFO: Iter: 76950, Loss: 0.886, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:26:22,847: INFO: Iter: 77000, Loss: 1.108, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:26:46,966: INFO: Iter: 77050, Loss: 0.971, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:27:10,716: INFO: Iter: 77100, Loss: 1.063, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:27:34,907: INFO: Iter: 77150, Loss: 1.247, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:27:58,604: INFO: Iter: 77200, Loss: 1.179, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:28:22,588: INFO: Iter: 77250, Loss: 1.298, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:28:46,702: INFO: Iter: 77300, Loss: 1.051, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:29:10,541: INFO: Iter: 77350, Loss: 1.210, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:29:34,633: INFO: Iter: 77400, Loss: 1.526, Accuracy: 0.000, Learning Rate: 0.001
2017-10-15 15:29:58,493: INFO: Iter: 77450, Loss: 1.504, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:30:22,387: INFO: Iter: 77500, Loss: 1.350, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:30:46,528: INFO: Iter: 77550, Loss: 0.674, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 15:31:10,588: INFO: Iter: 77600, Loss: 1.299, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:31:35,567: INFO: Iter: 77650, Loss: 1.110, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:32:00,165: INFO: Iter: 77700, Loss: 0.852, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:32:25,251: INFO: Iter: 77750, Loss: 0.739, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:32:49,724: INFO: Iter: 77800, Loss: 0.812, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:33:14,504: INFO: Iter: 77850, Loss: 0.803, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:33:39,349: INFO: Iter: 77900, Loss: 1.095, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:34:03,922: INFO: Iter: 77950, Loss: 0.814, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 15:34:28,714: INFO: Iter: 78000, Loss: 0.677, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 15:34:53,403: INFO: Iter: 78050, Loss: 0.766, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 15:35:17,602: INFO: Iter: 78100, Loss: 1.079, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:35:42,210: INFO: Iter: 78150, Loss: 0.817, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:36:06,506: INFO: Iter: 78200, Loss: 0.934, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:36:30,894: INFO: Iter: 78250, Loss: 1.229, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:36:54,947: INFO: Iter: 78300, Loss: 1.328, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:37:20,170: INFO: Iter: 78350, Loss: 0.507, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 15:37:44,387: INFO: Iter: 78400, Loss: 1.149, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:38:09,716: INFO: Iter: 78450, Loss: 0.799, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:38:34,171: INFO: Iter: 78500, Loss: 0.930, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:38:59,654: INFO: Iter: 78550, Loss: 0.632, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 15:39:24,166: INFO: Iter: 78600, Loss: 1.199, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:39:48,437: INFO: Iter: 78650, Loss: 1.088, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:40:12,477: INFO: Iter: 78700, Loss: 0.767, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 15:40:36,443: INFO: Iter: 78750, Loss: 1.043, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:41:01,000: INFO: Iter: 78800, Loss: 1.392, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:41:25,104: INFO: Iter: 78850, Loss: 0.837, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 15:41:49,153: INFO: Iter: 78900, Loss: 0.657, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 15:42:13,177: INFO: Iter: 78950, Loss: 1.033, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:42:37,213: INFO: Iter: 79000, Loss: 1.143, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:43:01,952: INFO: Iter: 79050, Loss: 1.253, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:43:26,652: INFO: Iter: 79100, Loss: 0.952, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:43:51,761: INFO: Iter: 79150, Loss: 0.916, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:44:16,431: INFO: Iter: 79200, Loss: 0.689, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 15:44:40,070: INFO: Iter: 79250, Loss: 0.707, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 15:45:04,171: INFO: Iter: 79300, Loss: 1.203, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:45:28,355: INFO: Iter: 79350, Loss: 1.302, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:45:52,525: INFO: Iter: 79400, Loss: 1.096, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:46:16,417: INFO: Iter: 79450, Loss: 1.231, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:46:40,159: INFO: Iter: 79500, Loss: 1.024, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:47:04,040: INFO: Iter: 79550, Loss: 1.124, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:47:28,087: INFO: Iter: 79600, Loss: 0.867, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:47:51,956: INFO: Iter: 79650, Loss: 1.064, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:48:15,952: INFO: Iter: 79700, Loss: 1.114, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:48:39,967: INFO: Iter: 79750, Loss: 1.023, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:49:03,824: INFO: Iter: 79800, Loss: 0.850, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:49:27,583: INFO: Iter: 79850, Loss: 1.153, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:49:51,908: INFO: Iter: 79900, Loss: 1.333, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:50:16,144: INFO: Iter: 79950, Loss: 0.973, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:50:40,918: INFO: Iter: 80000, Loss: 0.822, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 15:51:05,286: INFO: Iter: 80050, Loss: 1.088, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:51:29,213: INFO: Iter: 80100, Loss: 1.155, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:51:52,956: INFO: Iter: 80150, Loss: 1.339, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:52:17,908: INFO: Iter: 80200, Loss: 1.305, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:52:42,613: INFO: Iter: 80250, Loss: 0.924, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:53:07,028: INFO: Iter: 80300, Loss: 1.625, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:53:31,337: INFO: Iter: 80350, Loss: 1.072, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 15:53:55,536: INFO: Iter: 80400, Loss: 1.211, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:54:19,934: INFO: Iter: 80450, Loss: 1.247, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:54:44,216: INFO: Iter: 80500, Loss: 1.337, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:55:08,474: INFO: Iter: 80550, Loss: 1.091, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:55:32,334: INFO: Iter: 80600, Loss: 1.168, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:55:56,821: INFO: Iter: 80650, Loss: 0.664, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 15:56:21,373: INFO: Iter: 80700, Loss: 0.917, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:56:45,295: INFO: Iter: 80750, Loss: 1.226, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:57:09,602: INFO: Iter: 80800, Loss: 1.129, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:57:33,850: INFO: Iter: 80850, Loss: 0.846, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:57:58,165: INFO: Iter: 80900, Loss: 1.009, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:58:22,596: INFO: Iter: 80950, Loss: 1.288, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 15:58:46,697: INFO: Iter: 81000, Loss: 0.903, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 15:59:10,517: INFO: Iter: 81050, Loss: 1.388, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 15:59:34,450: INFO: Iter: 81100, Loss: 0.810, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 15:59:58,802: INFO: Iter: 81150, Loss: 1.101, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:00:24,193: INFO: Iter: 81200, Loss: 1.233, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:00:49,203: INFO: Iter: 81250, Loss: 1.472, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:01:13,375: INFO: Iter: 81300, Loss: 1.148, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:01:37,598: INFO: Iter: 81350, Loss: 1.441, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:02:01,493: INFO: Iter: 81400, Loss: 0.709, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:02:25,631: INFO: Iter: 81450, Loss: 0.894, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:02:49,611: INFO: Iter: 81500, Loss: 0.756, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:03:12,996: INFO: Iter: 81550, Loss: 0.785, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:03:36,765: INFO: Iter: 81600, Loss: 0.963, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:04:00,539: INFO: Iter: 81650, Loss: 0.650, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 16:04:25,626: INFO: Iter: 81700, Loss: 0.891, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 16:04:50,196: INFO: Iter: 81750, Loss: 1.348, Accuracy: 0.000, Learning Rate: 0.001
2017-10-15 16:05:14,387: INFO: Iter: 81800, Loss: 1.069, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:05:38,026: INFO: Iter: 81850, Loss: 1.024, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:06:01,492: INFO: Iter: 81900, Loss: 1.005, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:06:26,515: INFO: Iter: 81950, Loss: 0.932, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:06:51,348: INFO: Iter: 82000, Loss: 0.965, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:07:15,939: INFO: Iter: 82050, Loss: 0.838, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:07:40,492: INFO: Iter: 82100, Loss: 1.013, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:08:05,627: INFO: Iter: 82150, Loss: 0.685, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 16:08:30,272: INFO: Iter: 82200, Loss: 1.319, Accuracy: 0.000, Learning Rate: 0.001
2017-10-15 16:08:55,072: INFO: Iter: 82250, Loss: 1.304, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 16:09:20,373: INFO: Iter: 82300, Loss: 0.919, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:09:44,941: INFO: Iter: 82350, Loss: 1.262, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:10:08,912: INFO: Iter: 82400, Loss: 0.759, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:10:32,490: INFO: Iter: 82450, Loss: 0.811, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:10:56,250: INFO: Iter: 82500, Loss: 1.245, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:11:20,104: INFO: Iter: 82550, Loss: 0.840, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:11:44,000: INFO: Iter: 82600, Loss: 0.957, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:12:07,735: INFO: Iter: 82650, Loss: 1.118, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 16:12:31,864: INFO: Iter: 82700, Loss: 0.644, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 16:12:55,759: INFO: Iter: 82750, Loss: 0.849, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:13:19,785: INFO: Iter: 82800, Loss: 1.132, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:13:43,526: INFO: Iter: 82850, Loss: 1.120, Accuracy: 0.000, Learning Rate: 0.001
2017-10-15 16:14:07,493: INFO: Iter: 82900, Loss: 1.343, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:14:31,530: INFO: Iter: 82950, Loss: 0.904, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:14:55,295: INFO: Iter: 83000, Loss: 0.495, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 16:15:19,454: INFO: Iter: 83050, Loss: 1.082, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 16:15:43,405: INFO: Iter: 83100, Loss: 0.875, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 16:16:07,537: INFO: Iter: 83150, Loss: 1.128, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 16:16:31,285: INFO: Iter: 83200, Loss: 0.885, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:16:55,183: INFO: Iter: 83250, Loss: 1.127, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 16:17:19,225: INFO: Iter: 83300, Loss: 1.265, Accuracy: 0.000, Learning Rate: 0.001
2017-10-15 16:17:43,017: INFO: Iter: 83350, Loss: 0.814, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:18:06,285: INFO: Iter: 83400, Loss: 0.807, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 16:18:30,078: INFO: Iter: 83450, Loss: 0.536, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 16:18:53,906: INFO: Iter: 83500, Loss: 1.019, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 16:19:17,963: INFO: Iter: 83550, Loss: 1.370, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:19:42,043: INFO: Iter: 83600, Loss: 1.214, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:20:05,639: INFO: Iter: 83650, Loss: 1.054, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:20:29,702: INFO: Iter: 83700, Loss: 1.342, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 16:20:53,818: INFO: Iter: 83750, Loss: 1.139, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:21:17,706: INFO: Iter: 83800, Loss: 0.610, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 16:21:41,766: INFO: Iter: 83850, Loss: 0.980, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:22:05,386: INFO: Iter: 83900, Loss: 0.885, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:22:29,169: INFO: Iter: 83950, Loss: 0.763, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 16:22:53,354: INFO: Iter: 84000, Loss: 1.015, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:23:17,567: INFO: Iter: 84050, Loss: 0.976, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:23:42,828: INFO: Iter: 84100, Loss: 0.947, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:24:07,594: INFO: Iter: 84150, Loss: 0.949, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:24:31,325: INFO: Iter: 84200, Loss: 0.879, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:24:55,310: INFO: Iter: 84250, Loss: 0.740, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:25:19,739: INFO: Iter: 84300, Loss: 1.358, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 16:25:43,471: INFO: Iter: 84350, Loss: 0.847, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:26:07,961: INFO: Iter: 84400, Loss: 1.011, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:26:32,991: INFO: Iter: 84450, Loss: 1.040, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:26:56,734: INFO: Iter: 84500, Loss: 0.877, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:27:21,214: INFO: Iter: 84550, Loss: 0.679, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 16:27:45,186: INFO: Iter: 84600, Loss: 1.495, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:28:09,286: INFO: Iter: 84650, Loss: 0.969, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:28:34,106: INFO: Iter: 84700, Loss: 0.953, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:28:58,645: INFO: Iter: 84750, Loss: 1.315, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:29:23,241: INFO: Iter: 84800, Loss: 0.797, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:29:47,867: INFO: Iter: 84850, Loss: 1.123, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 16:30:13,245: INFO: Iter: 84900, Loss: 0.761, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:30:38,598: INFO: Iter: 84950, Loss: 1.009, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:31:03,210: INFO: Iter: 85000, Loss: 1.044, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:31:28,088: INFO: Iter: 85050, Loss: 1.009, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:31:53,134: INFO: Iter: 85100, Loss: 1.154, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:32:18,036: INFO: Iter: 85150, Loss: 0.825, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:32:43,040: INFO: Iter: 85200, Loss: 1.027, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:33:07,957: INFO: Iter: 85250, Loss: 0.872, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:33:32,855: INFO: Iter: 85300, Loss: 1.108, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:33:57,186: INFO: Iter: 85350, Loss: 1.068, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:34:21,887: INFO: Iter: 85400, Loss: 0.943, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:34:44,304: INFO: Iter: 85450, Loss: 0.673, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 16:35:06,294: INFO: Iter: 85500, Loss: 0.985, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:35:30,719: INFO: Iter: 85550, Loss: 1.018, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 16:35:55,171: INFO: Iter: 85600, Loss: 1.158, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:36:19,417: INFO: Iter: 85650, Loss: 0.880, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:36:44,101: INFO: Iter: 85700, Loss: 1.173, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 16:37:08,388: INFO: Iter: 85750, Loss: 0.814, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 16:37:32,659: INFO: Iter: 85800, Loss: 0.948, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:37:56,440: INFO: Iter: 85850, Loss: 1.043, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 16:38:21,206: INFO: Iter: 85900, Loss: 0.761, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:38:45,152: INFO: Iter: 85950, Loss: 0.799, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:39:10,245: INFO: Iter: 86000, Loss: 1.083, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:39:34,883: INFO: Iter: 86050, Loss: 1.216, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 16:39:59,580: INFO: Iter: 86100, Loss: 0.769, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 16:40:24,566: INFO: Iter: 86150, Loss: 0.767, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:40:49,051: INFO: Iter: 86200, Loss: 1.164, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 16:41:12,972: INFO: Iter: 86250, Loss: 1.057, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:41:36,898: INFO: Iter: 86300, Loss: 1.619, Accuracy: 0.000, Learning Rate: 0.001
2017-10-15 16:42:00,571: INFO: Iter: 86350, Loss: 0.867, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:42:24,761: INFO: Iter: 86400, Loss: 1.011, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:42:49,466: INFO: Iter: 86450, Loss: 0.713, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 16:43:14,647: INFO: Iter: 86500, Loss: 0.803, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:43:39,237: INFO: Iter: 86550, Loss: 0.937, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:44:03,524: INFO: Iter: 86600, Loss: 1.051, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 16:44:27,692: INFO: Iter: 86650, Loss: 0.635, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 16:44:52,750: INFO: Iter: 86700, Loss: 1.107, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 16:45:17,349: INFO: Iter: 86750, Loss: 1.315, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:45:41,908: INFO: Iter: 86800, Loss: 0.842, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:46:05,993: INFO: Iter: 86850, Loss: 0.607, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 16:46:29,612: INFO: Iter: 86900, Loss: 1.153, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 16:46:53,553: INFO: Iter: 86950, Loss: 0.990, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:47:17,491: INFO: Iter: 87000, Loss: 1.467, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:47:41,235: INFO: Iter: 87050, Loss: 0.823, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:48:04,771: INFO: Iter: 87100, Loss: 0.922, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 16:48:28,578: INFO: Iter: 87150, Loss: 1.212, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:48:52,194: INFO: Iter: 87200, Loss: 0.836, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:49:16,020: INFO: Iter: 87250, Loss: 1.277, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:49:39,591: INFO: Iter: 87300, Loss: 1.087, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:50:03,297: INFO: Iter: 87350, Loss: 1.133, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 16:50:26,636: INFO: Iter: 87400, Loss: 0.984, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:50:50,210: INFO: Iter: 87450, Loss: 0.910, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 16:51:13,885: INFO: Iter: 87500, Loss: 1.055, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 16:51:37,653: INFO: Iter: 87550, Loss: 0.735, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:52:01,546: INFO: Iter: 87600, Loss: 0.885, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:52:25,504: INFO: Iter: 87650, Loss: 0.597, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 16:52:49,524: INFO: Iter: 87700, Loss: 0.886, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:53:13,085: INFO: Iter: 87750, Loss: 0.949, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 16:53:37,102: INFO: Iter: 87800, Loss: 0.822, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:54:00,825: INFO: Iter: 87850, Loss: 1.075, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:54:24,722: INFO: Iter: 87900, Loss: 0.931, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:54:48,758: INFO: Iter: 87950, Loss: 1.280, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:55:12,426: INFO: Iter: 88000, Loss: 0.795, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:55:36,105: INFO: Iter: 88050, Loss: 0.749, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:56:00,211: INFO: Iter: 88100, Loss: 0.645, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 16:56:23,897: INFO: Iter: 88150, Loss: 1.023, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:56:48,200: INFO: Iter: 88200, Loss: 1.007, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 16:57:11,827: INFO: Iter: 88250, Loss: 1.022, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 16:57:35,635: INFO: Iter: 88300, Loss: 1.180, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 16:57:59,999: INFO: Iter: 88350, Loss: 0.853, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:58:23,794: INFO: Iter: 88400, Loss: 1.134, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 16:58:47,692: INFO: Iter: 88450, Loss: 0.985, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 16:59:11,643: INFO: Iter: 88500, Loss: 0.591, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 16:59:35,467: INFO: Iter: 88550, Loss: 0.478, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 16:59:59,133: INFO: Iter: 88600, Loss: 0.785, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:00:22,841: INFO: Iter: 88650, Loss: 0.759, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:00:46,674: INFO: Iter: 88700, Loss: 0.531, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 17:01:10,573: INFO: Iter: 88750, Loss: 0.994, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:01:34,340: INFO: Iter: 88800, Loss: 1.312, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:01:58,534: INFO: Iter: 88850, Loss: 0.662, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:02:22,518: INFO: Iter: 88900, Loss: 0.923, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:02:46,392: INFO: Iter: 88950, Loss: 0.681, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:03:10,611: INFO: Iter: 89000, Loss: 1.479, Accuracy: 0.000, Learning Rate: 0.001
2017-10-15 17:03:34,536: INFO: Iter: 89050, Loss: 1.224, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:03:58,456: INFO: Iter: 89100, Loss: 1.139, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:04:22,310: INFO: Iter: 89150, Loss: 0.828, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:04:46,442: INFO: Iter: 89200, Loss: 0.940, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:05:10,964: INFO: Iter: 89250, Loss: 0.631, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:05:34,488: INFO: Iter: 89300, Loss: 0.768, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:05:58,631: INFO: Iter: 89350, Loss: 1.111, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:06:22,161: INFO: Iter: 89400, Loss: 1.122, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:06:46,029: INFO: Iter: 89450, Loss: 0.923, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:07:10,474: INFO: Iter: 89500, Loss: 1.176, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 17:07:34,820: INFO: Iter: 89550, Loss: 0.617, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:07:58,635: INFO: Iter: 89600, Loss: 0.552, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 17:08:23,053: INFO: Iter: 89650, Loss: 1.123, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:08:46,722: INFO: Iter: 89700, Loss: 0.687, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:09:10,158: INFO: Iter: 89750, Loss: 0.860, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:09:34,269: INFO: Iter: 89800, Loss: 0.979, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:09:57,875: INFO: Iter: 89850, Loss: 1.069, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:10:21,895: INFO: Iter: 89900, Loss: 0.820, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:10:45,579: INFO: Iter: 89950, Loss: 0.612, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:11:09,965: INFO: Iter: 90000, Loss: 0.712, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:11:34,597: INFO: Iter: 90050, Loss: 1.274, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 17:11:58,772: INFO: Iter: 90100, Loss: 0.960, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:12:22,420: INFO: Iter: 90150, Loss: 0.638, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:12:46,289: INFO: Iter: 90200, Loss: 0.840, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:13:09,988: INFO: Iter: 90250, Loss: 0.457, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 17:13:33,221: INFO: Iter: 90300, Loss: 0.818, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:13:56,714: INFO: Iter: 90350, Loss: 0.890, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:14:20,552: INFO: Iter: 90400, Loss: 1.065, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:14:44,337: INFO: Iter: 90450, Loss: 1.167, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:15:08,257: INFO: Iter: 90500, Loss: 0.611, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:15:32,159: INFO: Iter: 90550, Loss: 1.128, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:15:55,788: INFO: Iter: 90600, Loss: 0.648, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:16:19,345: INFO: Iter: 90650, Loss: 0.803, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:16:43,056: INFO: Iter: 90700, Loss: 1.086, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:17:06,866: INFO: Iter: 90750, Loss: 1.039, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 17:17:30,597: INFO: Iter: 90800, Loss: 0.896, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:17:54,423: INFO: Iter: 90850, Loss: 0.938, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:18:18,168: INFO: Iter: 90900, Loss: 1.067, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:18:42,440: INFO: Iter: 90950, Loss: 1.190, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:19:06,343: INFO: Iter: 91000, Loss: 0.974, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:19:30,342: INFO: Iter: 91050, Loss: 0.778, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:19:54,478: INFO: Iter: 91100, Loss: 1.518, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:20:18,429: INFO: Iter: 91150, Loss: 0.701, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:20:42,976: INFO: Iter: 91200, Loss: 0.827, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:21:06,739: INFO: Iter: 91250, Loss: 0.684, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:21:30,882: INFO: Iter: 91300, Loss: 0.863, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:21:55,280: INFO: Iter: 91350, Loss: 0.853, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:22:19,782: INFO: Iter: 91400, Loss: 0.826, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:22:43,697: INFO: Iter: 91450, Loss: 0.706, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:23:07,585: INFO: Iter: 91500, Loss: 0.663, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:23:31,405: INFO: Iter: 91550, Loss: 0.923, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:23:55,472: INFO: Iter: 91600, Loss: 0.550, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 17:24:19,575: INFO: Iter: 91650, Loss: 0.442, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 17:24:44,470: INFO: Iter: 91700, Loss: 0.911, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:25:08,061: INFO: Iter: 91750, Loss: 0.939, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:25:31,846: INFO: Iter: 91800, Loss: 0.882, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:25:55,354: INFO: Iter: 91850, Loss: 0.923, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:26:19,263: INFO: Iter: 91900, Loss: 0.761, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:26:43,129: INFO: Iter: 91950, Loss: 0.701, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:27:06,796: INFO: Iter: 92000, Loss: 0.578, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:27:30,821: INFO: Iter: 92050, Loss: 0.887, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:27:54,943: INFO: Iter: 92100, Loss: 0.659, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:28:19,156: INFO: Iter: 92150, Loss: 0.574, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:28:42,923: INFO: Iter: 92200, Loss: 0.707, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:29:07,322: INFO: Iter: 92250, Loss: 0.596, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:29:31,106: INFO: Iter: 92300, Loss: 0.830, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:29:54,851: INFO: Iter: 92350, Loss: 1.069, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:30:18,606: INFO: Iter: 92400, Loss: 1.053, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:30:42,570: INFO: Iter: 92450, Loss: 1.031, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:31:06,618: INFO: Iter: 92500, Loss: 0.520, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:31:31,200: INFO: Iter: 92550, Loss: 0.664, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:31:56,161: INFO: Iter: 92600, Loss: 0.786, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:32:20,587: INFO: Iter: 92650, Loss: 0.774, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:32:44,969: INFO: Iter: 92700, Loss: 0.457, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:33:09,048: INFO: Iter: 92750, Loss: 1.217, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:33:32,996: INFO: Iter: 92800, Loss: 0.965, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:33:57,148: INFO: Iter: 92850, Loss: 0.968, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:34:21,131: INFO: Iter: 92900, Loss: 0.634, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:34:45,990: INFO: Iter: 92950, Loss: 1.446, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 17:35:10,633: INFO: Iter: 93000, Loss: 0.735, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:35:34,664: INFO: Iter: 93050, Loss: 0.927, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:35:58,489: INFO: Iter: 93100, Loss: 0.973, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:36:22,412: INFO: Iter: 93150, Loss: 1.298, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 17:36:46,520: INFO: Iter: 93200, Loss: 0.496, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 17:37:10,451: INFO: Iter: 93250, Loss: 0.572, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:37:34,123: INFO: Iter: 93300, Loss: 1.308, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 17:37:57,992: INFO: Iter: 93350, Loss: 0.835, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:38:21,780: INFO: Iter: 93400, Loss: 1.020, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 17:38:45,687: INFO: Iter: 93450, Loss: 1.000, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:39:09,596: INFO: Iter: 93500, Loss: 1.163, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:39:33,329: INFO: Iter: 93550, Loss: 1.033, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:39:56,951: INFO: Iter: 93600, Loss: 0.663, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:40:20,991: INFO: Iter: 93650, Loss: 0.555, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:40:45,286: INFO: Iter: 93700, Loss: 1.382, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:41:09,241: INFO: Iter: 93750, Loss: 0.778, Accuracy: 1.000, Learning Rate: 0.001
2017-10-15 17:41:33,134: INFO: Iter: 93800, Loss: 1.076, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:41:56,988: INFO: Iter: 93850, Loss: 0.802, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:42:21,206: INFO: Iter: 93900, Loss: 1.016, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:42:45,607: INFO: Iter: 93950, Loss: 1.029, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:43:09,481: INFO: Iter: 94000, Loss: 0.623, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:43:33,110: INFO: Iter: 94050, Loss: 0.860, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:43:56,543: INFO: Iter: 94100, Loss: 1.032, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:44:19,968: INFO: Iter: 94150, Loss: 0.902, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:44:42,681: INFO: Iter: 94200, Loss: 0.823, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:45:04,030: INFO: Iter: 94250, Loss: 0.767, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:45:27,584: INFO: Iter: 94300, Loss: 0.834, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:45:51,383: INFO: Iter: 94350, Loss: 0.917, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:46:15,227: INFO: Iter: 94400, Loss: 1.098, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:46:39,156: INFO: Iter: 94450, Loss: 1.016, Accuracy: 0.200, Learning Rate: 0.001
2017-10-15 17:47:03,131: INFO: Iter: 94500, Loss: 0.539, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:47:26,951: INFO: Iter: 94550, Loss: 1.231, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:47:50,793: INFO: Iter: 94600, Loss: 0.773, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:48:14,797: INFO: Iter: 94650, Loss: 0.835, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:48:38,560: INFO: Iter: 94700, Loss: 0.512, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:49:02,547: INFO: Iter: 94750, Loss: 0.895, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:49:26,367: INFO: Iter: 94800, Loss: 0.743, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:49:50,766: INFO: Iter: 94850, Loss: 0.867, Accuracy: 0.400, Learning Rate: 0.001
2017-10-15 17:50:15,534: INFO: Iter: 94900, Loss: 0.906, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:50:39,596: INFO: Iter: 94950, Loss: 0.893, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:51:03,996: INFO: Iter: 95000, Loss: 0.664, Accuracy: 0.600, Learning Rate: 0.001
2017-10-15 17:51:28,295: INFO: Iter: 95050, Loss: 0.608, Accuracy: 0.800, Learning Rate: 0.001
2017-10-15 17:51:50,556: INFO: Keyboard Interrupt? Gracefully quitting
2017-10-15 17:51:50,557: INFO: The training is done.

2017-10-15 17:51:53,399: INFO: *** NEW RUN ***
2017-10-15 17:51:53,400: INFO: filename: trained_model_2017.10.15-17.51.53
2017-10-15 17:51:53,400: INFO: n_epochs: 2500
2017-10-15 17:51:53,400: INFO: n_hidden: 16
2017-10-15 17:51:53,400: INFO: batch_size: 5
2017-10-15 17:51:53,400: INFO: dropout_enabled: True
2017-10-15 17:51:53,401: INFO: multi_layers_enabled: False
2017-10-15 17:51:53,401: INFO: n_layers: 1
2017-10-15 17:51:53,401: INFO: exp_decay_enabled: False
2017-10-15 17:51:53,401: INFO: reg_enabled: False

2017-10-15 17:51:54,413: INFO: Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled
	 [[Node: Input_Batch/input_producer/input_producer_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_STRING], timeout_ms=-1, _device="/job:localhost/replica:0/task:0/cpu:0"](Input_Batch/input_producer, Input_Batch/input_producer/limit_epochs)]]
2017-10-22 16:19:30,393: INFO: *** NEW RUN ***
2017-10-22 16:19:30,394: INFO: filename: trained_model_2017.10.22-16.19.30
2017-10-22 16:19:30,394: INFO: n_epochs: 2500
2017-10-22 16:19:30,395: INFO: n_hidden: 16
2017-10-22 16:19:30,395: INFO: batch_size: 5
2017-10-22 16:19:30,395: INFO: dropout_enabled: False
2017-10-22 16:19:30,395: INFO: multi_layers_enabled: False
2017-10-22 16:19:30,395: INFO: n_layers: 1
2017-10-22 16:19:30,395: INFO: exp_decay_enabled: False
2017-10-22 16:19:30,396: INFO: reg_enabled: False

2017-10-22 16:19:32,255: INFO: The training shall begin.
2017-10-22 16:19:35,714: INFO: Iter: 0, Loss: 1.162, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 16:20:00,917: INFO: Iter: 50, Loss: 1.168, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 16:20:25,775: INFO: Iter: 100, Loss: 1.087, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:20:50,695: INFO: Iter: 150, Loss: 1.069, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 16:21:15,447: INFO: Iter: 200, Loss: 1.133, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 16:21:40,169: INFO: Iter: 250, Loss: 1.192, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 16:22:05,062: INFO: Iter: 300, Loss: 1.131, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 16:22:17,810: INFO: Iter: 350, Loss: 1.111, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:22:42,459: INFO: Iter: 400, Loss: 0.840, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 16:23:08,619: INFO: Iter: 450, Loss: 1.082, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 16:23:33,954: INFO: Iter: 500, Loss: 1.077, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 16:23:59,573: INFO: Iter: 550, Loss: 1.255, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 16:24:24,431: INFO: Iter: 600, Loss: 1.095, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 16:24:49,814: INFO: Iter: 650, Loss: 1.259, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 16:25:13,965: INFO: Iter: 700, Loss: 1.039, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 16:25:38,700: INFO: Iter: 750, Loss: 1.175, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 16:26:04,201: INFO: Iter: 800, Loss: 0.957, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 16:26:29,164: INFO: Iter: 850, Loss: 1.036, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:26:53,897: INFO: Iter: 900, Loss: 1.084, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 16:27:18,350: INFO: Iter: 950, Loss: 1.083, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 16:27:42,911: INFO: Iter: 1000, Loss: 1.181, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 16:28:10,167: INFO: Iter: 1050, Loss: 1.130, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 16:28:53,077: INFO: Iter: 1100, Loss: 0.966, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:29:18,504: INFO: Iter: 1150, Loss: 0.900, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 16:29:47,335: INFO: Iter: 1200, Loss: 1.039, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:30:15,900: INFO: Iter: 1250, Loss: 1.108, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 16:30:40,182: INFO: Iter: 1300, Loss: 1.206, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 16:31:05,015: INFO: Iter: 1350, Loss: 0.976, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:31:29,116: INFO: Iter: 1400, Loss: 1.151, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 16:31:53,401: INFO: Iter: 1450, Loss: 0.993, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:32:17,571: INFO: Iter: 1500, Loss: 0.923, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:32:41,529: INFO: Iter: 1550, Loss: 1.218, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 16:33:05,579: INFO: Iter: 1600, Loss: 0.906, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 16:33:29,264: INFO: Iter: 1650, Loss: 0.977, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:33:53,970: INFO: Iter: 1700, Loss: 1.463, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 16:34:17,840: INFO: Iter: 1750, Loss: 1.106, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 16:34:42,718: INFO: Iter: 1800, Loss: 0.985, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:35:06,451: INFO: Iter: 1850, Loss: 1.154, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 16:35:30,942: INFO: Iter: 1900, Loss: 1.245, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 16:35:55,348: INFO: Iter: 1950, Loss: 1.041, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:36:20,063: INFO: Iter: 2000, Loss: 0.984, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:36:44,067: INFO: Iter: 2050, Loss: 1.077, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 16:37:07,578: INFO: Iter: 2100, Loss: 0.929, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:37:31,245: INFO: Iter: 2150, Loss: 1.191, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 16:37:55,336: INFO: Iter: 2200, Loss: 0.955, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:38:18,900: INFO: Iter: 2250, Loss: 0.967, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:38:43,182: INFO: Iter: 2300, Loss: 0.938, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:39:07,237: INFO: Iter: 2350, Loss: 0.907, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:39:31,651: INFO: Iter: 2400, Loss: 1.305, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 16:39:56,047: INFO: Iter: 2450, Loss: 1.078, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 16:40:21,077: INFO: Iter: 2500, Loss: 1.198, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 16:40:46,245: INFO: Iter: 2550, Loss: 0.938, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 16:41:10,427: INFO: Iter: 2600, Loss: 1.366, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 16:41:34,185: INFO: Iter: 2650, Loss: 1.170, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 16:41:57,987: INFO: Iter: 2700, Loss: 0.878, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 16:42:21,830: INFO: Iter: 2750, Loss: 1.003, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:42:46,038: INFO: Iter: 2800, Loss: 1.100, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 16:43:09,317: INFO: Iter: 2850, Loss: 0.979, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:43:33,255: INFO: Iter: 2900, Loss: 1.269, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 16:43:56,949: INFO: Iter: 2950, Loss: 1.128, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 16:44:21,013: INFO: Iter: 3000, Loss: 1.198, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 16:44:45,197: INFO: Iter: 3050, Loss: 1.037, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:45:08,474: INFO: Iter: 3100, Loss: 0.986, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:45:32,714: INFO: Iter: 3150, Loss: 1.079, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 16:45:57,245: INFO: Iter: 3200, Loss: 1.191, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 16:46:20,632: INFO: Iter: 3250, Loss: 1.011, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:46:44,879: INFO: Iter: 3300, Loss: 1.151, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 16:47:09,085: INFO: Iter: 3350, Loss: 1.130, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 16:47:32,733: INFO: Iter: 3400, Loss: 0.941, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:47:57,110: INFO: Iter: 3450, Loss: 1.185, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 16:48:19,752: INFO: Iter: 3500, Loss: 0.868, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 16:48:44,604: INFO: Iter: 3550, Loss: 0.984, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:49:07,932: INFO: Iter: 3600, Loss: 0.985, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:49:31,289: INFO: Iter: 3650, Loss: 0.958, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:49:55,916: INFO: Iter: 3700, Loss: 1.220, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 16:50:20,299: INFO: Iter: 3750, Loss: 1.231, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 16:50:44,750: INFO: Iter: 3800, Loss: 0.984, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:51:09,132: INFO: Iter: 3850, Loss: 1.202, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 16:51:34,241: INFO: Iter: 3900, Loss: 0.909, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 16:52:00,005: INFO: Keyboard Interrupt? Gracefully quitting
2017-10-22 16:52:00,006: INFO: The training is done.

2017-10-22 16:52:03,151: INFO: *** NEW RUN ***
2017-10-22 16:52:03,151: INFO: filename: trained_model_2017.10.22-16.52.03
2017-10-22 16:52:03,152: INFO: n_epochs: 2500
2017-10-22 16:52:03,152: INFO: n_hidden: 16
2017-10-22 16:52:03,152: INFO: batch_size: 5
2017-10-22 16:52:03,153: INFO: dropout_enabled: True
2017-10-22 16:52:03,153: INFO: multi_layers_enabled: False
2017-10-22 16:52:03,153: INFO: n_layers: 1
2017-10-22 16:52:03,153: INFO: exp_decay_enabled: False
2017-10-22 16:52:03,153: INFO: reg_enabled: False

2017-10-22 16:57:54,763: INFO: *** NEW RUN ***
2017-10-22 16:57:54,764: INFO: filename: trained_model_2017.10.22-16.57.54
2017-10-22 16:57:54,764: INFO: n_epochs: 2500
2017-10-22 16:57:54,765: INFO: n_hidden: 16
2017-10-22 16:57:54,765: INFO: batch_size: 5
2017-10-22 16:57:54,765: INFO: dropout_enabled: False
2017-10-22 16:57:54,765: INFO: n_layers: 1
2017-10-22 16:57:54,765: INFO: exp_decay_enabled: False
2017-10-22 16:57:54,766: INFO: reg_enabled: False

2017-10-22 16:57:56,822: INFO: The training shall begin.
2017-10-22 16:57:57,741: INFO: The training is done.

2017-10-22 17:16:22,972: INFO: *** NEW RUN ***
2017-10-22 17:16:22,973: INFO: filename: trained_model_2017.10.22-17.16.22
2017-10-22 17:16:22,974: INFO: n_epochs: 2500
2017-10-22 17:16:22,974: INFO: n_hidden: 16
2017-10-22 17:16:22,974: INFO: batch_size: 5
2017-10-22 17:16:22,974: INFO: dropout_enabled: False
2017-10-22 17:16:22,974: INFO: n_layers: 1
2017-10-22 17:16:22,975: INFO: exp_decay_enabled: False
2017-10-22 17:16:22,975: INFO: reg_enabled: False

2017-10-22 17:16:25,198: INFO: The training shall begin.
2017-10-22 17:16:28,622: INFO: Iter: 0, Loss: 1.065, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 17:16:35,074: INFO: Keyboard Interrupt? Gracefully quitting
2017-10-22 17:16:35,075: INFO: The training is done.

2017-10-22 17:16:37,840: INFO: *** NEW RUN ***
2017-10-22 17:16:37,840: INFO: filename: trained_model_2017.10.22-17.16.37
2017-10-22 17:16:37,841: INFO: n_epochs: 2500
2017-10-22 17:16:37,841: INFO: n_hidden: 16
2017-10-22 17:16:37,841: INFO: batch_size: 5
2017-10-22 17:16:37,841: INFO: dropout_enabled: True
2017-10-22 17:16:37,841: INFO: n_layers: 1
2017-10-22 17:16:37,841: INFO: exp_decay_enabled: False
2017-10-22 17:16:37,841: INFO: reg_enabled: False

2017-10-22 17:16:40,321: INFO: The training shall begin.
2017-10-22 17:16:45,333: INFO: Iter: 0, Loss: 1.166, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 17:17:19,528: INFO: Iter: 50, Loss: 1.033, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 17:17:54,151: INFO: Iter: 100, Loss: 1.736, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 17:18:28,679: INFO: Iter: 150, Loss: 1.304, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 17:19:04,182: INFO: Iter: 200, Loss: 1.090, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 17:19:38,421: INFO: Iter: 250, Loss: 0.844, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 17:20:15,942: INFO: Iter: 300, Loss: 0.971, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 17:20:53,077: INFO: Iter: 350, Loss: 1.052, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 17:21:30,099: INFO: Iter: 400, Loss: 1.054, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 17:24:07,729: INFO: Iter: 450, Loss: 0.925, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 17:24:43,210: INFO: Iter: 500, Loss: 1.157, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 17:25:18,541: INFO: Iter: 550, Loss: 1.217, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 17:25:53,973: INFO: Iter: 600, Loss: 1.164, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 17:26:30,490: INFO: Iter: 650, Loss: 1.018, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 17:27:10,283: INFO: Iter: 700, Loss: 1.088, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 17:27:45,059: INFO: Iter: 750, Loss: 0.929, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 17:28:20,342: INFO: Iter: 800, Loss: 0.838, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 17:28:54,460: INFO: Iter: 850, Loss: 0.752, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 17:29:30,000: INFO: Iter: 900, Loss: 1.299, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 17:30:05,683: INFO: Iter: 950, Loss: 1.095, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 17:30:41,141: INFO: Iter: 1000, Loss: 1.171, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 17:31:16,577: INFO: Iter: 1050, Loss: 1.130, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 17:31:51,185: INFO: Iter: 1100, Loss: 0.912, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 17:32:25,574: INFO: Iter: 1150, Loss: 1.000, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 17:32:59,518: INFO: Iter: 1200, Loss: 1.040, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 17:33:33,506: INFO: Iter: 1250, Loss: 1.233, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 17:34:07,484: INFO: Iter: 1300, Loss: 1.220, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 17:34:41,947: INFO: Iter: 1350, Loss: 1.089, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 17:35:16,652: INFO: Iter: 1400, Loss: 0.919, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 17:35:51,096: INFO: Iter: 1450, Loss: 0.850, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 17:36:25,183: INFO: Iter: 1500, Loss: 1.098, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 17:36:59,324: INFO: Iter: 1550, Loss: 1.148, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 17:37:33,386: INFO: Iter: 1600, Loss: 0.900, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 17:37:56,439: INFO: Iter: 1650, Loss: 1.192, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 17:38:32,086: INFO: Iter: 1700, Loss: 1.073, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 17:39:08,377: INFO: Iter: 1750, Loss: 0.960, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 17:39:44,286: INFO: Iter: 1800, Loss: 1.052, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 17:40:18,217: INFO: Iter: 1850, Loss: 1.189, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 17:40:52,578: INFO: Iter: 1900, Loss: 1.183, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 17:41:27,159: INFO: Iter: 1950, Loss: 0.970, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 17:42:02,731: INFO: Iter: 2000, Loss: 0.944, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 17:42:37,674: INFO: Iter: 2050, Loss: 1.045, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 17:43:13,926: INFO: Iter: 2100, Loss: 0.981, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 17:43:48,956: INFO: Iter: 2150, Loss: 1.291, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 17:44:22,779: INFO: Iter: 2200, Loss: 1.322, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 17:44:56,974: INFO: Iter: 2250, Loss: 1.115, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 17:45:32,469: INFO: Iter: 2300, Loss: 0.977, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 17:46:07,848: INFO: Iter: 2350, Loss: 1.112, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 17:46:44,269: INFO: Iter: 2400, Loss: 0.907, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 17:47:19,589: INFO: Iter: 2450, Loss: 1.161, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 17:47:54,461: INFO: Iter: 2500, Loss: 1.056, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 17:48:28,588: INFO: Iter: 2550, Loss: 1.181, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 17:49:03,626: INFO: Iter: 2600, Loss: 1.023, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 17:49:39,569: INFO: Iter: 2650, Loss: 0.758, Accuracy: 1.000, Learning Rate: 0.001
2017-10-22 17:50:13,738: INFO: Iter: 2700, Loss: 1.126, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 17:50:48,766: INFO: Iter: 2750, Loss: 1.015, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 17:51:24,161: INFO: Iter: 2800, Loss: 1.090, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 17:51:57,840: INFO: Iter: 2850, Loss: 0.822, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 17:52:32,136: INFO: Iter: 2900, Loss: 1.318, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 17:53:06,840: INFO: Iter: 2950, Loss: 1.092, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 17:53:41,139: INFO: Iter: 3000, Loss: 1.055, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 17:54:15,781: INFO: Iter: 3050, Loss: 0.911, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 17:54:51,680: INFO: Iter: 3100, Loss: 0.964, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 17:55:26,126: INFO: Iter: 3150, Loss: 1.099, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 17:56:01,836: INFO: Iter: 3200, Loss: 0.781, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 17:56:36,896: INFO: Iter: 3250, Loss: 0.962, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 17:57:11,242: INFO: Iter: 3300, Loss: 0.929, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 17:57:45,192: INFO: Iter: 3350, Loss: 0.997, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 17:58:19,237: INFO: Iter: 3400, Loss: 0.995, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 17:58:53,329: INFO: Iter: 3450, Loss: 1.049, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 17:59:27,038: INFO: Iter: 3500, Loss: 1.156, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:00:02,038: INFO: Iter: 3550, Loss: 1.342, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 18:00:35,496: INFO: Iter: 3600, Loss: 0.883, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 18:01:11,074: INFO: Iter: 3650, Loss: 1.110, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:01:46,553: INFO: Iter: 3700, Loss: 0.887, Accuracy: 1.000, Learning Rate: 0.001
2017-10-22 18:02:22,053: INFO: Iter: 3750, Loss: 1.167, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:02:57,115: INFO: Iter: 3800, Loss: 1.157, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 18:03:33,057: INFO: Iter: 3850, Loss: 1.116, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 18:04:07,687: INFO: Iter: 3900, Loss: 1.087, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 18:04:43,612: INFO: Iter: 3950, Loss: 1.007, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:05:17,780: INFO: Iter: 4000, Loss: 0.910, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 18:05:53,200: INFO: Iter: 4050, Loss: 0.844, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 18:06:28,076: INFO: Iter: 4100, Loss: 0.965, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 18:07:02,465: INFO: Iter: 4150, Loss: 1.303, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 18:07:36,923: INFO: Iter: 4200, Loss: 0.946, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 18:08:12,583: INFO: Iter: 4250, Loss: 0.810, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 18:08:46,983: INFO: Iter: 4300, Loss: 1.212, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:09:21,239: INFO: Iter: 4350, Loss: 1.143, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 18:09:55,125: INFO: Iter: 4400, Loss: 1.080, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:18:06,029: INFO: Iter: 4450, Loss: 1.005, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 18:18:40,396: INFO: Iter: 4500, Loss: 1.037, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 18:19:14,288: INFO: Iter: 4550, Loss: 1.212, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:19:47,950: INFO: Iter: 4600, Loss: 0.772, Accuracy: 1.000, Learning Rate: 0.001
2017-10-22 18:20:21,575: INFO: Iter: 4650, Loss: 1.112, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 18:20:55,245: INFO: Iter: 4700, Loss: 1.105, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:21:28,635: INFO: Iter: 4750, Loss: 1.030, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 18:22:02,373: INFO: Iter: 4800, Loss: 1.193, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 18:22:35,994: INFO: Iter: 4850, Loss: 1.365, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 18:23:09,669: INFO: Iter: 4900, Loss: 1.015, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:23:43,397: INFO: Iter: 4950, Loss: 1.304, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 18:24:17,015: INFO: Iter: 5000, Loss: 1.136, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:24:50,545: INFO: Iter: 5050, Loss: 1.150, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:25:24,311: INFO: Iter: 5100, Loss: 0.928, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 18:25:57,958: INFO: Iter: 5150, Loss: 1.066, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:26:31,800: INFO: Iter: 5200, Loss: 1.287, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 18:27:05,478: INFO: Iter: 5250, Loss: 1.078, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:27:38,801: INFO: Iter: 5300, Loss: 0.825, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 18:28:12,597: INFO: Iter: 5350, Loss: 0.750, Accuracy: 1.000, Learning Rate: 0.001
2017-10-22 18:28:46,335: INFO: Iter: 5400, Loss: 1.010, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 18:29:20,031: INFO: Iter: 5450, Loss: 0.869, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 18:29:53,733: INFO: Iter: 5500, Loss: 0.883, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 18:30:27,365: INFO: Iter: 5550, Loss: 1.044, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:31:00,977: INFO: Iter: 5600, Loss: 0.949, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 18:31:34,703: INFO: Iter: 5650, Loss: 0.843, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 18:32:08,640: INFO: Iter: 5700, Loss: 1.219, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 18:32:42,171: INFO: Iter: 5750, Loss: 1.230, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 18:33:04,255: INFO: Iter: 5800, Loss: 0.943, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 18:33:38,159: INFO: Iter: 5850, Loss: 0.925, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 18:34:12,031: INFO: Iter: 5900, Loss: 1.077, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:34:45,859: INFO: Iter: 5950, Loss: 0.983, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:35:19,249: INFO: Iter: 6000, Loss: 0.954, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 18:35:53,084: INFO: Iter: 6050, Loss: 1.481, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 18:36:26,940: INFO: Iter: 6100, Loss: 1.111, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 18:37:00,409: INFO: Iter: 6150, Loss: 0.952, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 18:37:34,075: INFO: Iter: 6200, Loss: 1.009, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 18:38:07,652: INFO: Iter: 6250, Loss: 1.245, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 18:38:41,470: INFO: Iter: 6300, Loss: 0.822, Accuracy: 1.000, Learning Rate: 0.001
2017-10-22 18:39:15,338: INFO: Iter: 6350, Loss: 1.090, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:39:49,041: INFO: Iter: 6400, Loss: 1.143, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:40:22,624: INFO: Iter: 6450, Loss: 0.887, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 18:40:56,333: INFO: Iter: 6500, Loss: 1.226, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:41:29,682: INFO: Iter: 6550, Loss: 1.246, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 18:42:03,170: INFO: Iter: 6600, Loss: 1.231, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 18:42:36,809: INFO: Iter: 6650, Loss: 0.989, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:43:10,357: INFO: Iter: 6700, Loss: 1.111, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:43:43,741: INFO: Iter: 6750, Loss: 1.175, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:44:17,544: INFO: Iter: 6800, Loss: 1.336, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 18:44:51,572: INFO: Iter: 6850, Loss: 1.376, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 18:45:25,386: INFO: Iter: 6900, Loss: 0.932, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 18:45:59,024: INFO: Iter: 6950, Loss: 0.893, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 18:46:32,632: INFO: Iter: 7000, Loss: 1.053, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:47:06,131: INFO: Iter: 7050, Loss: 1.130, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:47:39,654: INFO: Iter: 7100, Loss: 1.130, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:48:13,097: INFO: Iter: 7150, Loss: 1.175, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 18:48:46,812: INFO: Iter: 7200, Loss: 1.074, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:49:20,415: INFO: Iter: 7250, Loss: 1.035, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 18:49:54,265: INFO: Iter: 7300, Loss: 0.896, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 18:50:27,722: INFO: Iter: 7350, Loss: 0.993, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 18:51:01,478: INFO: Iter: 7400, Loss: 0.802, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 18:51:35,277: INFO: Iter: 7450, Loss: 1.116, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:52:08,689: INFO: Iter: 7500, Loss: 1.197, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 18:52:42,112: INFO: Iter: 7550, Loss: 0.857, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 18:53:15,812: INFO: Iter: 7600, Loss: 1.033, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 18:53:49,904: INFO: Iter: 7650, Loss: 0.951, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 18:54:23,332: INFO: Iter: 7700, Loss: 0.858, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 18:54:57,142: INFO: Iter: 7750, Loss: 0.926, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 18:55:31,134: INFO: Iter: 7800, Loss: 0.984, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 18:56:04,801: INFO: Iter: 7850, Loss: 1.122, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:56:38,614: INFO: Iter: 7900, Loss: 1.286, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 18:57:12,057: INFO: Iter: 7950, Loss: 1.129, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 18:57:45,727: INFO: Iter: 8000, Loss: 1.174, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 18:58:19,254: INFO: Iter: 8050, Loss: 1.122, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 18:58:52,710: INFO: Iter: 8100, Loss: 1.299, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 18:59:26,027: INFO: Iter: 8150, Loss: 1.153, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 18:59:59,735: INFO: Iter: 8200, Loss: 0.815, Accuracy: 1.000, Learning Rate: 0.001
2017-10-22 19:00:33,292: INFO: Iter: 8250, Loss: 0.842, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 19:01:07,254: INFO: Iter: 8300, Loss: 1.033, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:01:41,065: INFO: Iter: 8350, Loss: 1.210, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 19:02:14,940: INFO: Iter: 8400, Loss: 1.157, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:02:48,709: INFO: Iter: 8450, Loss: 0.900, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 19:03:22,554: INFO: Iter: 8500, Loss: 0.920, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:03:55,964: INFO: Iter: 8550, Loss: 0.937, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:04:29,649: INFO: Iter: 8600, Loss: 1.215, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 19:05:03,177: INFO: Iter: 8650, Loss: 0.876, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 19:05:36,986: INFO: Iter: 8700, Loss: 1.055, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:06:10,470: INFO: Iter: 8750, Loss: 1.065, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:06:44,037: INFO: Iter: 8800, Loss: 0.795, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 19:07:17,625: INFO: Iter: 8850, Loss: 1.315, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 19:07:50,960: INFO: Iter: 8900, Loss: 1.305, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 19:08:24,185: INFO: Iter: 8950, Loss: 1.017, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:08:57,961: INFO: Iter: 9000, Loss: 1.044, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:09:31,635: INFO: Iter: 9050, Loss: 0.933, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:10:05,225: INFO: Iter: 9100, Loss: 1.132, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:10:38,963: INFO: Iter: 9150, Loss: 1.286, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 19:11:12,751: INFO: Iter: 9200, Loss: 1.201, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:11:46,453: INFO: Iter: 9250, Loss: 1.054, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:12:19,992: INFO: Iter: 9300, Loss: 1.110, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:12:53,862: INFO: Iter: 9350, Loss: 1.180, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 19:13:27,799: INFO: Iter: 9400, Loss: 0.710, Accuracy: 1.000, Learning Rate: 0.001
2017-10-22 19:14:01,310: INFO: Iter: 9450, Loss: 1.081, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:14:34,991: INFO: Iter: 9500, Loss: 1.214, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 19:15:08,903: INFO: Iter: 9550, Loss: 0.844, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 19:15:42,823: INFO: Iter: 9600, Loss: 1.299, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 19:16:16,509: INFO: Iter: 9650, Loss: 0.842, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 19:16:50,080: INFO: Iter: 9700, Loss: 1.101, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:17:23,677: INFO: Iter: 9750, Loss: 0.894, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 19:17:57,153: INFO: Iter: 9800, Loss: 0.982, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:18:31,004: INFO: Iter: 9850, Loss: 1.042, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:19:04,716: INFO: Iter: 9900, Loss: 1.418, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 19:19:38,683: INFO: Iter: 9950, Loss: 1.125, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:20:12,150: INFO: Iter: 10000, Loss: 0.786, Accuracy: 1.000, Learning Rate: 0.001
2017-10-22 19:20:45,707: INFO: Iter: 10050, Loss: 0.951, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:21:19,483: INFO: Iter: 10100, Loss: 1.232, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 19:21:53,260: INFO: Iter: 10150, Loss: 1.026, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:22:26,508: INFO: Iter: 10200, Loss: 1.040, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:23:00,859: INFO: Iter: 10250, Loss: 1.022, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:23:34,650: INFO: Iter: 10300, Loss: 0.964, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 19:24:08,304: INFO: Iter: 10350, Loss: 0.960, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:24:42,016: INFO: Iter: 10400, Loss: 0.907, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:25:16,234: INFO: Iter: 10450, Loss: 1.018, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:25:50,241: INFO: Iter: 10500, Loss: 1.134, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:26:24,030: INFO: Iter: 10550, Loss: 1.096, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:26:58,213: INFO: Iter: 10600, Loss: 0.951, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:27:32,241: INFO: Iter: 10650, Loss: 1.126, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:28:06,051: INFO: Iter: 10700, Loss: 0.792, Accuracy: 1.000, Learning Rate: 0.001
2017-10-22 19:28:40,055: INFO: Iter: 10750, Loss: 1.232, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:29:14,244: INFO: Iter: 10800, Loss: 0.931, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:29:48,271: INFO: Iter: 10850, Loss: 1.088, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:30:22,442: INFO: Iter: 10900, Loss: 1.101, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:30:56,308: INFO: Iter: 10950, Loss: 1.058, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:31:30,439: INFO: Iter: 11000, Loss: 1.105, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:32:04,669: INFO: Iter: 11050, Loss: 1.014, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:32:38,798: INFO: Iter: 11100, Loss: 1.081, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:33:12,720: INFO: Iter: 11150, Loss: 0.772, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 19:33:46,591: INFO: Iter: 11200, Loss: 0.988, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:34:20,449: INFO: Iter: 11250, Loss: 0.868, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:34:54,056: INFO: Iter: 11300, Loss: 1.070, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:35:27,654: INFO: Iter: 11350, Loss: 1.053, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:36:01,407: INFO: Iter: 11400, Loss: 1.053, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:36:34,812: INFO: Iter: 11450, Loss: 0.832, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:37:08,310: INFO: Iter: 11500, Loss: 1.025, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:37:42,616: INFO: Iter: 11550, Loss: 1.016, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:38:16,567: INFO: Iter: 11600, Loss: 0.837, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 19:38:50,667: INFO: Iter: 11650, Loss: 0.923, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 19:39:24,569: INFO: Iter: 11700, Loss: 0.866, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:39:58,738: INFO: Iter: 11750, Loss: 1.411, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 19:40:32,632: INFO: Iter: 11800, Loss: 0.926, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:41:05,933: INFO: Iter: 11850, Loss: 0.832, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:41:39,525: INFO: Iter: 11900, Loss: 1.078, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:42:13,105: INFO: Iter: 11950, Loss: 1.089, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:42:46,897: INFO: Iter: 12000, Loss: 1.205, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 19:43:20,476: INFO: Iter: 12050, Loss: 0.898, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 19:43:54,266: INFO: Iter: 12100, Loss: 1.115, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:44:28,164: INFO: Iter: 12150, Loss: 0.952, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:45:02,375: INFO: Iter: 12200, Loss: 1.222, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 19:45:36,342: INFO: Iter: 12250, Loss: 0.701, Accuracy: 1.000, Learning Rate: 0.001
2017-10-22 19:46:10,250: INFO: Iter: 12300, Loss: 1.027, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:46:44,015: INFO: Iter: 12350, Loss: 0.980, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:47:18,311: INFO: Iter: 12400, Loss: 1.121, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:47:52,559: INFO: Iter: 12450, Loss: 1.052, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:48:26,730: INFO: Iter: 12500, Loss: 1.271, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 19:49:00,503: INFO: Iter: 12550, Loss: 1.025, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:49:34,701: INFO: Iter: 12600, Loss: 1.097, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:50:09,043: INFO: Iter: 12650, Loss: 1.031, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 19:50:42,879: INFO: Iter: 12700, Loss: 1.230, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 19:51:16,452: INFO: Iter: 12750, Loss: 0.767, Accuracy: 1.000, Learning Rate: 0.001
2017-10-22 19:51:50,490: INFO: Iter: 12800, Loss: 1.231, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 19:52:24,333: INFO: Iter: 12850, Loss: 0.705, Accuracy: 1.000, Learning Rate: 0.001
2017-10-22 19:52:58,635: INFO: Iter: 12900, Loss: 1.315, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 19:53:32,739: INFO: Iter: 12950, Loss: 1.153, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:54:07,137: INFO: Iter: 13000, Loss: 1.172, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 19:54:41,421: INFO: Iter: 13050, Loss: 1.064, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:55:15,489: INFO: Iter: 13100, Loss: 0.881, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:55:50,026: INFO: Iter: 13150, Loss: 1.038, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:56:24,009: INFO: Iter: 13200, Loss: 1.240, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:56:57,942: INFO: Iter: 13250, Loss: 0.796, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 19:57:32,196: INFO: Iter: 13300, Loss: 0.925, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:58:06,042: INFO: Iter: 13350, Loss: 0.871, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 19:58:40,065: INFO: Iter: 13400, Loss: 1.181, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 19:59:13,945: INFO: Iter: 13450, Loss: 0.850, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 19:59:48,234: INFO: Iter: 13500, Loss: 1.087, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:00:22,385: INFO: Iter: 13550, Loss: 1.091, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:00:56,436: INFO: Iter: 13600, Loss: 1.262, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 20:01:30,322: INFO: Iter: 13650, Loss: 0.994, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:02:04,438: INFO: Iter: 13700, Loss: 1.007, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:02:38,585: INFO: Iter: 13750, Loss: 1.274, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 20:03:12,692: INFO: Iter: 13800, Loss: 0.972, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:03:47,136: INFO: Iter: 13850, Loss: 0.995, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:04:21,200: INFO: Iter: 13900, Loss: 1.038, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:04:55,056: INFO: Iter: 13950, Loss: 0.917, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:05:29,090: INFO: Iter: 14000, Loss: 1.207, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:06:02,958: INFO: Iter: 14050, Loss: 1.070, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:06:36,640: INFO: Iter: 14100, Loss: 1.185, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:07:10,339: INFO: Iter: 14150, Loss: 0.988, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:07:44,242: INFO: Iter: 14200, Loss: 0.957, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:08:18,186: INFO: Iter: 14250, Loss: 1.053, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:08:52,143: INFO: Iter: 14300, Loss: 0.886, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:09:26,006: INFO: Iter: 14350, Loss: 0.932, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:10:00,134: INFO: Iter: 14400, Loss: 0.889, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:10:34,140: INFO: Iter: 14450, Loss: 0.868, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 20:11:08,172: INFO: Iter: 14500, Loss: 1.027, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:11:42,244: INFO: Iter: 14550, Loss: 1.071, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:12:16,512: INFO: Iter: 14600, Loss: 1.131, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 20:12:50,421: INFO: Iter: 14650, Loss: 1.282, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 20:13:24,032: INFO: Iter: 14700, Loss: 1.037, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:13:57,969: INFO: Iter: 14750, Loss: 1.251, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 20:14:32,107: INFO: Iter: 14800, Loss: 0.783, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 20:15:06,276: INFO: Iter: 14850, Loss: 0.857, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 20:15:40,296: INFO: Iter: 14900, Loss: 1.055, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:16:14,164: INFO: Iter: 14950, Loss: 1.180, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 20:16:48,169: INFO: Iter: 15000, Loss: 0.738, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 20:17:22,289: INFO: Iter: 15050, Loss: 1.075, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 20:17:56,374: INFO: Iter: 15100, Loss: 1.057, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:18:30,351: INFO: Iter: 15150, Loss: 0.990, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:19:04,195: INFO: Iter: 15200, Loss: 1.024, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:19:38,560: INFO: Iter: 15250, Loss: 1.105, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:20:12,780: INFO: Iter: 15300, Loss: 1.092, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:20:46,825: INFO: Iter: 15350, Loss: 1.093, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:21:20,741: INFO: Iter: 15400, Loss: 1.135, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:21:54,880: INFO: Iter: 15450, Loss: 0.890, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:22:29,198: INFO: Iter: 15500, Loss: 1.021, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:23:02,934: INFO: Iter: 15550, Loss: 0.907, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:23:36,983: INFO: Iter: 15600, Loss: 1.128, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:24:11,229: INFO: Iter: 15650, Loss: 0.939, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 20:24:45,070: INFO: Iter: 15700, Loss: 0.777, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 20:25:19,140: INFO: Iter: 15750, Loss: 0.911, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:25:53,320: INFO: Iter: 15800, Loss: 0.919, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:26:27,511: INFO: Iter: 15850, Loss: 0.960, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:27:01,429: INFO: Iter: 15900, Loss: 1.295, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 20:27:35,637: INFO: Iter: 15950, Loss: 0.905, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:28:09,294: INFO: Iter: 16000, Loss: 0.945, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:28:43,283: INFO: Iter: 16050, Loss: 1.139, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:29:17,490: INFO: Iter: 16100, Loss: 1.051, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:29:51,896: INFO: Iter: 16150, Loss: 0.998, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 20:30:25,882: INFO: Iter: 16200, Loss: 1.237, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:30:59,759: INFO: Iter: 16250, Loss: 1.135, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 20:31:33,769: INFO: Iter: 16300, Loss: 0.805, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 20:32:07,664: INFO: Iter: 16350, Loss: 0.957, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:32:41,839: INFO: Iter: 16400, Loss: 0.761, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 20:33:15,748: INFO: Iter: 16450, Loss: 0.723, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 20:33:49,823: INFO: Iter: 16500, Loss: 1.059, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:34:23,913: INFO: Iter: 16550, Loss: 1.102, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 20:34:57,910: INFO: Iter: 16600, Loss: 1.376, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 20:35:31,700: INFO: Iter: 16650, Loss: 0.869, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:36:05,806: INFO: Iter: 16700, Loss: 0.875, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:36:39,916: INFO: Iter: 16750, Loss: 1.119, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:37:13,877: INFO: Iter: 16800, Loss: 1.186, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:37:47,761: INFO: Iter: 16850, Loss: 1.278, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:38:21,405: INFO: Iter: 16900, Loss: 0.882, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 20:38:55,387: INFO: Iter: 16950, Loss: 0.915, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:39:29,226: INFO: Iter: 17000, Loss: 0.788, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 20:40:03,061: INFO: Iter: 17050, Loss: 0.778, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 20:40:37,214: INFO: Iter: 17100, Loss: 0.953, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:41:11,098: INFO: Iter: 17150, Loss: 0.946, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:41:45,023: INFO: Iter: 17200, Loss: 1.474, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 20:42:19,233: INFO: Iter: 17250, Loss: 0.884, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:42:53,580: INFO: Iter: 17300, Loss: 0.749, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 20:43:27,432: INFO: Iter: 17350, Loss: 1.065, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:44:01,519: INFO: Iter: 17400, Loss: 1.307, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 20:44:35,713: INFO: Iter: 17450, Loss: 1.121, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:45:09,887: INFO: Iter: 17500, Loss: 1.121, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:45:43,584: INFO: Iter: 17550, Loss: 1.114, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:46:17,305: INFO: Iter: 17600, Loss: 0.907, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:46:51,179: INFO: Iter: 17650, Loss: 1.185, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 20:47:25,385: INFO: Iter: 17700, Loss: 1.320, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:47:59,626: INFO: Iter: 17750, Loss: 1.124, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:48:33,734: INFO: Iter: 17800, Loss: 1.310, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:49:07,987: INFO: Iter: 17850, Loss: 0.866, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:49:42,193: INFO: Iter: 17900, Loss: 0.939, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:50:16,522: INFO: Iter: 17950, Loss: 0.961, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:50:50,453: INFO: Iter: 18000, Loss: 0.767, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 20:51:24,619: INFO: Iter: 18050, Loss: 0.753, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 20:51:58,762: INFO: Iter: 18100, Loss: 1.029, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:52:32,798: INFO: Iter: 18150, Loss: 0.832, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:53:06,771: INFO: Iter: 18200, Loss: 1.133, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:53:40,703: INFO: Iter: 18250, Loss: 1.036, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:54:14,507: INFO: Iter: 18300, Loss: 1.191, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:54:49,094: INFO: Iter: 18350, Loss: 0.903, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:55:23,154: INFO: Iter: 18400, Loss: 1.200, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 20:55:57,430: INFO: Iter: 18450, Loss: 0.767, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 20:56:31,433: INFO: Iter: 18500, Loss: 1.152, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:57:05,360: INFO: Iter: 18550, Loss: 1.029, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 20:57:39,580: INFO: Iter: 18600, Loss: 0.853, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:58:13,690: INFO: Iter: 18650, Loss: 0.910, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:58:47,874: INFO: Iter: 18700, Loss: 0.980, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 20:59:21,993: INFO: Iter: 18750, Loss: 1.024, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 20:59:56,059: INFO: Iter: 18800, Loss: 0.981, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:00:30,056: INFO: Iter: 18850, Loss: 1.298, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 21:01:04,328: INFO: Iter: 18900, Loss: 1.597, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 21:01:38,449: INFO: Iter: 18950, Loss: 1.016, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:02:12,885: INFO: Iter: 19000, Loss: 1.013, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:02:46,995: INFO: Iter: 19050, Loss: 0.999, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:03:21,227: INFO: Iter: 19100, Loss: 0.958, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:03:55,069: INFO: Iter: 19150, Loss: 1.064, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:04:29,097: INFO: Iter: 19200, Loss: 0.864, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:05:03,137: INFO: Iter: 19250, Loss: 1.304, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 21:05:37,006: INFO: Iter: 19300, Loss: 0.928, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:06:11,135: INFO: Iter: 19350, Loss: 0.947, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:06:45,360: INFO: Iter: 19400, Loss: 1.049, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:07:19,521: INFO: Iter: 19450, Loss: 1.041, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 21:07:53,487: INFO: Iter: 19500, Loss: 0.867, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 21:08:27,057: INFO: Iter: 19550, Loss: 1.253, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:09:01,125: INFO: Iter: 19600, Loss: 0.987, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 21:09:34,860: INFO: Iter: 19650, Loss: 1.020, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 21:10:09,180: INFO: Iter: 19700, Loss: 0.979, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:10:43,347: INFO: Iter: 19750, Loss: 0.705, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:11:17,551: INFO: Iter: 19800, Loss: 0.879, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:11:51,611: INFO: Iter: 19850, Loss: 1.052, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:12:25,609: INFO: Iter: 19900, Loss: 1.177, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 21:12:59,300: INFO: Iter: 19950, Loss: 1.014, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:13:33,347: INFO: Iter: 20000, Loss: 1.193, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 21:14:07,137: INFO: Iter: 20050, Loss: 0.949, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 21:14:41,243: INFO: Iter: 20100, Loss: 0.902, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 21:15:15,185: INFO: Iter: 20150, Loss: 1.344, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:15:49,055: INFO: Iter: 20200, Loss: 1.069, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:16:23,160: INFO: Iter: 20250, Loss: 1.083, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 21:16:57,160: INFO: Iter: 20300, Loss: 0.914, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:17:31,002: INFO: Iter: 20350, Loss: 0.862, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 21:18:05,099: INFO: Iter: 20400, Loss: 0.875, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 21:18:39,284: INFO: Iter: 20450, Loss: 1.115, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 21:19:16,935: INFO: Iter: 20500, Loss: 1.294, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 21:19:54,015: INFO: Iter: 20550, Loss: 1.086, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:20:28,688: INFO: Iter: 20600, Loss: 0.735, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:21:02,230: INFO: Iter: 20650, Loss: 0.890, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 21:21:36,136: INFO: Iter: 20700, Loss: 1.200, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:22:10,953: INFO: Iter: 20750, Loss: 0.836, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 21:22:45,862: INFO: Iter: 20800, Loss: 0.845, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:23:20,364: INFO: Iter: 20850, Loss: 1.020, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:23:57,185: INFO: Iter: 20900, Loss: 0.956, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:24:34,821: INFO: Iter: 20950, Loss: 0.880, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 21:25:10,601: INFO: Iter: 21000, Loss: 0.783, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 21:25:46,038: INFO: Iter: 21050, Loss: 1.181, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:26:23,666: INFO: Iter: 21100, Loss: 1.008, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 21:26:59,550: INFO: Iter: 21150, Loss: 1.063, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:27:38,803: INFO: Iter: 21200, Loss: 1.181, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:28:17,772: INFO: Iter: 21250, Loss: 0.874, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:28:55,442: INFO: Iter: 21300, Loss: 0.997, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:29:31,318: INFO: Iter: 21350, Loss: 0.744, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:30:08,002: INFO: Iter: 21400, Loss: 0.898, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:30:43,591: INFO: Iter: 21450, Loss: 0.806, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:31:21,407: INFO: Iter: 21500, Loss: 1.113, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:31:57,883: INFO: Iter: 21550, Loss: 0.875, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:32:33,709: INFO: Iter: 21600, Loss: 0.685, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:33:07,927: INFO: Iter: 21650, Loss: 0.881, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 21:33:42,491: INFO: Iter: 21700, Loss: 1.145, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:34:17,760: INFO: Iter: 21750, Loss: 1.362, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 21:34:54,400: INFO: Iter: 21800, Loss: 1.093, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:35:31,616: INFO: Iter: 21850, Loss: 1.019, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:36:07,246: INFO: Iter: 21900, Loss: 0.817, Accuracy: 1.000, Learning Rate: 0.001
2017-10-22 21:36:44,704: INFO: Iter: 21950, Loss: 1.320, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 21:37:20,944: INFO: Iter: 22000, Loss: 1.405, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:37:56,119: INFO: Iter: 22050, Loss: 0.939, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:38:31,430: INFO: Iter: 22100, Loss: 1.279, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 21:39:06,626: INFO: Iter: 22150, Loss: 1.050, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:39:41,677: INFO: Iter: 22200, Loss: 1.341, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 21:40:16,948: INFO: Iter: 22250, Loss: 0.732, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 21:40:51,711: INFO: Iter: 22300, Loss: 0.987, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:41:26,341: INFO: Iter: 22350, Loss: 0.899, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:42:00,373: INFO: Iter: 22400, Loss: 0.995, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:42:35,119: INFO: Iter: 22450, Loss: 1.022, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 21:43:09,431: INFO: Iter: 22500, Loss: 0.887, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:43:43,822: INFO: Iter: 22550, Loss: 1.111, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 21:44:18,135: INFO: Iter: 22600, Loss: 0.821, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:44:52,275: INFO: Iter: 22650, Loss: 0.996, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:45:27,062: INFO: Iter: 22700, Loss: 0.853, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 21:46:01,931: INFO: Iter: 22750, Loss: 1.106, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:46:36,677: INFO: Iter: 22800, Loss: 1.157, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 21:47:11,444: INFO: Iter: 22850, Loss: 1.066, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:47:46,118: INFO: Iter: 22900, Loss: 0.979, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:48:20,604: INFO: Iter: 22950, Loss: 0.775, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 21:48:54,790: INFO: Iter: 23000, Loss: 0.998, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 21:49:29,563: INFO: Iter: 23050, Loss: 0.934, Accuracy: 1.000, Learning Rate: 0.001
2017-10-22 21:50:03,698: INFO: Iter: 23100, Loss: 1.017, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:50:37,737: INFO: Iter: 23150, Loss: 1.116, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 21:51:11,921: INFO: Iter: 23200, Loss: 0.966, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:51:46,226: INFO: Iter: 23250, Loss: 0.866, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:52:20,597: INFO: Iter: 23300, Loss: 1.013, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 21:52:54,693: INFO: Iter: 23350, Loss: 1.233, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:53:28,843: INFO: Iter: 23400, Loss: 1.044, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:54:03,394: INFO: Iter: 23450, Loss: 0.811, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:54:37,987: INFO: Iter: 23500, Loss: 1.160, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:55:12,704: INFO: Iter: 23550, Loss: 0.899, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:55:47,713: INFO: Iter: 23600, Loss: 1.138, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:56:22,037: INFO: Iter: 23650, Loss: 1.052, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:56:56,655: INFO: Iter: 23700, Loss: 0.882, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 21:57:30,685: INFO: Iter: 23750, Loss: 1.019, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:58:04,684: INFO: Iter: 23800, Loss: 1.114, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 21:58:38,886: INFO: Iter: 23850, Loss: 1.009, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 21:59:13,215: INFO: Iter: 23900, Loss: 0.751, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 21:59:46,974: INFO: Iter: 23950, Loss: 1.123, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 22:00:21,067: INFO: Iter: 24000, Loss: 0.809, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:00:55,742: INFO: Iter: 24050, Loss: 1.050, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:01:29,549: INFO: Iter: 24100, Loss: 0.923, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:02:03,313: INFO: Iter: 24150, Loss: 0.459, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:02:37,428: INFO: Iter: 24200, Loss: 1.331, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:03:10,978: INFO: Iter: 24250, Loss: 0.650, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:03:44,413: INFO: Iter: 24300, Loss: 0.987, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:04:17,620: INFO: Iter: 24350, Loss: 0.839, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 22:04:50,886: INFO: Iter: 24400, Loss: 1.449, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 22:05:24,325: INFO: Iter: 24450, Loss: 0.699, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 22:05:57,728: INFO: Iter: 24500, Loss: 1.017, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:06:31,344: INFO: Iter: 24550, Loss: 0.978, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:07:05,268: INFO: Iter: 24600, Loss: 0.638, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:07:38,875: INFO: Iter: 24650, Loss: 0.610, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 22:08:12,743: INFO: Iter: 24700, Loss: 1.266, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 22:08:46,635: INFO: Iter: 24750, Loss: 1.079, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:09:20,508: INFO: Iter: 24800, Loss: 0.911, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:09:54,305: INFO: Iter: 24850, Loss: 0.892, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 22:10:28,271: INFO: Iter: 24900, Loss: 1.398, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 22:11:02,220: INFO: Iter: 24950, Loss: 1.019, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:11:35,911: INFO: Iter: 25000, Loss: 1.186, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:12:09,788: INFO: Iter: 25050, Loss: 0.833, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:12:43,316: INFO: Iter: 25100, Loss: 1.230, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:13:16,995: INFO: Iter: 25150, Loss: 0.677, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:13:50,797: INFO: Iter: 25200, Loss: 1.058, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:14:24,595: INFO: Iter: 25250, Loss: 1.147, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 22:14:58,469: INFO: Iter: 25300, Loss: 0.894, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:15:32,546: INFO: Iter: 25350, Loss: 0.870, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:16:06,449: INFO: Iter: 25400, Loss: 0.933, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:16:39,847: INFO: Iter: 25450, Loss: 1.616, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:17:13,490: INFO: Iter: 25500, Loss: 1.243, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:17:47,150: INFO: Iter: 25550, Loss: 0.883, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:18:21,100: INFO: Iter: 25600, Loss: 0.930, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 22:18:54,775: INFO: Iter: 25650, Loss: 1.057, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:19:28,465: INFO: Iter: 25700, Loss: 0.832, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:20:02,490: INFO: Iter: 25750, Loss: 0.934, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 22:20:36,349: INFO: Iter: 25800, Loss: 1.358, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 22:21:10,412: INFO: Iter: 25850, Loss: 1.066, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:21:44,004: INFO: Iter: 25900, Loss: 0.952, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:22:18,061: INFO: Iter: 25950, Loss: 1.015, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:22:51,693: INFO: Iter: 26000, Loss: 0.891, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:23:25,640: INFO: Iter: 26050, Loss: 1.172, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 22:23:59,703: INFO: Iter: 26100, Loss: 1.166, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 22:24:33,192: INFO: Iter: 26150, Loss: 1.065, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:25:06,525: INFO: Iter: 26200, Loss: 1.101, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 22:25:40,320: INFO: Iter: 26250, Loss: 1.087, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:26:14,151: INFO: Iter: 26300, Loss: 1.172, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:26:47,425: INFO: Iter: 26350, Loss: 0.987, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:27:21,390: INFO: Iter: 26400, Loss: 0.894, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:27:55,595: INFO: Iter: 26450, Loss: 0.923, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:28:29,740: INFO: Iter: 26500, Loss: 0.989, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:29:03,436: INFO: Iter: 26550, Loss: 1.002, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:29:37,076: INFO: Iter: 26600, Loss: 0.954, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:30:10,874: INFO: Iter: 26650, Loss: 1.096, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:30:44,618: INFO: Iter: 26700, Loss: 1.087, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 22:31:18,524: INFO: Iter: 26750, Loss: 0.878, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:31:52,647: INFO: Iter: 26800, Loss: 0.730, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 22:32:26,534: INFO: Iter: 26850, Loss: 0.855, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:33:00,193: INFO: Iter: 26900, Loss: 0.769, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:33:33,996: INFO: Iter: 26950, Loss: 1.020, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 22:34:07,447: INFO: Iter: 27000, Loss: 1.154, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 22:34:41,441: INFO: Iter: 27050, Loss: 0.643, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 22:35:15,279: INFO: Iter: 27100, Loss: 0.746, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 22:35:48,963: INFO: Iter: 27150, Loss: 0.844, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:36:22,541: INFO: Iter: 27200, Loss: 0.935, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:36:56,118: INFO: Iter: 27250, Loss: 0.742, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:37:29,844: INFO: Iter: 27300, Loss: 0.908, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:38:03,350: INFO: Iter: 27350, Loss: 0.802, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:38:37,077: INFO: Iter: 27400, Loss: 1.134, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:39:10,751: INFO: Iter: 27450, Loss: 0.983, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:39:44,658: INFO: Iter: 27500, Loss: 0.687, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:40:18,581: INFO: Iter: 27550, Loss: 0.825, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 22:40:52,331: INFO: Iter: 27600, Loss: 1.005, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:41:26,207: INFO: Iter: 27650, Loss: 0.727, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 22:41:59,999: INFO: Iter: 27700, Loss: 0.899, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:42:34,135: INFO: Iter: 27750, Loss: 0.861, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:43:07,968: INFO: Iter: 27800, Loss: 0.659, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 22:43:41,465: INFO: Iter: 27850, Loss: 0.827, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:44:15,054: INFO: Iter: 27900, Loss: 0.891, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 22:44:49,202: INFO: Iter: 27950, Loss: 0.726, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 22:45:23,210: INFO: Iter: 28000, Loss: 1.282, Accuracy: 0.000, Learning Rate: 0.001
2017-10-22 22:45:57,029: INFO: Iter: 28050, Loss: 0.716, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:46:31,235: INFO: Iter: 28100, Loss: 0.953, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:47:05,322: INFO: Iter: 28150, Loss: 0.710, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 22:47:39,192: INFO: Iter: 28200, Loss: 0.698, Accuracy: 1.000, Learning Rate: 0.001
2017-10-22 22:48:13,307: INFO: Iter: 28250, Loss: 0.777, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:48:47,305: INFO: Iter: 28300, Loss: 0.884, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:49:20,740: INFO: Iter: 28350, Loss: 0.752, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:49:54,465: INFO: Iter: 28400, Loss: 1.112, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 22:50:28,411: INFO: Iter: 28450, Loss: 0.548, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 22:51:02,076: INFO: Iter: 28500, Loss: 0.824, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:51:35,901: INFO: Iter: 28550, Loss: 0.814, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:52:09,928: INFO: Iter: 28600, Loss: 0.846, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:52:43,172: INFO: Iter: 28650, Loss: 1.005, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:53:17,048: INFO: Iter: 28700, Loss: 0.769, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:53:51,097: INFO: Iter: 28750, Loss: 0.559, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 22:54:24,773: INFO: Iter: 28800, Loss: 1.098, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:54:58,461: INFO: Iter: 28850, Loss: 0.555, Accuracy: 1.000, Learning Rate: 0.001
2017-10-22 22:55:32,252: INFO: Iter: 28900, Loss: 0.897, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:56:06,093: INFO: Iter: 28950, Loss: 0.679, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:56:40,013: INFO: Iter: 29000, Loss: 1.010, Accuracy: 0.600, Learning Rate: 0.001
2017-10-22 22:57:13,651: INFO: Iter: 29050, Loss: 1.068, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 22:57:47,499: INFO: Iter: 29100, Loss: 1.256, Accuracy: 0.200, Learning Rate: 0.001
2017-10-22 22:58:21,256: INFO: Iter: 29150, Loss: 1.249, Accuracy: 0.400, Learning Rate: 0.001
2017-10-22 22:58:54,895: INFO: Iter: 29200, Loss: 0.867, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 22:59:29,320: INFO: Iter: 29250, Loss: 0.386, Accuracy: 0.800, Learning Rate: 0.001
2017-10-22 23:00:02,736: INFO: Keyboard Interrupt? Gracefully quitting
2017-10-22 23:00:02,737: INFO: The training is done.

2017-10-22 23:10:53,981: INFO: *** NEW RUN ***
2017-10-22 23:10:53,982: INFO: filename: trained_model_2017.10.22-23.10.53
2017-10-22 23:10:53,983: INFO: n_epochs: 250
2017-10-22 23:10:53,983: INFO: n_hidden: 32
2017-10-22 23:10:53,983: INFO: batch_size: 5
2017-10-22 23:10:53,984: INFO: dropout_enabled: True
2017-10-22 23:10:53,984: INFO: n_layers: 1
2017-10-22 23:10:53,984: INFO: exp_decay_enabled: False
2017-10-22 23:10:53,984: INFO: reg_enabled: False

2017-10-22 23:10:56,256: INFO: The training shall begin.
2017-10-22 23:10:58,994: INFO: Keyboard Interrupt? Gracefully quitting
2017-10-22 23:10:58,994: INFO: The training is done.

2017-10-22 23:11:00,357: INFO: *** NEW RUN ***
2017-10-22 23:11:00,357: INFO: filename: trained_model_2017.10.22-23.11.00
2017-10-22 23:11:00,358: INFO: n_epochs: 250
2017-10-22 23:11:00,358: INFO: n_hidden: 32
2017-10-22 23:11:00,358: INFO: batch_size: 5
2017-10-22 23:11:00,358: INFO: dropout_enabled: True
2017-10-22 23:11:00,358: INFO: n_layers: 1
2017-10-22 23:11:00,358: INFO: exp_decay_enabled: False
2017-10-22 23:11:00,359: INFO: reg_enabled: False

2017-10-22 23:11:01,174: INFO: Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled
	 [[Node: Input_Batch/input_producer/input_producer_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_STRING], timeout_ms=-1, _device="/job:localhost/replica:0/task:0/cpu:0"](Input_Batch/input_producer, Input_Batch/input_producer/limit_epochs)]]
2017-10-23 00:43:07,614: INFO: *** NEW RUN ***
2017-10-23 00:43:42,666: INFO: *** NEW RUN ***
2017-10-23 00:43:42,667: INFO: filename: trained_model_2017.10.23-00.43.42
2017-10-23 00:43:42,667: INFO: n_epochs: 250
2017-10-23 00:43:42,667: INFO: n_hidden: 32
2017-10-23 00:43:42,667: INFO: batch_size: 5
2017-10-23 00:43:42,668: INFO: n_layers: 3
2017-10-23 00:43:42,668: INFO: exp_decay_enabled: False
2017-10-23 00:43:42,668: INFO: static_lr_val: 0.100000
2017-10-23 00:43:42,668: INFO: Reg Type: None
2017-10-23 00:43:42,668: INFO:   Dropout Prob: 0.500000
2017-10-23 00:43:42,668: INFO:   Beta: 0.010000

2017-10-23 00:43:46,115: INFO: The training shall begin.
2017-10-23 00:43:54,539: INFO: Epoch: 0, Iter: 0, Loss: 7.948, Accuracy: 0.400, Learning Rate: 0.100
2017-10-23 00:43:55,664: INFO: The training is done.

2017-10-23 00:45:02,400: INFO: *** NEW RUN ***
2017-10-23 00:45:02,400: INFO: filename: trained_model_2017.10.23-00.45.02
2017-10-23 00:45:02,400: INFO: n_epochs: 250
2017-10-23 00:45:02,401: INFO: n_hidden: 32
2017-10-23 00:45:02,401: INFO: batch_size: 5
2017-10-23 00:45:02,401: INFO: n_layers: 3
2017-10-23 00:45:02,401: INFO: exp_decay_enabled: False
2017-10-23 00:45:02,401: INFO: static_lr_val: 0.100000
2017-10-23 00:45:02,401: INFO: Reg Type: None
2017-10-23 00:45:02,402: INFO:   Dropout Prob: 0.500000
2017-10-23 00:45:02,402: INFO:   Beta: 0.010000

2017-10-23 00:45:05,886: INFO: The training shall begin.
2017-10-23 00:45:14,268: INFO: Epoch: 0, Iter: 0, Loss: 1.233, Accuracy: 0.600, Learning Rate: 0.100
2017-10-23 00:46:21,206: INFO: Epoch: 0, Iter: 50, Loss: 1.146, Accuracy: 0.600, Learning Rate: 0.100
2017-10-23 00:47:30,501: INFO: Epoch: 0, Iter: 100, Loss: 1.353, Accuracy: 0.200, Learning Rate: 0.100
2017-10-23 00:48:37,024: INFO: Epoch: 0, Iter: 150, Loss: 1.102, Accuracy: 0.400, Learning Rate: 0.100
2017-10-23 00:49:44,802: INFO: Epoch: 0, Iter: 200, Loss: 1.395, Accuracy: 0.200, Learning Rate: 0.100
2017-10-23 00:50:21,719: INFO: Keyboard Interrupt? Gracefully quitting
2017-10-23 00:50:21,720: INFO: The training is done.

2017-10-23 01:48:35,084: INFO: *** NEW RUN ***
2017-10-23 01:48:35,085: INFO: filename: trained_model_2017.10.23-01.48.34
2017-10-23 01:48:35,085: INFO: n_epochs: 250
2017-10-23 01:48:35,086: INFO: n_hidden: 32
2017-10-23 01:48:35,086: INFO: batch_size: 5
2017-10-23 01:48:35,086: INFO: n_layers: 3
2017-10-23 01:48:35,086: INFO: exp_decay_enabled: False
2017-10-23 01:48:35,086: INFO: static_lr_val: 0.100000
2017-10-23 01:48:35,087: INFO: Reg Type: None
2017-10-23 01:48:35,087: INFO:   Dropout Prob: 0.500000
2017-10-23 01:48:35,087: INFO:   Beta: 0.010000

2017-10-23 01:48:37,761: INFO: Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled
	 [[Node: Input_Batch/input_producer/input_producer_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_STRING], timeout_ms=-1, _device="/job:localhost/replica:0/task:0/cpu:0"](Input_Batch/input_producer, Input_Batch/input_producer/limit_epochs)]]
2017-10-23 02:23:10,490: INFO: *** NEW RUN ***
2017-10-23 02:23:10,490: INFO: filename: trained_model_2017.10.23-02.23.10
2017-10-23 02:23:10,490: INFO: n_epochs: 500
2017-10-23 02:23:10,491: INFO: n_hidden: 32
2017-10-23 02:23:10,491: INFO: batch_size: 5
2017-10-23 02:23:10,491: INFO: n_layers: 3
2017-10-23 02:23:10,491: INFO: exp_decay_enabled: False
2017-10-23 02:23:10,491: INFO: static_lr_val: 0.050
2017-10-23 02:23:10,492: INFO: Reg Type: None
2017-10-23 02:23:10,492: INFO:   Dropout Prob: 0.50
2017-10-23 02:23:10,492: INFO:   Beta: 0.010

2017-10-23 02:23:13,972: INFO: The training shall begin.
2017-10-23 02:23:22,373: INFO: Epoch: 0, Iter: 0, Loss: 6.161, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 02:24:24,854: INFO: Epoch: 0, Iter: 50, Loss: 1.118, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 02:25:33,594: INFO: Epoch: 0, Iter: 100, Loss: 1.080, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 02:26:38,943: INFO: Epoch: 0, Iter: 150, Loss: 1.288, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 02:27:41,514: INFO: Epoch: 0, Iter: 200, Loss: 1.303, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 02:28:42,583: INFO: Epoch: 1, Iter: 250, Loss: 0.817, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 02:29:42,763: INFO: Epoch: 1, Iter: 300, Loss: 0.969, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 02:30:42,839: INFO: Epoch: 1, Iter: 350, Loss: 1.257, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 02:31:43,425: INFO: Epoch: 1, Iter: 400, Loss: 1.221, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 02:32:44,174: INFO: Epoch: 2, Iter: 450, Loss: 0.988, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 02:33:44,743: INFO: Epoch: 2, Iter: 500, Loss: 1.047, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 02:34:45,134: INFO: Epoch: 2, Iter: 550, Loss: 1.121, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 02:35:45,380: INFO: Epoch: 2, Iter: 600, Loss: 1.169, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 02:36:46,053: INFO: Epoch: 3, Iter: 650, Loss: 0.856, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 02:37:46,054: INFO: Epoch: 3, Iter: 700, Loss: 1.290, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 02:38:46,433: INFO: Epoch: 3, Iter: 750, Loss: 1.111, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 02:39:47,043: INFO: Epoch: 3, Iter: 800, Loss: 1.066, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 02:40:47,471: INFO: Epoch: 4, Iter: 850, Loss: 1.158, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 02:41:47,595: INFO: Epoch: 4, Iter: 900, Loss: 1.106, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 02:42:48,232: INFO: Epoch: 4, Iter: 950, Loss: 1.124, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 02:43:48,845: INFO: Epoch: 4, Iter: 1000, Loss: 1.031, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 02:44:49,258: INFO: Epoch: 5, Iter: 1050, Loss: 0.975, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 02:45:49,649: INFO: Epoch: 5, Iter: 1100, Loss: 0.974, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 02:46:50,626: INFO: Epoch: 5, Iter: 1150, Loss: 1.132, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 02:47:51,198: INFO: Epoch: 5, Iter: 1200, Loss: 1.067, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 02:48:52,242: INFO: Epoch: 5, Iter: 1250, Loss: 1.144, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 02:49:52,839: INFO: Epoch: 6, Iter: 1300, Loss: 0.993, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 02:50:53,078: INFO: Epoch: 6, Iter: 1350, Loss: 1.239, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 02:51:53,748: INFO: Epoch: 6, Iter: 1400, Loss: 0.953, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 02:52:54,209: INFO: Epoch: 6, Iter: 1450, Loss: 1.308, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 02:53:54,772: INFO: Epoch: 7, Iter: 1500, Loss: 1.305, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 02:54:55,450: INFO: Epoch: 7, Iter: 1550, Loss: 0.944, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 02:55:55,747: INFO: Epoch: 7, Iter: 1600, Loss: 1.134, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 02:56:56,617: INFO: Epoch: 7, Iter: 1650, Loss: 1.134, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 02:57:57,126: INFO: Epoch: 8, Iter: 1700, Loss: 1.201, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 02:58:57,532: INFO: Epoch: 8, Iter: 1750, Loss: 1.067, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 02:59:58,060: INFO: Epoch: 8, Iter: 1800, Loss: 0.932, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 03:00:58,623: INFO: Epoch: 8, Iter: 1850, Loss: 0.855, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 03:01:59,363: INFO: Epoch: 9, Iter: 1900, Loss: 1.377, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 03:02:59,912: INFO: Epoch: 9, Iter: 1950, Loss: 1.012, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 03:04:00,620: INFO: Epoch: 9, Iter: 2000, Loss: 1.208, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 03:05:00,747: INFO: Epoch: 9, Iter: 2050, Loss: 1.263, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 03:06:01,351: INFO: Epoch: 10, Iter: 2100, Loss: 1.198, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 03:07:02,147: INFO: Epoch: 10, Iter: 2150, Loss: 1.112, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 03:08:02,530: INFO: Epoch: 10, Iter: 2200, Loss: 0.994, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 03:09:03,076: INFO: Epoch: 10, Iter: 2250, Loss: 1.062, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 03:10:03,183: INFO: Epoch: 10, Iter: 2300, Loss: 1.217, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 03:11:03,342: INFO: Epoch: 11, Iter: 2350, Loss: 1.029, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 03:12:03,633: INFO: Epoch: 11, Iter: 2400, Loss: 1.097, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 03:13:04,373: INFO: Epoch: 11, Iter: 2450, Loss: 1.095, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 03:14:05,039: INFO: Epoch: 11, Iter: 2500, Loss: 1.028, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 03:15:05,132: INFO: Epoch: 12, Iter: 2550, Loss: 0.974, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 03:16:05,225: INFO: Epoch: 12, Iter: 2600, Loss: 1.201, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 03:17:05,846: INFO: Epoch: 12, Iter: 2650, Loss: 1.052, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 03:18:06,364: INFO: Epoch: 12, Iter: 2700, Loss: 1.137, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 03:19:06,414: INFO: Epoch: 13, Iter: 2750, Loss: 1.377, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 03:20:07,030: INFO: Epoch: 13, Iter: 2800, Loss: 1.524, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 03:21:07,427: INFO: Epoch: 13, Iter: 2850, Loss: 1.251, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 03:22:07,832: INFO: Epoch: 13, Iter: 2900, Loss: 1.082, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 03:23:08,644: INFO: Epoch: 14, Iter: 2950, Loss: 1.064, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 03:24:08,947: INFO: Epoch: 14, Iter: 3000, Loss: 0.971, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 03:25:09,191: INFO: Epoch: 14, Iter: 3050, Loss: 1.209, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 03:26:09,810: INFO: Epoch: 14, Iter: 3100, Loss: 0.957, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 03:27:10,214: INFO: Epoch: 15, Iter: 3150, Loss: 1.117, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 03:28:10,607: INFO: Epoch: 15, Iter: 3200, Loss: 1.149, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 03:29:11,455: INFO: Epoch: 15, Iter: 3250, Loss: 1.300, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 03:30:11,713: INFO: Epoch: 15, Iter: 3300, Loss: 1.049, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 03:31:12,469: INFO: Epoch: 15, Iter: 3350, Loss: 1.090, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 03:32:12,933: INFO: Epoch: 16, Iter: 3400, Loss: 0.754, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 03:33:13,764: INFO: Epoch: 16, Iter: 3450, Loss: 1.029, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 03:34:14,308: INFO: Epoch: 16, Iter: 3500, Loss: 1.075, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 03:35:14,910: INFO: Epoch: 16, Iter: 3550, Loss: 1.304, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 03:36:14,854: INFO: Epoch: 17, Iter: 3600, Loss: 0.844, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 03:37:15,190: INFO: Epoch: 17, Iter: 3650, Loss: 1.340, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 03:38:15,662: INFO: Epoch: 17, Iter: 3700, Loss: 0.980, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 03:39:16,141: INFO: Epoch: 17, Iter: 3750, Loss: 1.112, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 03:40:16,504: INFO: Epoch: 18, Iter: 3800, Loss: 0.975, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 03:41:17,229: INFO: Epoch: 18, Iter: 3850, Loss: 1.217, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 03:42:18,129: INFO: Epoch: 18, Iter: 3900, Loss: 0.951, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 03:43:18,996: INFO: Epoch: 18, Iter: 3950, Loss: 1.278, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 03:44:19,009: INFO: Epoch: 19, Iter: 4000, Loss: 1.101, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 03:45:19,250: INFO: Epoch: 19, Iter: 4050, Loss: 1.069, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 03:46:19,807: INFO: Epoch: 19, Iter: 4100, Loss: 0.893, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 03:47:20,447: INFO: Epoch: 19, Iter: 4150, Loss: 1.178, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 03:48:21,064: INFO: Epoch: 20, Iter: 4200, Loss: 0.905, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 03:49:21,396: INFO: Epoch: 20, Iter: 4250, Loss: 1.019, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 03:50:22,116: INFO: Epoch: 20, Iter: 4300, Loss: 1.036, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 03:51:22,164: INFO: Epoch: 20, Iter: 4350, Loss: 0.868, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 03:52:22,610: INFO: Epoch: 20, Iter: 4400, Loss: 1.197, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 03:53:23,067: INFO: Epoch: 21, Iter: 4450, Loss: 0.845, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 03:54:23,345: INFO: Epoch: 21, Iter: 4500, Loss: 1.142, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 03:55:23,588: INFO: Epoch: 21, Iter: 4550, Loss: 0.919, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 03:56:23,781: INFO: Epoch: 21, Iter: 4600, Loss: 0.893, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 03:57:24,432: INFO: Epoch: 22, Iter: 4650, Loss: 0.984, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 03:58:25,967: INFO: Epoch: 22, Iter: 4700, Loss: 1.122, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 03:59:26,080: INFO: Epoch: 22, Iter: 4750, Loss: 1.092, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 04:00:26,862: INFO: Epoch: 22, Iter: 4800, Loss: 0.911, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 04:01:27,194: INFO: Epoch: 23, Iter: 4850, Loss: 1.255, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 04:02:27,682: INFO: Epoch: 23, Iter: 4900, Loss: 1.157, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 04:03:28,281: INFO: Epoch: 23, Iter: 4950, Loss: 1.088, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 04:04:28,769: INFO: Epoch: 23, Iter: 5000, Loss: 1.193, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 04:05:29,406: INFO: Epoch: 24, Iter: 5050, Loss: 0.966, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 04:06:29,894: INFO: Epoch: 24, Iter: 5100, Loss: 0.978, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 04:07:30,572: INFO: Epoch: 24, Iter: 5150, Loss: 1.162, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 04:08:31,270: INFO: Epoch: 24, Iter: 5200, Loss: 1.196, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 04:09:31,587: INFO: Epoch: 25, Iter: 5250, Loss: 1.327, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 04:10:31,965: INFO: Epoch: 25, Iter: 5300, Loss: 1.015, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 04:11:32,564: INFO: Epoch: 25, Iter: 5350, Loss: 0.968, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 04:12:33,252: INFO: Epoch: 25, Iter: 5400, Loss: 0.969, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 04:13:34,231: INFO: Epoch: 25, Iter: 5450, Loss: 1.097, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 04:14:34,398: INFO: Epoch: 26, Iter: 5500, Loss: 1.022, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 04:15:34,894: INFO: Epoch: 26, Iter: 5550, Loss: 1.010, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 04:16:35,404: INFO: Epoch: 26, Iter: 5600, Loss: 1.174, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 04:17:36,184: INFO: Epoch: 26, Iter: 5650, Loss: 0.846, Accuracy: 1.000, Learning Rate: 0.050
2017-10-23 04:18:36,711: INFO: Epoch: 27, Iter: 5700, Loss: 1.008, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 04:19:37,024: INFO: Epoch: 27, Iter: 5750, Loss: 1.138, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 04:20:37,527: INFO: Epoch: 27, Iter: 5800, Loss: 1.179, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 04:21:38,068: INFO: Epoch: 27, Iter: 5850, Loss: 0.807, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 04:22:38,479: INFO: Epoch: 28, Iter: 5900, Loss: 1.379, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 04:23:38,949: INFO: Epoch: 28, Iter: 5950, Loss: 1.080, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 04:24:39,388: INFO: Epoch: 28, Iter: 6000, Loss: 1.071, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 04:25:39,413: INFO: Epoch: 28, Iter: 6050, Loss: 1.305, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 04:26:39,708: INFO: Epoch: 29, Iter: 6100, Loss: 0.800, Accuracy: 1.000, Learning Rate: 0.050
2017-10-23 04:27:40,207: INFO: Epoch: 29, Iter: 6150, Loss: 1.093, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 04:28:40,822: INFO: Epoch: 29, Iter: 6200, Loss: 0.957, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 04:29:40,963: INFO: Epoch: 29, Iter: 6250, Loss: 1.339, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 04:30:41,099: INFO: Epoch: 30, Iter: 6300, Loss: 0.996, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 04:31:41,298: INFO: Epoch: 30, Iter: 6350, Loss: 1.123, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 04:32:41,814: INFO: Epoch: 30, Iter: 6400, Loss: 0.970, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 04:33:42,431: INFO: Epoch: 30, Iter: 6450, Loss: 0.890, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 04:34:43,030: INFO: Epoch: 30, Iter: 6500, Loss: 1.312, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 04:35:43,115: INFO: Epoch: 31, Iter: 6550, Loss: 1.106, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 04:36:43,798: INFO: Epoch: 31, Iter: 6600, Loss: 0.914, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 04:37:44,345: INFO: Epoch: 31, Iter: 6650, Loss: 1.365, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 04:38:45,664: INFO: Epoch: 31, Iter: 6700, Loss: 1.062, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 04:39:46,370: INFO: Epoch: 32, Iter: 6750, Loss: 1.022, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 04:40:46,856: INFO: Epoch: 32, Iter: 6800, Loss: 1.146, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 04:41:47,146: INFO: Epoch: 32, Iter: 6850, Loss: 1.111, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 04:42:47,752: INFO: Epoch: 32, Iter: 6900, Loss: 1.215, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 04:43:48,326: INFO: Epoch: 33, Iter: 6950, Loss: 1.059, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 04:44:48,534: INFO: Epoch: 33, Iter: 7000, Loss: 1.189, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 04:45:49,116: INFO: Epoch: 33, Iter: 7050, Loss: 1.216, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 04:46:49,972: INFO: Epoch: 33, Iter: 7100, Loss: 1.162, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 04:47:50,133: INFO: Epoch: 34, Iter: 7150, Loss: 1.046, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 04:48:50,421: INFO: Epoch: 34, Iter: 7200, Loss: 1.468, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 04:49:50,576: INFO: Epoch: 34, Iter: 7250, Loss: 0.981, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 04:50:51,053: INFO: Epoch: 34, Iter: 7300, Loss: 1.103, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 04:51:51,374: INFO: Epoch: 35, Iter: 7350, Loss: 1.115, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 04:52:51,789: INFO: Epoch: 35, Iter: 7400, Loss: 1.136, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 04:53:52,385: INFO: Epoch: 35, Iter: 7450, Loss: 0.997, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 04:54:52,630: INFO: Epoch: 35, Iter: 7500, Loss: 1.152, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 04:55:52,698: INFO: Epoch: 35, Iter: 7550, Loss: 1.227, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 04:56:53,243: INFO: Epoch: 36, Iter: 7600, Loss: 0.978, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 04:57:53,605: INFO: Epoch: 36, Iter: 7650, Loss: 1.013, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 04:58:54,078: INFO: Epoch: 36, Iter: 7700, Loss: 1.167, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 04:59:54,644: INFO: Epoch: 36, Iter: 7750, Loss: 1.090, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 05:00:54,925: INFO: Epoch: 37, Iter: 7800, Loss: 1.024, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 05:01:55,054: INFO: Epoch: 37, Iter: 7850, Loss: 0.967, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 05:02:55,396: INFO: Epoch: 37, Iter: 7900, Loss: 1.293, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 05:03:55,809: INFO: Epoch: 37, Iter: 7950, Loss: 1.045, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 05:04:56,138: INFO: Epoch: 38, Iter: 8000, Loss: 1.133, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 05:05:56,438: INFO: Epoch: 38, Iter: 8050, Loss: 0.990, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 05:06:57,137: INFO: Epoch: 38, Iter: 8100, Loss: 1.383, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 05:07:57,544: INFO: Epoch: 38, Iter: 8150, Loss: 1.012, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 05:08:58,032: INFO: Epoch: 39, Iter: 8200, Loss: 1.222, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 05:09:58,296: INFO: Epoch: 39, Iter: 8250, Loss: 1.158, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 05:10:58,571: INFO: Epoch: 39, Iter: 8300, Loss: 0.934, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 05:11:58,766: INFO: Epoch: 39, Iter: 8350, Loss: 1.226, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 05:12:59,239: INFO: Epoch: 40, Iter: 8400, Loss: 1.302, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 05:14:00,058: INFO: Epoch: 40, Iter: 8450, Loss: 1.084, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 05:15:00,230: INFO: Epoch: 40, Iter: 8500, Loss: 0.933, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 05:16:00,436: INFO: Epoch: 40, Iter: 8550, Loss: 1.089, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 05:17:00,861: INFO: Epoch: 40, Iter: 8600, Loss: 1.146, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 05:18:01,426: INFO: Epoch: 41, Iter: 8650, Loss: 1.121, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 05:19:02,032: INFO: Epoch: 41, Iter: 8700, Loss: 1.112, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 05:20:02,670: INFO: Epoch: 41, Iter: 8750, Loss: 1.206, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 05:21:03,202: INFO: Epoch: 41, Iter: 8800, Loss: 0.961, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 05:22:03,448: INFO: Epoch: 42, Iter: 8850, Loss: 1.083, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 05:23:03,993: INFO: Epoch: 42, Iter: 8900, Loss: 1.131, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 05:24:04,600: INFO: Epoch: 42, Iter: 8950, Loss: 0.985, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 05:25:05,136: INFO: Epoch: 42, Iter: 9000, Loss: 0.979, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 05:26:05,517: INFO: Epoch: 43, Iter: 9050, Loss: 1.062, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 05:27:05,986: INFO: Epoch: 43, Iter: 9100, Loss: 1.221, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 05:28:06,471: INFO: Epoch: 43, Iter: 9150, Loss: 1.065, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 05:29:06,918: INFO: Epoch: 43, Iter: 9200, Loss: 0.506, Accuracy: 1.000, Learning Rate: 0.050
2017-10-23 05:30:07,249: INFO: Epoch: 44, Iter: 9250, Loss: 1.200, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 05:31:07,809: INFO: Epoch: 44, Iter: 9300, Loss: 1.055, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 05:32:08,159: INFO: Epoch: 44, Iter: 9350, Loss: 0.963, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 05:33:08,432: INFO: Epoch: 44, Iter: 9400, Loss: 0.788, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 05:34:09,049: INFO: Epoch: 45, Iter: 9450, Loss: 0.816, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 05:35:09,404: INFO: Epoch: 45, Iter: 9500, Loss: 1.168, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 05:36:10,103: INFO: Epoch: 45, Iter: 9550, Loss: 1.119, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 05:37:10,548: INFO: Epoch: 45, Iter: 9600, Loss: 0.963, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 05:38:11,008: INFO: Epoch: 45, Iter: 9650, Loss: 1.144, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 05:39:11,068: INFO: Epoch: 46, Iter: 9700, Loss: 1.632, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 05:40:11,552: INFO: Epoch: 46, Iter: 9750, Loss: 0.987, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 05:41:12,009: INFO: Epoch: 46, Iter: 9800, Loss: 1.162, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 05:42:12,409: INFO: Epoch: 46, Iter: 9850, Loss: 1.090, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 05:43:12,914: INFO: Epoch: 47, Iter: 9900, Loss: 1.468, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 05:44:12,974: INFO: Epoch: 47, Iter: 9950, Loss: 0.800, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 05:45:13,529: INFO: Epoch: 47, Iter: 10000, Loss: 1.103, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 05:46:13,772: INFO: Epoch: 47, Iter: 10050, Loss: 0.942, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 05:47:14,515: INFO: Epoch: 48, Iter: 10100, Loss: 1.170, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 05:48:14,913: INFO: Epoch: 48, Iter: 10150, Loss: 1.106, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 05:49:15,366: INFO: Epoch: 48, Iter: 10200, Loss: 0.766, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 05:50:15,587: INFO: Epoch: 48, Iter: 10250, Loss: 1.144, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 05:51:16,005: INFO: Epoch: 49, Iter: 10300, Loss: 1.101, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 05:52:16,282: INFO: Epoch: 49, Iter: 10350, Loss: 1.041, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 05:53:16,984: INFO: Epoch: 49, Iter: 10400, Loss: 1.118, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 05:54:17,320: INFO: Epoch: 49, Iter: 10450, Loss: 1.137, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 05:55:17,664: INFO: Epoch: 50, Iter: 10500, Loss: 1.077, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 05:56:18,164: INFO: Epoch: 50, Iter: 10550, Loss: 1.021, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 05:57:18,914: INFO: Epoch: 50, Iter: 10600, Loss: 1.024, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 05:58:19,359: INFO: Epoch: 50, Iter: 10650, Loss: 1.180, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 05:59:19,287: INFO: Epoch: 50, Iter: 10700, Loss: 0.885, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 06:00:19,618: INFO: Epoch: 51, Iter: 10750, Loss: 0.802, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 06:01:19,970: INFO: Epoch: 51, Iter: 10800, Loss: 1.216, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 06:02:20,293: INFO: Epoch: 51, Iter: 10850, Loss: 1.011, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 06:03:21,478: INFO: Epoch: 51, Iter: 10900, Loss: 1.145, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 06:04:21,760: INFO: Epoch: 52, Iter: 10950, Loss: 0.653, Accuracy: 1.000, Learning Rate: 0.050
2017-10-23 06:05:21,981: INFO: Epoch: 52, Iter: 11000, Loss: 0.964, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 06:06:22,465: INFO: Epoch: 52, Iter: 11050, Loss: 1.132, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 06:07:22,775: INFO: Epoch: 52, Iter: 11100, Loss: 1.135, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 06:08:23,407: INFO: Epoch: 53, Iter: 11150, Loss: 0.953, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 06:09:23,484: INFO: Epoch: 53, Iter: 11200, Loss: 1.193, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 06:10:23,471: INFO: Epoch: 53, Iter: 11250, Loss: 1.132, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 06:11:23,820: INFO: Epoch: 53, Iter: 11300, Loss: 0.848, Accuracy: 1.000, Learning Rate: 0.050
2017-10-23 06:12:24,608: INFO: Epoch: 54, Iter: 11350, Loss: 1.081, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 06:13:24,943: INFO: Epoch: 54, Iter: 11400, Loss: 1.212, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 06:14:25,883: INFO: Epoch: 54, Iter: 11450, Loss: 0.797, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 06:15:26,214: INFO: Epoch: 54, Iter: 11500, Loss: 1.250, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 06:16:26,587: INFO: Epoch: 55, Iter: 11550, Loss: 0.948, Accuracy: 1.000, Learning Rate: 0.050
2017-10-23 06:17:27,525: INFO: Epoch: 55, Iter: 11600, Loss: 1.230, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 06:18:27,984: INFO: Epoch: 55, Iter: 11650, Loss: 1.042, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 06:19:28,496: INFO: Epoch: 55, Iter: 11700, Loss: 1.033, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 06:20:28,738: INFO: Epoch: 55, Iter: 11750, Loss: 0.849, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 06:21:28,649: INFO: Epoch: 56, Iter: 11800, Loss: 1.323, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 06:22:28,980: INFO: Epoch: 56, Iter: 11850, Loss: 1.055, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 06:23:29,622: INFO: Epoch: 56, Iter: 11900, Loss: 1.097, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 06:24:30,046: INFO: Epoch: 56, Iter: 11950, Loss: 1.155, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 06:25:30,532: INFO: Epoch: 57, Iter: 12000, Loss: 1.085, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 06:26:30,762: INFO: Epoch: 57, Iter: 12050, Loss: 1.078, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 06:27:31,280: INFO: Epoch: 57, Iter: 12100, Loss: 1.353, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 06:28:31,683: INFO: Epoch: 57, Iter: 12150, Loss: 1.082, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 06:29:32,332: INFO: Epoch: 58, Iter: 12200, Loss: 1.142, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 06:30:32,635: INFO: Epoch: 58, Iter: 12250, Loss: 0.929, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 06:31:32,771: INFO: Epoch: 58, Iter: 12300, Loss: 1.261, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 06:32:33,728: INFO: Epoch: 58, Iter: 12350, Loss: 1.083, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 06:33:34,426: INFO: Epoch: 59, Iter: 12400, Loss: 0.995, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 06:34:34,509: INFO: Epoch: 59, Iter: 12450, Loss: 1.139, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 06:35:34,868: INFO: Epoch: 59, Iter: 12500, Loss: 1.316, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 06:36:35,285: INFO: Epoch: 59, Iter: 12550, Loss: 1.344, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 06:37:35,968: INFO: Epoch: 60, Iter: 12600, Loss: 1.285, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 06:38:36,409: INFO: Epoch: 60, Iter: 12650, Loss: 1.075, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 06:39:36,505: INFO: Epoch: 60, Iter: 12700, Loss: 0.907, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 06:40:36,909: INFO: Epoch: 60, Iter: 12750, Loss: 0.903, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 06:41:37,757: INFO: Epoch: 60, Iter: 12800, Loss: 0.904, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 06:42:38,103: INFO: Epoch: 61, Iter: 12850, Loss: 1.112, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 06:43:38,894: INFO: Epoch: 61, Iter: 12900, Loss: 1.181, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 06:44:39,329: INFO: Epoch: 61, Iter: 12950, Loss: 1.221, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 06:45:39,609: INFO: Epoch: 61, Iter: 13000, Loss: 1.258, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 06:46:39,845: INFO: Epoch: 62, Iter: 13050, Loss: 0.951, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 06:47:40,530: INFO: Epoch: 62, Iter: 13100, Loss: 1.153, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 06:48:40,909: INFO: Epoch: 62, Iter: 13150, Loss: 1.052, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 06:49:41,168: INFO: Epoch: 62, Iter: 13200, Loss: 0.955, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 06:50:41,593: INFO: Epoch: 63, Iter: 13250, Loss: 1.399, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 06:51:41,782: INFO: Epoch: 63, Iter: 13300, Loss: 0.970, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 06:52:41,698: INFO: Epoch: 63, Iter: 13350, Loss: 1.081, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 06:53:42,296: INFO: Epoch: 63, Iter: 13400, Loss: 1.194, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 06:54:42,687: INFO: Epoch: 64, Iter: 13450, Loss: 0.935, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 06:55:43,209: INFO: Epoch: 64, Iter: 13500, Loss: 1.040, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 06:56:43,887: INFO: Epoch: 64, Iter: 13550, Loss: 1.137, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 06:57:44,282: INFO: Epoch: 64, Iter: 13600, Loss: 1.155, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 06:58:45,172: INFO: Epoch: 65, Iter: 13650, Loss: 1.085, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 06:59:46,407: INFO: Epoch: 65, Iter: 13700, Loss: 0.598, Accuracy: 1.000, Learning Rate: 0.050
2017-10-23 07:00:46,157: INFO: Epoch: 65, Iter: 13750, Loss: 1.187, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 07:01:45,978: INFO: Epoch: 65, Iter: 13800, Loss: 1.002, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 07:02:46,126: INFO: Epoch: 65, Iter: 13850, Loss: 1.047, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 07:03:46,381: INFO: Epoch: 66, Iter: 13900, Loss: 1.145, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 07:04:46,378: INFO: Epoch: 66, Iter: 13950, Loss: 0.883, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 07:05:46,470: INFO: Epoch: 66, Iter: 14000, Loss: 0.791, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 07:06:46,529: INFO: Epoch: 66, Iter: 14050, Loss: 1.053, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 07:07:46,685: INFO: Epoch: 67, Iter: 14100, Loss: 0.850, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 07:08:48,406: INFO: Epoch: 67, Iter: 14150, Loss: 1.005, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 07:09:48,121: INFO: Epoch: 67, Iter: 14200, Loss: 1.324, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 07:10:48,228: INFO: Epoch: 67, Iter: 14250, Loss: 0.966, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 07:11:48,007: INFO: Epoch: 68, Iter: 14300, Loss: 1.345, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 07:12:47,882: INFO: Epoch: 68, Iter: 14350, Loss: 1.278, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 07:13:47,865: INFO: Epoch: 68, Iter: 14400, Loss: 1.170, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 07:14:47,905: INFO: Epoch: 68, Iter: 14450, Loss: 1.127, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 07:15:47,866: INFO: Epoch: 69, Iter: 14500, Loss: 1.090, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 07:16:48,106: INFO: Epoch: 69, Iter: 14550, Loss: 1.247, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 07:17:48,233: INFO: Epoch: 69, Iter: 14600, Loss: 0.961, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 07:18:48,151: INFO: Epoch: 69, Iter: 14650, Loss: 0.879, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 07:19:48,083: INFO: Epoch: 70, Iter: 14700, Loss: 0.755, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 07:20:48,113: INFO: Epoch: 70, Iter: 14750, Loss: 1.021, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 07:21:47,936: INFO: Epoch: 70, Iter: 14800, Loss: 0.846, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 07:22:47,893: INFO: Epoch: 70, Iter: 14850, Loss: 1.089, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 07:23:48,404: INFO: Epoch: 70, Iter: 14900, Loss: 1.071, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 07:24:48,353: INFO: Epoch: 71, Iter: 14950, Loss: 1.239, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 07:25:47,893: INFO: Epoch: 71, Iter: 15000, Loss: 1.110, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 07:26:48,209: INFO: Epoch: 71, Iter: 15050, Loss: 1.018, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 07:27:48,020: INFO: Epoch: 71, Iter: 15100, Loss: 1.096, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 07:28:48,319: INFO: Epoch: 72, Iter: 15150, Loss: 1.071, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 07:29:48,488: INFO: Epoch: 72, Iter: 15200, Loss: 0.988, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 07:30:48,598: INFO: Epoch: 72, Iter: 15250, Loss: 0.892, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 07:31:48,939: INFO: Epoch: 72, Iter: 15300, Loss: 1.030, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 07:32:49,451: INFO: Epoch: 73, Iter: 15350, Loss: 0.958, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 07:33:49,993: INFO: Epoch: 73, Iter: 15400, Loss: 0.951, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 07:34:50,586: INFO: Epoch: 73, Iter: 15450, Loss: 0.786, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 07:35:50,862: INFO: Epoch: 73, Iter: 15500, Loss: 1.255, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 07:36:51,684: INFO: Epoch: 74, Iter: 15550, Loss: 1.147, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 07:37:52,429: INFO: Epoch: 74, Iter: 15600, Loss: 1.119, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 07:38:52,847: INFO: Epoch: 74, Iter: 15650, Loss: 1.151, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 07:39:53,145: INFO: Epoch: 74, Iter: 15700, Loss: 0.999, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 07:40:53,779: INFO: Epoch: 75, Iter: 15750, Loss: 1.325, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 07:41:54,070: INFO: Epoch: 75, Iter: 15800, Loss: 1.224, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 07:42:54,921: INFO: Epoch: 75, Iter: 15850, Loss: 0.983, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 07:43:55,386: INFO: Epoch: 75, Iter: 15900, Loss: 1.220, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 07:44:55,831: INFO: Epoch: 75, Iter: 15950, Loss: 1.127, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 07:45:56,204: INFO: Epoch: 76, Iter: 16000, Loss: 0.972, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 07:46:56,787: INFO: Epoch: 76, Iter: 16050, Loss: 1.197, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 07:47:57,200: INFO: Epoch: 76, Iter: 16100, Loss: 1.120, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 07:48:57,874: INFO: Epoch: 76, Iter: 16150, Loss: 1.041, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 07:49:58,655: INFO: Epoch: 77, Iter: 16200, Loss: 1.076, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 07:50:58,910: INFO: Epoch: 77, Iter: 16250, Loss: 1.138, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 07:51:59,586: INFO: Epoch: 77, Iter: 16300, Loss: 1.136, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 07:53:00,058: INFO: Epoch: 77, Iter: 16350, Loss: 0.853, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 07:54:00,101: INFO: Epoch: 78, Iter: 16400, Loss: 1.002, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 07:55:00,553: INFO: Epoch: 78, Iter: 16450, Loss: 0.718, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 07:56:00,922: INFO: Epoch: 78, Iter: 16500, Loss: 0.998, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 07:57:01,476: INFO: Epoch: 78, Iter: 16550, Loss: 1.080, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 07:58:02,046: INFO: Epoch: 79, Iter: 16600, Loss: 1.107, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 07:59:02,365: INFO: Epoch: 79, Iter: 16650, Loss: 0.954, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 08:00:02,853: INFO: Epoch: 79, Iter: 16700, Loss: 1.002, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 08:01:03,216: INFO: Epoch: 79, Iter: 16750, Loss: 1.135, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 08:02:03,859: INFO: Epoch: 80, Iter: 16800, Loss: 0.832, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 08:03:04,546: INFO: Epoch: 80, Iter: 16850, Loss: 0.974, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 08:04:05,300: INFO: Epoch: 80, Iter: 16900, Loss: 0.843, Accuracy: 1.000, Learning Rate: 0.050
2017-10-23 08:05:05,801: INFO: Epoch: 80, Iter: 16950, Loss: 0.957, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 08:06:06,655: INFO: Epoch: 80, Iter: 17000, Loss: 1.289, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 08:07:07,057: INFO: Epoch: 81, Iter: 17050, Loss: 1.014, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 08:08:08,277: INFO: Epoch: 81, Iter: 17100, Loss: 1.186, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 08:09:08,941: INFO: Epoch: 81, Iter: 17150, Loss: 1.074, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 08:10:09,335: INFO: Epoch: 81, Iter: 17200, Loss: 1.099, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 08:11:09,806: INFO: Epoch: 82, Iter: 17250, Loss: 1.061, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 08:12:10,142: INFO: Epoch: 82, Iter: 17300, Loss: 1.154, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 08:13:10,787: INFO: Epoch: 82, Iter: 17350, Loss: 1.326, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 08:14:11,490: INFO: Epoch: 82, Iter: 17400, Loss: 0.967, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 08:15:11,855: INFO: Epoch: 83, Iter: 17450, Loss: 1.087, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 08:16:12,014: INFO: Epoch: 83, Iter: 17500, Loss: 1.046, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 08:17:12,520: INFO: Epoch: 83, Iter: 17550, Loss: 1.128, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 08:18:12,963: INFO: Epoch: 83, Iter: 17600, Loss: 0.757, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 08:19:13,301: INFO: Epoch: 84, Iter: 17650, Loss: 1.098, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 08:20:13,735: INFO: Epoch: 84, Iter: 17700, Loss: 0.991, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 08:21:13,976: INFO: Epoch: 84, Iter: 17750, Loss: 1.244, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 08:22:14,448: INFO: Epoch: 84, Iter: 17800, Loss: 1.178, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 08:23:15,417: INFO: Epoch: 85, Iter: 17850, Loss: 0.815, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 08:24:15,784: INFO: Epoch: 85, Iter: 17900, Loss: 0.973, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 08:25:16,016: INFO: Epoch: 85, Iter: 17950, Loss: 1.193, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 08:26:16,371: INFO: Epoch: 85, Iter: 18000, Loss: 1.115, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 08:27:16,748: INFO: Epoch: 85, Iter: 18050, Loss: 0.724, Accuracy: 1.000, Learning Rate: 0.050
2017-10-23 08:28:17,319: INFO: Epoch: 86, Iter: 18100, Loss: 0.797, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 08:29:17,790: INFO: Epoch: 86, Iter: 18150, Loss: 1.049, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 08:30:17,887: INFO: Epoch: 86, Iter: 18200, Loss: 1.022, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 08:31:18,035: INFO: Epoch: 86, Iter: 18250, Loss: 1.065, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 08:32:18,699: INFO: Epoch: 87, Iter: 18300, Loss: 1.115, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 08:33:19,984: INFO: Epoch: 87, Iter: 18350, Loss: 1.165, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 08:34:20,688: INFO: Epoch: 87, Iter: 18400, Loss: 1.176, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 08:35:20,830: INFO: Epoch: 87, Iter: 18450, Loss: 1.124, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 08:36:21,202: INFO: Epoch: 88, Iter: 18500, Loss: 1.140, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 08:37:22,009: INFO: Epoch: 88, Iter: 18550, Loss: 0.767, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 08:38:22,892: INFO: Epoch: 88, Iter: 18600, Loss: 1.182, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 08:39:23,166: INFO: Epoch: 88, Iter: 18650, Loss: 1.417, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 08:40:23,477: INFO: Epoch: 89, Iter: 18700, Loss: 1.129, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 08:41:23,519: INFO: Epoch: 89, Iter: 18750, Loss: 1.222, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 08:42:23,938: INFO: Epoch: 89, Iter: 18800, Loss: 0.931, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 08:43:24,633: INFO: Epoch: 89, Iter: 18850, Loss: 0.887, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 08:44:24,945: INFO: Epoch: 90, Iter: 18900, Loss: 1.304, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 08:45:25,290: INFO: Epoch: 90, Iter: 18950, Loss: 1.058, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 08:46:25,884: INFO: Epoch: 90, Iter: 19000, Loss: 1.621, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 08:47:26,476: INFO: Epoch: 90, Iter: 19050, Loss: 0.952, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 08:48:27,208: INFO: Epoch: 90, Iter: 19100, Loss: 1.027, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 08:49:27,516: INFO: Epoch: 91, Iter: 19150, Loss: 1.235, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 08:50:28,141: INFO: Epoch: 91, Iter: 19200, Loss: 1.131, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 08:51:28,793: INFO: Epoch: 91, Iter: 19250, Loss: 1.185, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 08:52:29,835: INFO: Epoch: 91, Iter: 19300, Loss: 0.988, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 08:53:30,601: INFO: Epoch: 92, Iter: 19350, Loss: 0.974, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 08:54:30,797: INFO: Epoch: 92, Iter: 19400, Loss: 0.960, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 08:55:31,100: INFO: Epoch: 92, Iter: 19450, Loss: 0.830, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 08:56:31,479: INFO: Epoch: 92, Iter: 19500, Loss: 1.482, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 08:57:32,466: INFO: Epoch: 93, Iter: 19550, Loss: 0.836, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 08:58:33,158: INFO: Epoch: 93, Iter: 19600, Loss: 1.268, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 08:59:33,657: INFO: Epoch: 93, Iter: 19650, Loss: 1.112, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 09:00:34,207: INFO: Epoch: 93, Iter: 19700, Loss: 1.243, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 09:01:35,668: INFO: Epoch: 94, Iter: 19750, Loss: 1.212, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 09:02:36,210: INFO: Epoch: 94, Iter: 19800, Loss: 1.151, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 09:03:37,211: INFO: Epoch: 94, Iter: 19850, Loss: 0.808, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 09:04:37,364: INFO: Epoch: 94, Iter: 19900, Loss: 0.773, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 09:05:37,861: INFO: Epoch: 95, Iter: 19950, Loss: 1.044, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 09:06:38,176: INFO: Epoch: 95, Iter: 20000, Loss: 1.001, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 09:07:38,973: INFO: Epoch: 95, Iter: 20050, Loss: 1.097, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 09:08:39,738: INFO: Epoch: 95, Iter: 20100, Loss: 1.025, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 09:09:40,105: INFO: Epoch: 95, Iter: 20150, Loss: 1.098, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 09:10:40,736: INFO: Epoch: 96, Iter: 20200, Loss: 1.000, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 09:11:41,172: INFO: Epoch: 96, Iter: 20250, Loss: 0.853, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 09:12:41,483: INFO: Epoch: 96, Iter: 20300, Loss: 1.008, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 09:13:41,988: INFO: Epoch: 96, Iter: 20350, Loss: 0.907, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 09:14:42,084: INFO: Epoch: 97, Iter: 20400, Loss: 0.967, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 09:15:42,427: INFO: Epoch: 97, Iter: 20450, Loss: 1.060, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 09:16:43,345: INFO: Epoch: 97, Iter: 20500, Loss: 1.192, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 09:17:44,026: INFO: Epoch: 97, Iter: 20550, Loss: 1.158, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 09:18:44,547: INFO: Epoch: 98, Iter: 20600, Loss: 0.984, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 09:19:45,123: INFO: Epoch: 98, Iter: 20650, Loss: 0.959, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 09:20:45,738: INFO: Epoch: 98, Iter: 20700, Loss: 1.111, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 09:21:50,480: INFO: Epoch: 98, Iter: 20750, Loss: 1.020, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 09:22:55,867: INFO: Epoch: 99, Iter: 20800, Loss: 0.930, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 09:23:58,740: INFO: Epoch: 99, Iter: 20850, Loss: 1.175, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 09:24:59,696: INFO: Epoch: 99, Iter: 20900, Loss: 0.959, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 09:26:00,376: INFO: Epoch: 99, Iter: 20950, Loss: 1.030, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 09:27:00,966: INFO: Epoch: 100, Iter: 21000, Loss: 1.110, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 09:28:01,071: INFO: Epoch: 100, Iter: 21050, Loss: 1.031, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 09:29:01,435: INFO: Epoch: 100, Iter: 21100, Loss: 1.006, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 09:30:02,050: INFO: Epoch: 100, Iter: 21150, Loss: 1.034, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 09:31:03,221: INFO: Epoch: 100, Iter: 21200, Loss: 1.122, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 09:32:03,571: INFO: Epoch: 101, Iter: 21250, Loss: 1.106, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 09:33:04,427: INFO: Epoch: 101, Iter: 21300, Loss: 1.083, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 09:34:04,868: INFO: Epoch: 101, Iter: 21350, Loss: 1.390, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 09:35:05,356: INFO: Epoch: 101, Iter: 21400, Loss: 0.962, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 09:36:05,927: INFO: Epoch: 102, Iter: 21450, Loss: 1.187, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 09:37:06,637: INFO: Epoch: 102, Iter: 21500, Loss: 1.072, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 09:38:06,904: INFO: Epoch: 102, Iter: 21550, Loss: 0.994, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 09:39:07,073: INFO: Epoch: 102, Iter: 21600, Loss: 0.838, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 09:40:07,288: INFO: Epoch: 103, Iter: 21650, Loss: 1.158, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 09:41:07,602: INFO: Epoch: 103, Iter: 21700, Loss: 1.119, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 09:42:08,007: INFO: Epoch: 103, Iter: 21750, Loss: 0.753, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 09:43:09,103: INFO: Epoch: 103, Iter: 21800, Loss: 1.095, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 09:44:09,141: INFO: Epoch: 104, Iter: 21850, Loss: 1.119, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 09:45:09,493: INFO: Epoch: 104, Iter: 21900, Loss: 1.165, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 09:46:09,916: INFO: Epoch: 104, Iter: 21950, Loss: 0.921, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 09:47:10,514: INFO: Epoch: 104, Iter: 22000, Loss: 0.954, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 09:48:11,078: INFO: Epoch: 105, Iter: 22050, Loss: 1.145, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 09:49:11,429: INFO: Epoch: 105, Iter: 22100, Loss: 1.384, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 09:50:11,582: INFO: Epoch: 105, Iter: 22150, Loss: 0.990, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 09:51:12,124: INFO: Epoch: 105, Iter: 22200, Loss: 1.189, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 09:52:12,424: INFO: Epoch: 105, Iter: 22250, Loss: 1.124, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 09:53:13,016: INFO: Epoch: 106, Iter: 22300, Loss: 0.986, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 09:54:13,436: INFO: Epoch: 106, Iter: 22350, Loss: 0.990, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 09:55:14,098: INFO: Epoch: 106, Iter: 22400, Loss: 0.966, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 09:56:14,258: INFO: Epoch: 106, Iter: 22450, Loss: 0.918, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 09:57:15,233: INFO: Epoch: 107, Iter: 22500, Loss: 1.009, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 09:58:15,968: INFO: Epoch: 107, Iter: 22550, Loss: 0.896, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 09:59:16,132: INFO: Epoch: 107, Iter: 22600, Loss: 1.126, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 10:00:17,209: INFO: Epoch: 107, Iter: 22650, Loss: 0.892, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 10:01:17,947: INFO: Epoch: 108, Iter: 22700, Loss: 0.846, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 10:02:18,438: INFO: Epoch: 108, Iter: 22750, Loss: 1.358, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 10:03:19,031: INFO: Epoch: 108, Iter: 22800, Loss: 1.177, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 10:04:19,139: INFO: Epoch: 108, Iter: 22850, Loss: 1.072, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 10:05:19,616: INFO: Epoch: 109, Iter: 22900, Loss: 1.421, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 10:06:20,007: INFO: Epoch: 109, Iter: 22950, Loss: 0.998, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 10:07:20,683: INFO: Epoch: 109, Iter: 23000, Loss: 1.096, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 10:08:21,274: INFO: Epoch: 109, Iter: 23050, Loss: 1.012, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 10:09:21,635: INFO: Epoch: 110, Iter: 23100, Loss: 1.268, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 10:10:21,820: INFO: Epoch: 110, Iter: 23150, Loss: 1.381, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 10:11:22,380: INFO: Epoch: 110, Iter: 23200, Loss: 0.948, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 10:12:22,896: INFO: Epoch: 110, Iter: 23250, Loss: 1.108, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 10:13:23,553: INFO: Epoch: 110, Iter: 23300, Loss: 1.211, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 10:14:23,733: INFO: Epoch: 111, Iter: 23350, Loss: 0.770, Accuracy: 1.000, Learning Rate: 0.050
2017-10-23 10:15:24,186: INFO: Epoch: 111, Iter: 23400, Loss: 0.935, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 10:16:24,540: INFO: Epoch: 111, Iter: 23450, Loss: 0.999, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 10:17:25,087: INFO: Epoch: 111, Iter: 23500, Loss: 1.011, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 10:18:25,514: INFO: Epoch: 112, Iter: 23550, Loss: 1.254, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 10:19:25,755: INFO: Epoch: 112, Iter: 23600, Loss: 1.175, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 10:20:26,083: INFO: Epoch: 112, Iter: 23650, Loss: 0.736, Accuracy: 1.000, Learning Rate: 0.050
2017-10-23 10:21:26,211: INFO: Epoch: 112, Iter: 23700, Loss: 1.297, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 10:22:26,396: INFO: Epoch: 113, Iter: 23750, Loss: 1.053, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 10:23:27,103: INFO: Epoch: 113, Iter: 23800, Loss: 1.060, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 10:24:27,583: INFO: Epoch: 113, Iter: 23850, Loss: 0.810, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 10:25:28,020: INFO: Epoch: 113, Iter: 23900, Loss: 1.214, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 10:26:28,473: INFO: Epoch: 114, Iter: 23950, Loss: 1.109, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 10:27:28,851: INFO: Epoch: 114, Iter: 24000, Loss: 1.115, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 10:28:29,235: INFO: Epoch: 114, Iter: 24050, Loss: 1.117, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 10:29:29,274: INFO: Epoch: 114, Iter: 24100, Loss: 1.015, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 10:30:29,646: INFO: Epoch: 115, Iter: 24150, Loss: 1.303, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 10:31:29,748: INFO: Epoch: 115, Iter: 24200, Loss: 0.914, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 10:32:30,097: INFO: Epoch: 115, Iter: 24250, Loss: 1.148, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 10:33:30,509: INFO: Epoch: 115, Iter: 24300, Loss: 1.085, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 10:34:30,929: INFO: Epoch: 115, Iter: 24350, Loss: 1.077, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 10:35:31,323: INFO: Epoch: 116, Iter: 24400, Loss: 1.356, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 10:36:32,069: INFO: Epoch: 116, Iter: 24450, Loss: 0.957, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 10:37:32,890: INFO: Epoch: 116, Iter: 24500, Loss: 1.140, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 10:38:33,323: INFO: Epoch: 116, Iter: 24550, Loss: 1.073, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 10:39:33,590: INFO: Epoch: 117, Iter: 24600, Loss: 1.123, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 10:40:34,000: INFO: Epoch: 117, Iter: 24650, Loss: 1.231, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 10:41:34,380: INFO: Epoch: 117, Iter: 24700, Loss: 1.084, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 10:42:35,194: INFO: Epoch: 117, Iter: 24750, Loss: 1.026, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 10:43:35,522: INFO: Epoch: 118, Iter: 24800, Loss: 1.062, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 10:44:36,129: INFO: Epoch: 118, Iter: 24850, Loss: 1.097, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 10:45:36,899: INFO: Epoch: 118, Iter: 24900, Loss: 1.075, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 10:46:37,300: INFO: Epoch: 118, Iter: 24950, Loss: 1.221, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 10:47:38,093: INFO: Epoch: 119, Iter: 25000, Loss: 1.119, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 10:48:43,077: INFO: Epoch: 119, Iter: 25050, Loss: 0.977, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 10:49:43,684: INFO: Epoch: 119, Iter: 25100, Loss: 0.729, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 10:50:43,707: INFO: Epoch: 119, Iter: 25150, Loss: 1.572, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 10:51:44,200: INFO: Epoch: 120, Iter: 25200, Loss: 1.117, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 10:52:44,666: INFO: Epoch: 120, Iter: 25250, Loss: 1.091, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 10:53:45,215: INFO: Epoch: 120, Iter: 25300, Loss: 0.984, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 10:54:46,167: INFO: Epoch: 120, Iter: 25350, Loss: 1.178, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 10:55:46,253: INFO: Epoch: 120, Iter: 25400, Loss: 0.865, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 10:56:46,723: INFO: Epoch: 121, Iter: 25450, Loss: 0.998, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 10:57:47,002: INFO: Epoch: 121, Iter: 25500, Loss: 1.206, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 10:58:47,424: INFO: Epoch: 121, Iter: 25550, Loss: 0.947, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 10:59:47,885: INFO: Epoch: 121, Iter: 25600, Loss: 0.819, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 11:00:48,056: INFO: Epoch: 122, Iter: 25650, Loss: 0.927, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 11:01:48,112: INFO: Epoch: 122, Iter: 25700, Loss: 1.227, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 11:02:49,627: INFO: Epoch: 122, Iter: 25750, Loss: 1.245, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 11:03:50,172: INFO: Epoch: 122, Iter: 25800, Loss: 1.193, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 11:04:50,474: INFO: Epoch: 123, Iter: 25850, Loss: 1.226, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 11:05:50,813: INFO: Epoch: 123, Iter: 25900, Loss: 1.022, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 11:06:51,558: INFO: Epoch: 123, Iter: 25950, Loss: 0.741, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 11:07:52,009: INFO: Epoch: 123, Iter: 26000, Loss: 1.150, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 11:08:52,401: INFO: Epoch: 124, Iter: 26050, Loss: 1.231, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 11:09:52,544: INFO: Epoch: 124, Iter: 26100, Loss: 1.081, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 11:10:53,105: INFO: Epoch: 124, Iter: 26150, Loss: 0.870, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 11:11:53,335: INFO: Epoch: 124, Iter: 26200, Loss: 0.933, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 11:12:54,163: INFO: Epoch: 125, Iter: 26250, Loss: 1.023, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 11:13:54,533: INFO: Epoch: 125, Iter: 26300, Loss: 1.001, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 11:14:55,033: INFO: Epoch: 125, Iter: 26350, Loss: 0.909, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 11:15:55,291: INFO: Epoch: 125, Iter: 26400, Loss: 1.202, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 11:16:55,759: INFO: Epoch: 125, Iter: 26450, Loss: 1.224, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 11:17:56,516: INFO: Epoch: 126, Iter: 26500, Loss: 0.992, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 11:18:56,607: INFO: Epoch: 126, Iter: 26550, Loss: 1.136, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 11:19:56,997: INFO: Epoch: 126, Iter: 26600, Loss: 0.955, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 11:20:57,128: INFO: Epoch: 126, Iter: 26650, Loss: 1.108, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 11:21:57,383: INFO: Epoch: 127, Iter: 26700, Loss: 0.975, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 11:22:57,794: INFO: Epoch: 127, Iter: 26750, Loss: 1.251, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 11:23:58,139: INFO: Epoch: 127, Iter: 26800, Loss: 1.096, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 11:24:58,641: INFO: Epoch: 127, Iter: 26850, Loss: 1.255, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 11:25:58,319: INFO: Epoch: 128, Iter: 26900, Loss: 1.268, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 11:26:59,164: INFO: Epoch: 128, Iter: 26950, Loss: 1.229, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 11:27:59,769: INFO: Epoch: 128, Iter: 27000, Loss: 1.116, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 11:29:00,202: INFO: Epoch: 128, Iter: 27050, Loss: 0.846, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 11:30:00,843: INFO: Epoch: 129, Iter: 27100, Loss: 0.890, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 11:31:01,407: INFO: Epoch: 129, Iter: 27150, Loss: 1.570, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 11:32:01,548: INFO: Epoch: 129, Iter: 27200, Loss: 1.158, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 11:33:02,613: INFO: Epoch: 129, Iter: 27250, Loss: 1.298, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 11:34:02,970: INFO: Epoch: 130, Iter: 27300, Loss: 1.081, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 11:35:03,418: INFO: Epoch: 130, Iter: 27350, Loss: 0.970, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 11:36:03,612: INFO: Epoch: 130, Iter: 27400, Loss: 0.554, Accuracy: 1.000, Learning Rate: 0.050
2017-10-23 11:37:04,344: INFO: Epoch: 130, Iter: 27450, Loss: 0.808, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 11:38:04,924: INFO: Epoch: 130, Iter: 27500, Loss: 0.996, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 11:39:05,352: INFO: Epoch: 131, Iter: 27550, Loss: 1.556, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 11:40:05,575: INFO: Epoch: 131, Iter: 27600, Loss: 1.026, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 11:41:05,847: INFO: Epoch: 131, Iter: 27650, Loss: 1.149, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 11:42:06,560: INFO: Epoch: 131, Iter: 27700, Loss: 1.053, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 11:43:07,331: INFO: Epoch: 132, Iter: 27750, Loss: 0.970, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 11:44:07,790: INFO: Epoch: 132, Iter: 27800, Loss: 0.700, Accuracy: 1.000, Learning Rate: 0.050
2017-10-23 11:45:07,974: INFO: Epoch: 132, Iter: 27850, Loss: 1.325, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 11:46:08,345: INFO: Epoch: 132, Iter: 27900, Loss: 1.206, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 11:47:08,851: INFO: Epoch: 133, Iter: 27950, Loss: 1.039, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 11:48:09,497: INFO: Epoch: 133, Iter: 28000, Loss: 1.176, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 11:49:09,649: INFO: Epoch: 133, Iter: 28050, Loss: 1.148, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 11:50:09,630: INFO: Epoch: 133, Iter: 28100, Loss: 0.825, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 11:51:09,860: INFO: Epoch: 134, Iter: 28150, Loss: 0.942, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 11:52:10,601: INFO: Epoch: 134, Iter: 28200, Loss: 1.175, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 11:53:11,387: INFO: Epoch: 134, Iter: 28250, Loss: 0.843, Accuracy: 1.000, Learning Rate: 0.050
2017-10-23 11:54:11,670: INFO: Epoch: 134, Iter: 28300, Loss: 1.132, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 11:55:12,194: INFO: Epoch: 135, Iter: 28350, Loss: 1.074, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 11:56:12,013: INFO: Epoch: 135, Iter: 28400, Loss: 1.077, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 11:57:12,811: INFO: Epoch: 135, Iter: 28450, Loss: 1.377, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 11:58:13,092: INFO: Epoch: 135, Iter: 28500, Loss: 0.877, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 11:59:13,190: INFO: Epoch: 135, Iter: 28550, Loss: 1.067, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 12:00:13,513: INFO: Epoch: 136, Iter: 28600, Loss: 1.007, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 12:01:16,096: INFO: Epoch: 136, Iter: 28650, Loss: 1.262, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 12:02:16,341: INFO: Epoch: 136, Iter: 28700, Loss: 1.080, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 12:03:17,113: INFO: Epoch: 136, Iter: 28750, Loss: 1.075, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 12:04:17,724: INFO: Epoch: 137, Iter: 28800, Loss: 0.986, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 12:05:18,166: INFO: Epoch: 137, Iter: 28850, Loss: 1.180, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 12:06:18,449: INFO: Epoch: 137, Iter: 28900, Loss: 1.259, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 12:07:18,645: INFO: Epoch: 137, Iter: 28950, Loss: 1.241, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 12:08:19,352: INFO: Epoch: 138, Iter: 29000, Loss: 0.887, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 12:09:23,766: INFO: Epoch: 138, Iter: 29050, Loss: 0.687, Accuracy: 1.000, Learning Rate: 0.050
2017-10-23 12:10:24,241: INFO: Epoch: 138, Iter: 29100, Loss: 0.795, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 12:11:24,806: INFO: Epoch: 138, Iter: 29150, Loss: 1.123, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 12:12:25,409: INFO: Epoch: 139, Iter: 29200, Loss: 1.012, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 12:13:26,240: INFO: Epoch: 139, Iter: 29250, Loss: 0.962, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 12:14:26,539: INFO: Epoch: 139, Iter: 29300, Loss: 0.994, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 12:15:26,824: INFO: Epoch: 139, Iter: 29350, Loss: 0.833, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 12:16:27,162: INFO: Epoch: 140, Iter: 29400, Loss: 1.310, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 12:17:27,718: INFO: Epoch: 140, Iter: 29450, Loss: 1.094, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 12:18:27,908: INFO: Epoch: 140, Iter: 29500, Loss: 1.007, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 12:19:28,374: INFO: Epoch: 140, Iter: 29550, Loss: 1.217, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 12:20:28,511: INFO: Epoch: 140, Iter: 29600, Loss: 1.100, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 12:21:28,791: INFO: Epoch: 141, Iter: 29650, Loss: 1.094, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 12:22:29,283: INFO: Epoch: 141, Iter: 29700, Loss: 1.078, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 12:23:29,679: INFO: Epoch: 141, Iter: 29750, Loss: 1.062, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 12:24:30,252: INFO: Epoch: 141, Iter: 29800, Loss: 0.908, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 12:25:30,671: INFO: Epoch: 142, Iter: 29850, Loss: 1.004, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 12:26:31,139: INFO: Epoch: 142, Iter: 29900, Loss: 1.146, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 12:27:31,514: INFO: Epoch: 142, Iter: 29950, Loss: 0.827, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 12:28:32,231: INFO: Epoch: 142, Iter: 30000, Loss: 1.172, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 12:29:33,686: INFO: Epoch: 143, Iter: 30050, Loss: 1.103, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 12:30:33,982: INFO: Epoch: 143, Iter: 30100, Loss: 1.095, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 12:31:34,249: INFO: Epoch: 143, Iter: 30150, Loss: 0.869, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 12:32:34,513: INFO: Epoch: 143, Iter: 30200, Loss: 0.931, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 12:33:35,401: INFO: Epoch: 144, Iter: 30250, Loss: 0.971, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 12:34:35,679: INFO: Epoch: 144, Iter: 30300, Loss: 0.951, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 12:35:36,078: INFO: Epoch: 144, Iter: 30350, Loss: 1.171, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 12:36:36,384: INFO: Epoch: 144, Iter: 30400, Loss: 1.138, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 12:37:37,207: INFO: Epoch: 145, Iter: 30450, Loss: 1.068, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 12:38:37,714: INFO: Epoch: 145, Iter: 30500, Loss: 0.955, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 12:39:38,012: INFO: Epoch: 145, Iter: 30550, Loss: 1.202, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 12:40:38,212: INFO: Epoch: 145, Iter: 30600, Loss: 1.191, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 12:41:38,464: INFO: Epoch: 145, Iter: 30650, Loss: 0.942, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 12:42:39,133: INFO: Epoch: 146, Iter: 30700, Loss: 1.063, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 12:43:39,929: INFO: Epoch: 146, Iter: 30750, Loss: 1.116, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 12:44:40,417: INFO: Epoch: 146, Iter: 30800, Loss: 1.121, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 12:45:41,011: INFO: Epoch: 146, Iter: 30850, Loss: 1.107, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 12:46:41,552: INFO: Epoch: 147, Iter: 30900, Loss: 0.917, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 12:47:42,179: INFO: Epoch: 147, Iter: 30950, Loss: 0.984, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 12:48:42,783: INFO: Epoch: 147, Iter: 31000, Loss: 1.406, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 12:49:43,390: INFO: Epoch: 147, Iter: 31050, Loss: 0.969, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 12:50:43,335: INFO: Epoch: 148, Iter: 31100, Loss: 1.125, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 12:51:43,875: INFO: Epoch: 148, Iter: 31150, Loss: 1.074, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 12:52:44,120: INFO: Epoch: 148, Iter: 31200, Loss: 1.130, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 12:53:44,646: INFO: Epoch: 148, Iter: 31250, Loss: 1.021, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 12:54:45,028: INFO: Epoch: 149, Iter: 31300, Loss: 0.951, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 12:55:45,246: INFO: Epoch: 149, Iter: 31350, Loss: 0.896, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 12:56:45,734: INFO: Epoch: 149, Iter: 31400, Loss: 1.103, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 12:57:46,221: INFO: Epoch: 149, Iter: 31450, Loss: 0.980, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 12:58:46,540: INFO: Epoch: 150, Iter: 31500, Loss: 1.018, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 12:59:47,236: INFO: Epoch: 150, Iter: 31550, Loss: 1.028, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 13:00:47,458: INFO: Epoch: 150, Iter: 31600, Loss: 0.953, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 13:01:47,649: INFO: Epoch: 150, Iter: 31650, Loss: 1.131, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 13:02:48,108: INFO: Epoch: 150, Iter: 31700, Loss: 1.012, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 13:03:48,955: INFO: Epoch: 151, Iter: 31750, Loss: 1.133, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 13:04:49,050: INFO: Epoch: 151, Iter: 31800, Loss: 0.975, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 13:05:49,469: INFO: Epoch: 151, Iter: 31850, Loss: 0.951, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 13:06:50,201: INFO: Epoch: 151, Iter: 31900, Loss: 1.107, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 13:07:50,371: INFO: Epoch: 152, Iter: 31950, Loss: 1.142, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 13:08:51,144: INFO: Epoch: 152, Iter: 32000, Loss: 1.066, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 13:09:51,484: INFO: Epoch: 152, Iter: 32050, Loss: 1.115, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 13:10:52,624: INFO: Epoch: 152, Iter: 32100, Loss: 1.448, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 13:11:52,932: INFO: Epoch: 153, Iter: 32150, Loss: 1.097, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 13:12:54,358: INFO: Epoch: 153, Iter: 32200, Loss: 1.246, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 13:13:55,118: INFO: Epoch: 153, Iter: 32250, Loss: 1.103, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 13:14:55,666: INFO: Epoch: 153, Iter: 32300, Loss: 0.897, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 13:15:56,251: INFO: Epoch: 154, Iter: 32350, Loss: 0.896, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 13:16:56,985: INFO: Epoch: 154, Iter: 32400, Loss: 1.133, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 13:17:57,645: INFO: Epoch: 154, Iter: 32450, Loss: 0.962, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 13:18:58,285: INFO: Epoch: 154, Iter: 32500, Loss: 1.000, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 13:19:58,776: INFO: Epoch: 155, Iter: 32550, Loss: 1.059, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 13:20:59,142: INFO: Epoch: 155, Iter: 32600, Loss: 1.118, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 13:21:59,520: INFO: Epoch: 155, Iter: 32650, Loss: 1.137, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 13:23:00,214: INFO: Epoch: 155, Iter: 32700, Loss: 0.853, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 13:24:00,768: INFO: Epoch: 155, Iter: 32750, Loss: 1.048, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 13:25:01,352: INFO: Epoch: 156, Iter: 32800, Loss: 1.186, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 13:26:02,019: INFO: Epoch: 156, Iter: 32850, Loss: 0.973, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 13:27:02,633: INFO: Epoch: 156, Iter: 32900, Loss: 0.781, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 13:28:03,345: INFO: Epoch: 156, Iter: 32950, Loss: 1.190, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 13:29:03,532: INFO: Epoch: 157, Iter: 33000, Loss: 1.150, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 13:30:04,290: INFO: Epoch: 157, Iter: 33050, Loss: 1.201, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 13:31:04,498: INFO: Epoch: 157, Iter: 33100, Loss: 1.024, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 13:32:04,706: INFO: Epoch: 157, Iter: 33150, Loss: 1.034, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 13:33:05,165: INFO: Epoch: 158, Iter: 33200, Loss: 1.082, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 13:34:05,672: INFO: Epoch: 158, Iter: 33250, Loss: 0.804, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 13:35:05,947: INFO: Epoch: 158, Iter: 33300, Loss: 1.108, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 13:36:06,291: INFO: Epoch: 158, Iter: 33350, Loss: 1.339, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 13:37:06,790: INFO: Epoch: 159, Iter: 33400, Loss: 1.074, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 13:38:07,405: INFO: Epoch: 159, Iter: 33450, Loss: 1.106, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 13:39:07,466: INFO: Epoch: 159, Iter: 33500, Loss: 1.132, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 13:40:07,875: INFO: Epoch: 159, Iter: 33550, Loss: 1.252, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 13:41:08,227: INFO: Epoch: 160, Iter: 33600, Loss: 1.049, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 13:42:08,308: INFO: Epoch: 160, Iter: 33650, Loss: 0.993, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 13:43:09,209: INFO: Epoch: 160, Iter: 33700, Loss: 1.426, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 13:44:09,639: INFO: Epoch: 160, Iter: 33750, Loss: 0.977, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 13:45:09,953: INFO: Epoch: 160, Iter: 33800, Loss: 1.055, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 13:46:10,360: INFO: Epoch: 161, Iter: 33850, Loss: 0.856, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 13:47:11,047: INFO: Epoch: 161, Iter: 33900, Loss: 1.367, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 13:48:11,828: INFO: Epoch: 161, Iter: 33950, Loss: 1.155, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 13:49:11,885: INFO: Epoch: 161, Iter: 34000, Loss: 1.118, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 13:50:12,114: INFO: Epoch: 162, Iter: 34050, Loss: 1.097, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 13:51:12,491: INFO: Epoch: 162, Iter: 34100, Loss: 1.167, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 13:52:12,945: INFO: Epoch: 162, Iter: 34150, Loss: 1.104, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 13:53:16,916: INFO: Epoch: 162, Iter: 34200, Loss: 0.993, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 13:54:18,347: INFO: Epoch: 163, Iter: 34250, Loss: 1.166, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 13:55:18,791: INFO: Epoch: 163, Iter: 34300, Loss: 1.075, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 13:56:18,931: INFO: Epoch: 163, Iter: 34350, Loss: 0.792, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 13:57:19,759: INFO: Epoch: 163, Iter: 34400, Loss: 1.203, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 13:58:20,238: INFO: Epoch: 164, Iter: 34450, Loss: 1.233, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 13:59:20,651: INFO: Epoch: 164, Iter: 34500, Loss: 1.034, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 14:00:21,236: INFO: Epoch: 164, Iter: 34550, Loss: 1.010, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 14:01:21,616: INFO: Epoch: 164, Iter: 34600, Loss: 0.970, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 14:02:21,819: INFO: Epoch: 165, Iter: 34650, Loss: 0.878, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 14:03:23,013: INFO: Epoch: 165, Iter: 34700, Loss: 1.085, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 14:04:24,033: INFO: Epoch: 165, Iter: 34750, Loss: 1.214, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 14:05:24,153: INFO: Epoch: 165, Iter: 34800, Loss: 1.234, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 14:06:24,487: INFO: Epoch: 165, Iter: 34850, Loss: 1.187, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 14:07:24,810: INFO: Epoch: 166, Iter: 34900, Loss: 0.896, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 14:08:25,728: INFO: Epoch: 166, Iter: 34950, Loss: 0.977, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 14:09:26,518: INFO: Epoch: 166, Iter: 35000, Loss: 1.227, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 14:10:26,371: INFO: Epoch: 166, Iter: 35050, Loss: 1.116, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 14:11:26,626: INFO: Epoch: 167, Iter: 35100, Loss: 1.299, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 14:12:27,326: INFO: Epoch: 167, Iter: 35150, Loss: 1.114, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 14:13:27,950: INFO: Epoch: 167, Iter: 35200, Loss: 1.003, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 14:14:28,445: INFO: Epoch: 167, Iter: 35250, Loss: 1.003, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 14:15:28,856: INFO: Epoch: 168, Iter: 35300, Loss: 0.767, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 14:16:29,134: INFO: Epoch: 168, Iter: 35350, Loss: 1.200, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 14:17:30,003: INFO: Epoch: 168, Iter: 35400, Loss: 1.371, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 14:18:30,333: INFO: Epoch: 168, Iter: 35450, Loss: 1.162, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 14:19:30,697: INFO: Epoch: 169, Iter: 35500, Loss: 0.969, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 14:20:30,980: INFO: Epoch: 169, Iter: 35550, Loss: 1.113, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 14:21:31,548: INFO: Epoch: 169, Iter: 35600, Loss: 0.825, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 14:22:31,995: INFO: Epoch: 169, Iter: 35650, Loss: 0.995, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 14:23:32,176: INFO: Epoch: 170, Iter: 35700, Loss: 0.900, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 14:24:32,391: INFO: Epoch: 170, Iter: 35750, Loss: 1.289, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 14:25:32,452: INFO: Epoch: 170, Iter: 35800, Loss: 1.142, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 14:26:32,807: INFO: Epoch: 170, Iter: 35850, Loss: 0.987, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 14:27:33,517: INFO: Epoch: 170, Iter: 35900, Loss: 1.010, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 14:28:34,185: INFO: Epoch: 171, Iter: 35950, Loss: 0.973, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 14:29:34,632: INFO: Epoch: 171, Iter: 36000, Loss: 0.981, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 14:30:34,786: INFO: Epoch: 171, Iter: 36050, Loss: 1.072, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 14:31:35,143: INFO: Epoch: 171, Iter: 36100, Loss: 0.861, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 14:32:35,437: INFO: Epoch: 172, Iter: 36150, Loss: 1.109, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 14:33:35,704: INFO: Epoch: 172, Iter: 36200, Loss: 1.225, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 14:34:36,134: INFO: Epoch: 172, Iter: 36250, Loss: 1.217, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 14:35:36,396: INFO: Epoch: 172, Iter: 36300, Loss: 1.040, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 14:36:36,780: INFO: Epoch: 173, Iter: 36350, Loss: 1.011, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 14:37:37,261: INFO: Epoch: 173, Iter: 36400, Loss: 1.358, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 14:38:37,889: INFO: Epoch: 173, Iter: 36450, Loss: 1.002, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 14:39:38,359: INFO: Epoch: 173, Iter: 36500, Loss: 1.457, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 14:40:38,727: INFO: Epoch: 174, Iter: 36550, Loss: 1.052, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 14:41:39,026: INFO: Epoch: 174, Iter: 36600, Loss: 0.973, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 14:42:39,723: INFO: Epoch: 174, Iter: 36650, Loss: 0.903, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 14:43:40,447: INFO: Epoch: 174, Iter: 36700, Loss: 1.113, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 14:44:40,759: INFO: Epoch: 175, Iter: 36750, Loss: 1.137, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 14:45:41,170: INFO: Epoch: 175, Iter: 36800, Loss: 1.082, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 14:46:41,336: INFO: Epoch: 175, Iter: 36850, Loss: 0.902, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 14:47:41,998: INFO: Epoch: 175, Iter: 36900, Loss: 1.255, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 14:48:42,648: INFO: Epoch: 175, Iter: 36950, Loss: 1.008, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 14:49:42,965: INFO: Epoch: 176, Iter: 37000, Loss: 0.974, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 14:50:43,387: INFO: Epoch: 176, Iter: 37050, Loss: 1.158, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 14:51:43,954: INFO: Epoch: 176, Iter: 37100, Loss: 1.130, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 14:52:44,266: INFO: Epoch: 176, Iter: 37150, Loss: 1.153, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 14:53:45,064: INFO: Epoch: 177, Iter: 37200, Loss: 1.189, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 14:54:45,776: INFO: Epoch: 177, Iter: 37250, Loss: 0.983, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 14:55:47,465: INFO: Epoch: 177, Iter: 37300, Loss: 1.070, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 14:56:47,944: INFO: Epoch: 177, Iter: 37350, Loss: 1.342, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 14:57:48,259: INFO: Epoch: 178, Iter: 37400, Loss: 1.280, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 14:58:50,079: INFO: Epoch: 178, Iter: 37450, Loss: 0.969, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 14:59:50,460: INFO: Epoch: 178, Iter: 37500, Loss: 1.404, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 15:00:50,876: INFO: Epoch: 178, Iter: 37550, Loss: 1.143, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 15:01:50,940: INFO: Epoch: 179, Iter: 37600, Loss: 1.024, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 15:02:51,683: INFO: Epoch: 179, Iter: 37650, Loss: 1.097, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 15:03:52,276: INFO: Epoch: 179, Iter: 37700, Loss: 1.070, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 15:04:52,554: INFO: Epoch: 179, Iter: 37750, Loss: 1.246, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 15:05:53,021: INFO: Epoch: 180, Iter: 37800, Loss: 1.078, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 15:06:53,834: INFO: Epoch: 180, Iter: 37850, Loss: 0.982, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 15:07:54,387: INFO: Epoch: 180, Iter: 37900, Loss: 0.962, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 15:08:54,826: INFO: Epoch: 180, Iter: 37950, Loss: 1.066, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 15:09:54,988: INFO: Epoch: 180, Iter: 38000, Loss: 1.241, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 15:10:55,483: INFO: Epoch: 181, Iter: 38050, Loss: 1.113, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 15:11:55,460: INFO: Epoch: 181, Iter: 38100, Loss: 0.877, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 15:12:56,180: INFO: Epoch: 181, Iter: 38150, Loss: 1.285, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 15:13:56,731: INFO: Epoch: 181, Iter: 38200, Loss: 1.350, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 15:14:57,182: INFO: Epoch: 182, Iter: 38250, Loss: 1.114, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 15:15:57,704: INFO: Epoch: 182, Iter: 38300, Loss: 0.933, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 15:16:58,246: INFO: Epoch: 182, Iter: 38350, Loss: 1.167, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 15:17:59,033: INFO: Epoch: 182, Iter: 38400, Loss: 1.048, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 15:18:59,523: INFO: Epoch: 183, Iter: 38450, Loss: 1.115, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 15:19:59,942: INFO: Epoch: 183, Iter: 38500, Loss: 1.078, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 15:21:00,591: INFO: Epoch: 183, Iter: 38550, Loss: 1.414, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 15:22:00,910: INFO: Epoch: 183, Iter: 38600, Loss: 1.177, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 15:23:01,343: INFO: Epoch: 184, Iter: 38650, Loss: 1.058, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 15:24:01,749: INFO: Epoch: 184, Iter: 38700, Loss: 0.868, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 15:25:02,080: INFO: Epoch: 184, Iter: 38750, Loss: 1.146, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 15:26:02,096: INFO: Epoch: 184, Iter: 38800, Loss: 0.980, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 15:27:02,773: INFO: Epoch: 185, Iter: 38850, Loss: 0.944, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 15:28:03,147: INFO: Epoch: 185, Iter: 38900, Loss: 0.783, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 15:29:03,594: INFO: Epoch: 185, Iter: 38950, Loss: 0.986, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 15:30:03,641: INFO: Epoch: 185, Iter: 39000, Loss: 1.074, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 15:31:03,965: INFO: Epoch: 185, Iter: 39050, Loss: 0.974, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 15:32:04,345: INFO: Epoch: 186, Iter: 39100, Loss: 1.125, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 15:33:04,793: INFO: Epoch: 186, Iter: 39150, Loss: 1.007, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 15:34:05,198: INFO: Epoch: 186, Iter: 39200, Loss: 0.807, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 15:35:05,850: INFO: Epoch: 186, Iter: 39250, Loss: 1.217, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 15:36:06,449: INFO: Epoch: 187, Iter: 39300, Loss: 1.054, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 15:37:06,981: INFO: Epoch: 187, Iter: 39350, Loss: 0.682, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 15:38:07,521: INFO: Epoch: 187, Iter: 39400, Loss: 0.919, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 15:39:08,167: INFO: Epoch: 187, Iter: 39450, Loss: 1.106, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 15:40:08,564: INFO: Epoch: 188, Iter: 39500, Loss: 1.130, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 15:41:09,117: INFO: Epoch: 188, Iter: 39550, Loss: 0.982, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 15:42:09,857: INFO: Epoch: 188, Iter: 39600, Loss: 1.082, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 15:43:10,662: INFO: Epoch: 188, Iter: 39650, Loss: 1.030, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 15:44:10,854: INFO: Epoch: 189, Iter: 39700, Loss: 1.133, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 15:45:11,327: INFO: Epoch: 189, Iter: 39750, Loss: 0.820, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 15:46:11,447: INFO: Epoch: 189, Iter: 39800, Loss: 0.708, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 15:47:11,979: INFO: Epoch: 189, Iter: 39850, Loss: 1.140, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 15:48:12,609: INFO: Epoch: 190, Iter: 39900, Loss: 0.948, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 15:49:13,081: INFO: Epoch: 190, Iter: 39950, Loss: 1.203, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 15:50:13,259: INFO: Epoch: 190, Iter: 40000, Loss: 0.726, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 15:51:13,773: INFO: Epoch: 190, Iter: 40050, Loss: 1.211, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 15:52:14,297: INFO: Epoch: 190, Iter: 40100, Loss: 1.140, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 15:53:14,980: INFO: Epoch: 191, Iter: 40150, Loss: 1.123, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 15:54:15,258: INFO: Epoch: 191, Iter: 40200, Loss: 1.257, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 15:55:15,721: INFO: Epoch: 191, Iter: 40250, Loss: 1.129, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 15:56:15,875: INFO: Epoch: 191, Iter: 40300, Loss: 1.179, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 15:57:16,535: INFO: Epoch: 192, Iter: 40350, Loss: 1.111, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 15:58:17,177: INFO: Epoch: 192, Iter: 40400, Loss: 0.783, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 15:59:17,837: INFO: Epoch: 192, Iter: 40450, Loss: 1.376, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 16:00:18,177: INFO: Epoch: 192, Iter: 40500, Loss: 1.180, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 16:01:18,607: INFO: Epoch: 193, Iter: 40550, Loss: 0.999, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 16:02:19,056: INFO: Epoch: 193, Iter: 40600, Loss: 0.977, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 16:03:19,707: INFO: Epoch: 193, Iter: 40650, Loss: 1.005, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 16:04:20,863: INFO: Epoch: 193, Iter: 40700, Loss: 0.741, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 16:05:20,730: INFO: Epoch: 194, Iter: 40750, Loss: 1.078, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 16:06:20,877: INFO: Epoch: 194, Iter: 40800, Loss: 1.036, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 16:07:21,207: INFO: Epoch: 194, Iter: 40850, Loss: 0.918, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 16:08:21,827: INFO: Epoch: 194, Iter: 40900, Loss: 1.174, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 16:09:22,130: INFO: Epoch: 195, Iter: 40950, Loss: 1.320, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 16:10:22,331: INFO: Epoch: 195, Iter: 41000, Loss: 0.955, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 16:11:22,558: INFO: Epoch: 195, Iter: 41050, Loss: 1.204, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 16:12:22,492: INFO: Epoch: 195, Iter: 41100, Loss: 0.992, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 16:13:23,017: INFO: Epoch: 195, Iter: 41150, Loss: 0.994, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 16:14:23,598: INFO: Epoch: 196, Iter: 41200, Loss: 1.132, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 16:15:24,334: INFO: Epoch: 196, Iter: 41250, Loss: 0.828, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 16:16:24,633: INFO: Epoch: 196, Iter: 41300, Loss: 0.718, Accuracy: 1.000, Learning Rate: 0.050
2017-10-23 16:17:25,122: INFO: Epoch: 196, Iter: 41350, Loss: 1.206, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 16:18:25,693: INFO: Epoch: 197, Iter: 41400, Loss: 1.161, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 16:19:25,850: INFO: Epoch: 197, Iter: 41450, Loss: 1.029, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 16:20:26,393: INFO: Epoch: 197, Iter: 41500, Loss: 1.329, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 16:21:26,549: INFO: Epoch: 197, Iter: 41550, Loss: 0.731, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 16:22:27,099: INFO: Epoch: 198, Iter: 41600, Loss: 0.859, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 16:23:27,943: INFO: Epoch: 198, Iter: 41650, Loss: 0.965, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 16:24:28,069: INFO: Epoch: 198, Iter: 41700, Loss: 0.969, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 16:25:28,223: INFO: Epoch: 198, Iter: 41750, Loss: 1.068, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 16:26:28,866: INFO: Epoch: 199, Iter: 41800, Loss: 1.171, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 16:27:29,166: INFO: Epoch: 199, Iter: 41850, Loss: 1.116, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 16:28:29,730: INFO: Epoch: 199, Iter: 41900, Loss: 1.054, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 16:29:29,943: INFO: Epoch: 199, Iter: 41950, Loss: 0.751, Accuracy: 1.000, Learning Rate: 0.050
2017-10-23 16:30:29,950: INFO: Epoch: 200, Iter: 42000, Loss: 1.026, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 16:31:30,307: INFO: Epoch: 200, Iter: 42050, Loss: 1.093, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 16:32:30,546: INFO: Epoch: 200, Iter: 42100, Loss: 1.129, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 16:33:31,168: INFO: Epoch: 200, Iter: 42150, Loss: 1.110, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 16:34:31,409: INFO: Epoch: 200, Iter: 42200, Loss: 1.083, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 16:35:31,514: INFO: Epoch: 201, Iter: 42250, Loss: 1.153, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 16:36:32,637: INFO: Epoch: 201, Iter: 42300, Loss: 0.999, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 16:37:33,189: INFO: Epoch: 201, Iter: 42350, Loss: 1.264, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 16:38:33,619: INFO: Epoch: 201, Iter: 42400, Loss: 1.253, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 16:39:33,837: INFO: Epoch: 202, Iter: 42450, Loss: 0.977, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 16:40:34,035: INFO: Epoch: 202, Iter: 42500, Loss: 0.897, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 16:41:34,061: INFO: Epoch: 202, Iter: 42550, Loss: 1.053, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 16:42:34,761: INFO: Epoch: 202, Iter: 42600, Loss: 0.799, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 16:43:35,248: INFO: Epoch: 203, Iter: 42650, Loss: 1.089, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 16:44:35,510: INFO: Epoch: 203, Iter: 42700, Loss: 0.958, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 16:45:35,715: INFO: Epoch: 203, Iter: 42750, Loss: 0.928, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 16:46:36,040: INFO: Epoch: 203, Iter: 42800, Loss: 1.262, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 16:47:36,664: INFO: Epoch: 204, Iter: 42850, Loss: 1.101, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 16:48:37,489: INFO: Epoch: 204, Iter: 42900, Loss: 0.954, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 16:49:37,738: INFO: Epoch: 204, Iter: 42950, Loss: 1.072, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 16:50:38,100: INFO: Epoch: 204, Iter: 43000, Loss: 0.908, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 16:51:38,234: INFO: Epoch: 205, Iter: 43050, Loss: 0.990, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 16:52:38,652: INFO: Epoch: 205, Iter: 43100, Loss: 1.018, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 16:53:39,529: INFO: Epoch: 205, Iter: 43150, Loss: 1.231, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 16:54:39,476: INFO: Epoch: 205, Iter: 43200, Loss: 1.140, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 16:55:39,342: INFO: Epoch: 205, Iter: 43250, Loss: 1.309, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 16:56:40,330: INFO: Epoch: 206, Iter: 43300, Loss: 1.318, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 16:57:41,114: INFO: Epoch: 206, Iter: 43350, Loss: 1.147, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 16:58:41,997: INFO: Epoch: 206, Iter: 43400, Loss: 0.920, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 16:59:42,261: INFO: Epoch: 206, Iter: 43450, Loss: 0.758, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 17:00:43,016: INFO: Epoch: 207, Iter: 43500, Loss: 0.962, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 17:01:43,085: INFO: Epoch: 207, Iter: 43550, Loss: 1.065, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 17:02:43,182: INFO: Epoch: 207, Iter: 43600, Loss: 1.078, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 17:03:43,947: INFO: Epoch: 207, Iter: 43650, Loss: 0.793, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 17:04:44,648: INFO: Epoch: 208, Iter: 43700, Loss: 0.864, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 17:05:45,095: INFO: Epoch: 208, Iter: 43750, Loss: 1.237, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 17:06:45,684: INFO: Epoch: 208, Iter: 43800, Loss: 0.913, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 17:07:45,925: INFO: Epoch: 208, Iter: 43850, Loss: 0.847, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 17:08:46,525: INFO: Epoch: 209, Iter: 43900, Loss: 1.337, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 17:09:46,847: INFO: Epoch: 209, Iter: 43950, Loss: 1.013, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 17:10:47,179: INFO: Epoch: 209, Iter: 44000, Loss: 0.917, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 17:11:47,660: INFO: Epoch: 209, Iter: 44050, Loss: 1.453, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 17:12:48,447: INFO: Epoch: 210, Iter: 44100, Loss: 0.972, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 17:13:49,206: INFO: Epoch: 210, Iter: 44150, Loss: 1.062, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 17:14:49,960: INFO: Epoch: 210, Iter: 44200, Loss: 0.968, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 17:15:50,406: INFO: Epoch: 210, Iter: 44250, Loss: 0.991, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 17:16:50,309: INFO: Epoch: 210, Iter: 44300, Loss: 1.296, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 17:17:51,055: INFO: Epoch: 211, Iter: 44350, Loss: 1.046, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 17:18:51,423: INFO: Epoch: 211, Iter: 44400, Loss: 1.055, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 17:19:51,506: INFO: Epoch: 211, Iter: 44450, Loss: 1.051, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 17:20:51,615: INFO: Epoch: 211, Iter: 44500, Loss: 1.484, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 17:21:51,998: INFO: Epoch: 212, Iter: 44550, Loss: 1.145, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 17:22:52,140: INFO: Epoch: 212, Iter: 44600, Loss: 0.884, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 17:23:52,574: INFO: Epoch: 212, Iter: 44650, Loss: 1.285, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 17:24:52,663: INFO: Epoch: 212, Iter: 44700, Loss: 1.270, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 17:25:53,270: INFO: Epoch: 213, Iter: 44750, Loss: 1.092, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 17:26:53,934: INFO: Epoch: 213, Iter: 44800, Loss: 0.829, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 17:27:54,613: INFO: Epoch: 213, Iter: 44850, Loss: 0.966, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 17:28:55,045: INFO: Epoch: 213, Iter: 44900, Loss: 0.808, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 17:29:55,554: INFO: Epoch: 214, Iter: 44950, Loss: 1.032, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 17:30:55,894: INFO: Epoch: 214, Iter: 45000, Loss: 0.983, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 17:31:55,953: INFO: Epoch: 214, Iter: 45050, Loss: 0.925, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 17:32:56,709: INFO: Epoch: 214, Iter: 45100, Loss: 1.082, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 17:33:57,108: INFO: Epoch: 215, Iter: 45150, Loss: 0.797, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 17:34:57,676: INFO: Epoch: 215, Iter: 45200, Loss: 0.698, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 17:35:57,446: INFO: Epoch: 215, Iter: 45250, Loss: 1.247, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 17:36:58,108: INFO: Epoch: 215, Iter: 45300, Loss: 1.227, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 17:37:58,977: INFO: Epoch: 215, Iter: 45350, Loss: 1.231, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 17:38:59,323: INFO: Epoch: 216, Iter: 45400, Loss: 1.020, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 17:39:59,619: INFO: Epoch: 216, Iter: 45450, Loss: 1.243, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 17:40:59,960: INFO: Epoch: 216, Iter: 45500, Loss: 1.175, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 17:42:00,364: INFO: Epoch: 216, Iter: 45550, Loss: 0.995, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 17:43:00,848: INFO: Epoch: 217, Iter: 45600, Loss: 0.974, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 17:44:01,868: INFO: Epoch: 217, Iter: 45650, Loss: 0.954, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 17:45:02,094: INFO: Epoch: 217, Iter: 45700, Loss: 1.171, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 17:46:02,615: INFO: Epoch: 217, Iter: 45750, Loss: 0.995, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 17:47:03,164: INFO: Epoch: 218, Iter: 45800, Loss: 1.204, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 17:48:03,769: INFO: Epoch: 218, Iter: 45850, Loss: 1.060, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 17:49:04,126: INFO: Epoch: 218, Iter: 45900, Loss: 0.955, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 17:50:04,330: INFO: Epoch: 218, Iter: 45950, Loss: 1.097, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 17:51:04,433: INFO: Epoch: 219, Iter: 46000, Loss: 0.998, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 17:52:04,659: INFO: Epoch: 219, Iter: 46050, Loss: 1.064, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 17:53:05,015: INFO: Epoch: 219, Iter: 46100, Loss: 1.204, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 17:54:05,480: INFO: Epoch: 219, Iter: 46150, Loss: 1.241, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 17:55:05,827: INFO: Epoch: 220, Iter: 46200, Loss: 1.119, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 17:56:06,112: INFO: Epoch: 220, Iter: 46250, Loss: 1.027, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 17:57:06,607: INFO: Epoch: 220, Iter: 46300, Loss: 0.954, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 17:58:07,297: INFO: Epoch: 220, Iter: 46350, Loss: 1.040, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 17:59:07,691: INFO: Epoch: 220, Iter: 46400, Loss: 1.117, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 18:00:08,162: INFO: Epoch: 221, Iter: 46450, Loss: 0.988, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 18:01:08,367: INFO: Epoch: 221, Iter: 46500, Loss: 1.181, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 18:02:08,831: INFO: Epoch: 221, Iter: 46550, Loss: 0.848, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 18:03:09,301: INFO: Epoch: 221, Iter: 46600, Loss: 1.089, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 18:04:09,466: INFO: Epoch: 222, Iter: 46650, Loss: 1.091, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 18:05:09,607: INFO: Epoch: 222, Iter: 46700, Loss: 1.304, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 18:06:10,107: INFO: Epoch: 222, Iter: 46750, Loss: 1.062, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 18:07:12,600: INFO: Epoch: 222, Iter: 46800, Loss: 1.112, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 18:08:13,150: INFO: Epoch: 223, Iter: 46850, Loss: 1.126, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 18:09:13,512: INFO: Epoch: 223, Iter: 46900, Loss: 1.098, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 18:10:13,682: INFO: Epoch: 223, Iter: 46950, Loss: 0.922, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 18:11:14,204: INFO: Epoch: 223, Iter: 47000, Loss: 1.145, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 18:12:15,377: INFO: Epoch: 224, Iter: 47050, Loss: 1.134, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 18:13:16,184: INFO: Epoch: 224, Iter: 47100, Loss: 0.957, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 18:14:16,585: INFO: Epoch: 224, Iter: 47150, Loss: 1.094, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 18:15:17,419: INFO: Epoch: 224, Iter: 47200, Loss: 0.982, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 18:16:17,497: INFO: Epoch: 225, Iter: 47250, Loss: 1.209, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 18:17:17,867: INFO: Epoch: 225, Iter: 47300, Loss: 1.230, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 18:18:17,977: INFO: Epoch: 225, Iter: 47350, Loss: 1.435, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 18:19:18,005: INFO: Epoch: 225, Iter: 47400, Loss: 0.996, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 18:20:18,193: INFO: Epoch: 225, Iter: 47450, Loss: 1.252, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 18:21:17,925: INFO: Epoch: 226, Iter: 47500, Loss: 0.928, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 18:22:18,137: INFO: Epoch: 226, Iter: 47550, Loss: 1.191, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 18:23:18,182: INFO: Epoch: 226, Iter: 47600, Loss: 1.156, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 18:24:18,031: INFO: Epoch: 226, Iter: 47650, Loss: 1.248, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 18:25:18,350: INFO: Epoch: 227, Iter: 47700, Loss: 0.776, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 18:26:18,150: INFO: Epoch: 227, Iter: 47750, Loss: 1.245, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 18:27:18,335: INFO: Epoch: 227, Iter: 47800, Loss: 0.961, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 18:28:18,377: INFO: Epoch: 227, Iter: 47850, Loss: 1.213, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 18:29:18,205: INFO: Epoch: 228, Iter: 47900, Loss: 1.236, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 18:30:18,400: INFO: Epoch: 228, Iter: 47950, Loss: 0.965, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 18:31:18,670: INFO: Epoch: 228, Iter: 48000, Loss: 1.142, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 18:32:19,078: INFO: Epoch: 228, Iter: 48050, Loss: 0.955, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 18:33:18,928: INFO: Epoch: 229, Iter: 48100, Loss: 1.053, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 18:34:19,761: INFO: Epoch: 229, Iter: 48150, Loss: 1.159, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 18:35:19,955: INFO: Epoch: 229, Iter: 48200, Loss: 0.953, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 18:36:19,984: INFO: Epoch: 229, Iter: 48250, Loss: 0.715, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 18:37:20,454: INFO: Epoch: 230, Iter: 48300, Loss: 0.855, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 18:38:21,116: INFO: Epoch: 230, Iter: 48350, Loss: 0.933, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 18:39:21,089: INFO: Epoch: 230, Iter: 48400, Loss: 1.074, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 18:40:21,322: INFO: Epoch: 230, Iter: 48450, Loss: 1.127, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 18:41:21,368: INFO: Epoch: 230, Iter: 48500, Loss: 1.228, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 18:42:21,778: INFO: Epoch: 231, Iter: 48550, Loss: 1.075, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 18:43:22,278: INFO: Epoch: 231, Iter: 48600, Loss: 1.452, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 18:44:22,740: INFO: Epoch: 231, Iter: 48650, Loss: 1.119, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 18:45:22,760: INFO: Epoch: 231, Iter: 48700, Loss: 0.986, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 18:46:23,013: INFO: Epoch: 232, Iter: 48750, Loss: 0.954, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 18:47:23,710: INFO: Epoch: 232, Iter: 48800, Loss: 0.586, Accuracy: 1.000, Learning Rate: 0.050
2017-10-23 18:48:24,462: INFO: Epoch: 232, Iter: 48850, Loss: 1.134, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 18:49:24,962: INFO: Epoch: 232, Iter: 48900, Loss: 1.017, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 18:50:25,391: INFO: Epoch: 233, Iter: 48950, Loss: 0.975, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 18:51:25,989: INFO: Epoch: 233, Iter: 49000, Loss: 1.273, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 18:52:26,387: INFO: Epoch: 233, Iter: 49050, Loss: 1.515, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 18:53:26,978: INFO: Epoch: 233, Iter: 49100, Loss: 0.919, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 18:54:27,766: INFO: Epoch: 234, Iter: 49150, Loss: 1.031, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 18:55:27,895: INFO: Epoch: 234, Iter: 49200, Loss: 1.122, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 18:56:28,324: INFO: Epoch: 234, Iter: 49250, Loss: 0.978, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 18:57:29,118: INFO: Epoch: 234, Iter: 49300, Loss: 1.437, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 18:58:29,675: INFO: Epoch: 235, Iter: 49350, Loss: 1.007, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 18:59:29,626: INFO: Epoch: 235, Iter: 49400, Loss: 1.057, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 19:00:30,540: INFO: Epoch: 235, Iter: 49450, Loss: 0.969, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 19:01:31,081: INFO: Epoch: 235, Iter: 49500, Loss: 1.556, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 19:02:31,407: INFO: Epoch: 235, Iter: 49550, Loss: 0.973, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 19:03:32,255: INFO: Epoch: 236, Iter: 49600, Loss: 0.916, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 19:04:32,304: INFO: Epoch: 236, Iter: 49650, Loss: 1.222, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 19:05:32,716: INFO: Epoch: 236, Iter: 49700, Loss: 0.963, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 19:06:33,097: INFO: Epoch: 236, Iter: 49750, Loss: 1.069, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 19:07:37,084: INFO: Epoch: 237, Iter: 49800, Loss: 1.005, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 19:08:38,833: INFO: Epoch: 237, Iter: 49850, Loss: 1.146, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 19:09:40,009: INFO: Epoch: 237, Iter: 49900, Loss: 1.121, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 19:10:41,407: INFO: Epoch: 237, Iter: 49950, Loss: 0.898, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 19:11:42,597: INFO: Epoch: 238, Iter: 50000, Loss: 0.813, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 19:12:44,023: INFO: Epoch: 238, Iter: 50050, Loss: 1.157, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 19:13:45,948: INFO: Epoch: 238, Iter: 50100, Loss: 1.277, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 19:14:47,145: INFO: Epoch: 238, Iter: 50150, Loss: 0.875, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 19:15:48,381: INFO: Epoch: 239, Iter: 50200, Loss: 1.038, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 19:16:50,183: INFO: Epoch: 239, Iter: 50250, Loss: 1.028, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 19:17:52,403: INFO: Epoch: 239, Iter: 50300, Loss: 1.077, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 19:18:54,474: INFO: Epoch: 239, Iter: 50350, Loss: 0.837, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 19:19:55,450: INFO: Epoch: 240, Iter: 50400, Loss: 1.244, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 19:20:56,976: INFO: Epoch: 240, Iter: 50450, Loss: 1.289, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 19:21:58,206: INFO: Epoch: 240, Iter: 50500, Loss: 1.285, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 19:22:59,535: INFO: Epoch: 240, Iter: 50550, Loss: 1.105, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 19:24:00,899: INFO: Epoch: 240, Iter: 50600, Loss: 1.000, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 19:25:02,349: INFO: Epoch: 241, Iter: 50650, Loss: 1.144, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 19:26:03,626: INFO: Epoch: 241, Iter: 50700, Loss: 1.383, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 19:27:04,822: INFO: Epoch: 241, Iter: 50750, Loss: 1.059, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 19:28:06,291: INFO: Epoch: 241, Iter: 50800, Loss: 1.219, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 19:29:07,435: INFO: Epoch: 242, Iter: 50850, Loss: 1.117, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 19:30:08,757: INFO: Epoch: 242, Iter: 50900, Loss: 1.252, Accuracy: 0.000, Learning Rate: 0.050
2017-10-23 19:31:10,440: INFO: Epoch: 242, Iter: 50950, Loss: 1.110, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 19:32:11,591: INFO: Epoch: 242, Iter: 51000, Loss: 0.957, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 19:33:12,919: INFO: Epoch: 243, Iter: 51050, Loss: 1.105, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 19:34:14,620: INFO: Epoch: 243, Iter: 51100, Loss: 1.021, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 19:35:16,197: INFO: Epoch: 243, Iter: 51150, Loss: 1.099, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 19:36:17,649: INFO: Epoch: 243, Iter: 51200, Loss: 1.013, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 19:37:19,273: INFO: Epoch: 244, Iter: 51250, Loss: 1.271, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 19:38:20,850: INFO: Epoch: 244, Iter: 51300, Loss: 1.101, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 19:39:22,383: INFO: Epoch: 244, Iter: 51350, Loss: 1.091, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 19:40:23,710: INFO: Epoch: 244, Iter: 51400, Loss: 0.965, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 19:41:25,197: INFO: Epoch: 245, Iter: 51450, Loss: 0.964, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 19:42:26,632: INFO: Epoch: 245, Iter: 51500, Loss: 1.065, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 19:43:28,320: INFO: Epoch: 245, Iter: 51550, Loss: 1.094, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 19:44:29,479: INFO: Epoch: 245, Iter: 51600, Loss: 0.989, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 19:45:30,499: INFO: Epoch: 245, Iter: 51650, Loss: 0.777, Accuracy: 1.000, Learning Rate: 0.050
2017-10-23 19:46:31,836: INFO: Epoch: 246, Iter: 51700, Loss: 0.814, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 19:47:33,113: INFO: Epoch: 246, Iter: 51750, Loss: 0.837, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 19:48:34,847: INFO: Epoch: 246, Iter: 51800, Loss: 1.102, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 19:49:36,010: INFO: Epoch: 246, Iter: 51850, Loss: 1.010, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 19:50:37,000: INFO: Epoch: 247, Iter: 51900, Loss: 0.963, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 19:51:38,353: INFO: Epoch: 247, Iter: 51950, Loss: 1.124, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 19:52:39,656: INFO: Epoch: 247, Iter: 52000, Loss: 0.996, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 19:53:40,977: INFO: Epoch: 247, Iter: 52050, Loss: 1.263, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 19:54:41,884: INFO: Epoch: 248, Iter: 52100, Loss: 1.197, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 19:55:42,969: INFO: Epoch: 248, Iter: 52150, Loss: 1.181, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 19:56:44,301: INFO: Epoch: 248, Iter: 52200, Loss: 0.980, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 19:57:45,744: INFO: Epoch: 248, Iter: 52250, Loss: 0.851, Accuracy: 0.800, Learning Rate: 0.050
2017-10-23 19:58:47,326: INFO: Epoch: 249, Iter: 52300, Loss: 1.015, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 19:59:48,681: INFO: Epoch: 249, Iter: 52350, Loss: 1.117, Accuracy: 0.600, Learning Rate: 0.050
2017-10-23 20:00:50,460: INFO: Epoch: 249, Iter: 52400, Loss: 1.112, Accuracy: 0.400, Learning Rate: 0.050
2017-10-23 20:01:51,810: INFO: Epoch: 249, Iter: 52450, Loss: 1.245, Accuracy: 0.200, Learning Rate: 0.050
2017-10-23 20:02:44,730: INFO: Cycled through epochs 500 times
2017-10-23 20:02:44,730: INFO: The training is done.

2017-10-28 15:36:21,109: INFO: *** NEW RUN ***
2017-10-28 15:36:21,110: INFO: filename: trained_model_2017.10.28-15.36.20
2017-10-28 15:36:21,111: INFO: n_epochs: 500
2017-10-28 15:36:21,111: INFO: n_hidden: 32
2017-10-28 15:36:21,111: INFO: batch_size: 5
2017-10-28 15:36:21,111: INFO: n_layers: 3
2017-10-28 15:36:21,111: INFO: exp_decay_enabled: False
2017-10-28 15:36:21,112: INFO: static_lr_val: 0.050
2017-10-28 15:36:21,112: INFO: Reg Type: None
2017-10-28 15:36:21,112: INFO:   Dropout Prob: 0.50
2017-10-28 15:36:21,112: INFO:   Beta: 0.010

2017-10-28 15:36:24,631: INFO: The training shall begin.
2017-10-28 15:36:33,135: INFO: Epoch: 0, Iter: 0, Loss: 5.990, Accuracy: 0.400, Learning Rate: 0.050
2017-10-28 15:37:35,668: INFO: Epoch: 0, Iter: 50, Loss: 1.005, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 15:38:39,265: INFO: Epoch: 0, Iter: 100, Loss: 1.256, Accuracy: 0.400, Learning Rate: 0.050
2017-10-28 15:39:51,498: INFO: Epoch: 0, Iter: 150, Loss: 0.973, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 15:40:55,562: INFO: Epoch: 0, Iter: 200, Loss: 0.826, Accuracy: 0.800, Learning Rate: 0.050
2017-10-28 15:42:01,082: INFO: Epoch: 1, Iter: 250, Loss: 1.132, Accuracy: 0.400, Learning Rate: 0.050
2017-10-28 15:42:18,594: INFO: Keyboard Interrupt? Gracefully quitting
2017-10-28 15:42:18,594: INFO: The training is done.

2017-10-28 16:09:08,857: INFO: *** NEW RUN ***
2017-10-28 16:09:08,858: INFO: filename: trained_model_2017.10.28-16.09.08
2017-10-28 16:09:08,858: INFO: n_epochs: 500
2017-10-28 16:09:08,858: INFO: n_hidden: 32
2017-10-28 16:09:08,858: INFO: batch_size: 5
2017-10-28 16:09:08,859: INFO: n_layers: 3
2017-10-28 16:09:08,859: INFO: exp_decay_enabled: False
2017-10-28 16:09:08,859: INFO: static_lr_val: 0.050
2017-10-28 16:09:08,859: INFO: Reg Type: None
2017-10-28 16:09:08,859: INFO:   Dropout Prob: 0.50
2017-10-28 16:09:08,859: INFO:   Beta: 0.010

2017-10-28 16:09:12,172: INFO: The training shall begin.
2017-10-28 16:09:20,452: INFO: Epoch: 0, Iter: 0, Loss: 1.607, Accuracy: 0.400, Learning Rate: 0.050
2017-10-28 16:09:34,338: INFO: Keyboard Interrupt? Gracefully quitting
2017-10-28 16:09:34,339: INFO: The training is done.

2017-10-28 16:09:41,558: INFO: In read Batch
2017-10-28 16:09:44,342: INFO: *** NEW RUN ***
2017-10-28 16:09:44,342: INFO: filename: trained_model_2017.10.28-16.09.44
2017-10-28 16:09:44,342: INFO: n_epochs: 500
2017-10-28 16:09:44,343: INFO: n_hidden: 32
2017-10-28 16:09:44,343: INFO: batch_size: 5
2017-10-28 16:09:44,343: INFO: n_layers: 3
2017-10-28 16:09:44,343: INFO: exp_decay_enabled: False
2017-10-28 16:09:44,343: INFO: static_lr_val: 0.050
2017-10-28 16:09:44,343: INFO: Reg Type: None
2017-10-28 16:09:44,343: INFO:   Dropout Prob: 0.50
2017-10-28 16:09:44,344: INFO:   Beta: 0.010

2017-10-28 16:09:47,636: INFO: The training shall begin.
2017-10-28 16:09:55,810: INFO: Epoch: 0, Iter: 0, Loss: 1.343, Accuracy: 0.800, Learning Rate: 0.050
2017-10-28 16:10:31,712: INFO: Keyboard Interrupt? Gracefully quitting
2017-10-28 16:10:31,712: INFO: The training is done.

2017-10-28 16:11:58,848: INFO: *** NEW RUN ***
2017-10-28 16:11:58,849: INFO: filename: trained_model_2017.10.28-16.11.58
2017-10-28 16:11:58,849: INFO: n_epochs: 500
2017-10-28 16:11:58,850: INFO: n_hidden: 32
2017-10-28 16:11:58,850: INFO: batch_size: 5
2017-10-28 16:11:58,850: INFO: n_layers: 3
2017-10-28 16:11:58,850: INFO: exp_decay_enabled: False
2017-10-28 16:11:58,850: INFO: static_lr_val: 0.050
2017-10-28 16:11:58,851: INFO: Reg Type: None
2017-10-28 16:11:58,851: INFO:   Dropout Prob: 0.50
2017-10-28 16:11:58,851: INFO:   Beta: 0.010

2017-10-28 16:12:02,169: INFO: The training shall begin.
2017-10-28 16:12:10,409: INFO: Epoch: 0, Iter: 0, Loss: 3.920, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 16:12:33,999: INFO: Keyboard Interrupt? Gracefully quitting
2017-10-28 16:12:33,999: INFO: The training is done.

2017-10-28 16:14:44,530: INFO: *** NEW RUN ***
2017-10-28 16:14:44,531: INFO: filename: trained_model_2017.10.28-16.14.44
2017-10-28 16:14:44,532: INFO: n_epochs: 500
2017-10-28 16:14:44,532: INFO: n_hidden: 32
2017-10-28 16:14:44,532: INFO: batch_size: 5
2017-10-28 16:14:44,532: INFO: n_layers: 3
2017-10-28 16:14:44,532: INFO: exp_decay_enabled: False
2017-10-28 16:14:44,532: INFO: static_lr_val: 0.050
2017-10-28 16:14:44,533: INFO: Reg Type: None
2017-10-28 16:14:44,533: INFO:   Dropout Prob: 0.50
2017-10-28 16:14:44,533: INFO:   Beta: 0.010

2017-10-28 16:14:47,844: INFO: The training shall begin.
2017-10-28 16:14:52,600: INFO: The training is done.

2017-10-28 16:16:51,116: INFO: *** NEW RUN ***
2017-10-28 16:16:51,117: INFO: filename: trained_model_2017.10.28-16.16.50
2017-10-28 16:16:51,118: INFO: n_epochs: 500
2017-10-28 16:16:51,118: INFO: n_hidden: 32
2017-10-28 16:16:51,118: INFO: batch_size: 5
2017-10-28 16:16:51,118: INFO: n_layers: 3
2017-10-28 16:16:51,118: INFO: exp_decay_enabled: False
2017-10-28 16:16:51,118: INFO: static_lr_val: 0.050
2017-10-28 16:16:51,119: INFO: Reg Type: None
2017-10-28 16:16:51,119: INFO:   Dropout Prob: 0.50
2017-10-28 16:16:51,119: INFO:   Beta: 0.010

2017-10-28 16:16:54,418: INFO: The training shall begin.
2017-10-28 16:17:02,864: INFO: Epoch: 0, Iter: 0, Loss: 2.692, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 16:17:44,431: INFO: Keyboard Interrupt? Gracefully quitting
2017-10-28 16:17:44,432: INFO: The training is done.

2017-10-28 16:21:00,057: INFO: *** NEW RUN ***
2017-10-28 16:21:00,057: INFO: filename: trained_model_2017.10.28-16.20.59
2017-10-28 16:21:00,058: INFO: n_epochs: 1
2017-10-28 16:21:00,058: INFO: n_hidden: 32
2017-10-28 16:21:00,058: INFO: batch_size: 5
2017-10-28 16:21:00,058: INFO: n_layers: 3
2017-10-28 16:21:00,058: INFO: exp_decay_enabled: False
2017-10-28 16:21:00,058: INFO: static_lr_val: 0.050
2017-10-28 16:21:00,059: INFO: Reg Type: None
2017-10-28 16:21:00,059: INFO:   Dropout Prob: 0.50
2017-10-28 16:21:00,059: INFO:   Beta: 0.010

2017-10-28 16:21:03,479: INFO: The training shall begin.
2017-10-28 16:21:12,340: INFO: Epoch: 0, Iter: 0, Loss: 4.996, Accuracy: 0.400, Learning Rate: 0.050
2017-10-28 16:22:15,449: INFO: Epoch: 0, Iter: 50, Loss: 1.009, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 16:23:18,914: INFO: Epoch: 0, Iter: 100, Loss: 0.991, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 16:23:19,924: INFO: Cycled through epochs 1 times
2017-10-28 16:23:19,924: INFO: The training is done.

2017-10-28 16:59:49,523: INFO: *** NEW RUN ***
2017-10-28 16:59:49,524: INFO: filename: trained_model_2017.10.28-16.59.49
2017-10-28 16:59:49,525: INFO: n_epochs: 1
2017-10-28 16:59:49,525: INFO: n_hidden: 32
2017-10-28 16:59:49,525: INFO: batch_size: 5
2017-10-28 16:59:49,525: INFO: n_layers: 3
2017-10-28 16:59:49,525: INFO: exp_decay_enabled: False
2017-10-28 16:59:49,526: INFO: static_lr_val: 0.050
2017-10-28 16:59:49,526: INFO: Reg Type: None
2017-10-28 16:59:49,526: INFO:   Dropout Prob: 0.50
2017-10-28 16:59:49,526: INFO:   Beta: 0.010

2017-10-28 16:59:52,809: INFO: The training shall begin.
2017-10-28 17:00:01,146: INFO: Epoch: 0, Iter: 0, Loss: 2.880, Accuracy: 0.800, Learning Rate: 0.050
2017-10-28 17:00:10,438: INFO: Epoch: 0, Iter: 5, Loss: 0.491, Accuracy: 0.800, Learning Rate: 0.050
2017-10-28 17:00:20,826: INFO: Epoch: 0, Iter: 10, Loss: 1.516, Accuracy: 0.400, Learning Rate: 0.050
2017-10-28 17:00:29,960: INFO: Epoch: 0, Iter: 15, Loss: 1.194, Accuracy: 0.800, Learning Rate: 0.050
2017-10-28 17:00:38,960: INFO: Epoch: 0, Iter: 20, Loss: 1.968, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 17:00:48,011: INFO: Epoch: 0, Iter: 25, Loss: 1.715, Accuracy: 0.400, Learning Rate: 0.050
2017-10-28 17:00:57,104: INFO: Epoch: 0, Iter: 30, Loss: 0.912, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 17:01:06,097: INFO: Epoch: 0, Iter: 35, Loss: 0.644, Accuracy: 0.800, Learning Rate: 0.050
2017-10-28 17:01:15,047: INFO: Epoch: 0, Iter: 40, Loss: 1.845, Accuracy: 0.200, Learning Rate: 0.050
2017-10-28 17:01:24,190: INFO: Epoch: 0, Iter: 45, Loss: 1.213, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 17:01:33,320: INFO: Epoch: 0, Iter: 50, Loss: 1.364, Accuracy: 0.200, Learning Rate: 0.050
2017-10-28 17:01:42,549: INFO: Epoch: 0, Iter: 55, Loss: 1.171, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 17:01:52,050: INFO: Epoch: 0, Iter: 60, Loss: 0.886, Accuracy: 0.400, Learning Rate: 0.050
2017-10-28 17:02:01,292: INFO: Epoch: 0, Iter: 65, Loss: 1.012, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 17:02:10,424: INFO: Epoch: 0, Iter: 70, Loss: 1.038, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 17:02:19,549: INFO: Epoch: 0, Iter: 75, Loss: 1.129, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 17:02:28,816: INFO: Epoch: 0, Iter: 80, Loss: 0.934, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 17:02:37,850: INFO: Epoch: 0, Iter: 85, Loss: 1.084, Accuracy: 0.400, Learning Rate: 0.050
2017-10-28 17:02:46,950: INFO: Epoch: 0, Iter: 90, Loss: 1.105, Accuracy: 0.400, Learning Rate: 0.050
2017-10-28 17:02:56,402: INFO: Epoch: 0, Iter: 95, Loss: 0.810, Accuracy: 0.800, Learning Rate: 0.050
2017-10-28 17:03:05,632: INFO: Epoch: 0, Iter: 100, Loss: 0.970, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 17:03:06,700: INFO: Cycled through epochs 1 times
2017-10-28 17:03:06,701: INFO: The training is done.

2017-10-28 17:06:39,920: INFO: *** NEW RUN ***
2017-10-28 17:06:39,920: INFO: filename: trained_model_2017.10.28-17.06.39
2017-10-28 17:06:39,921: INFO: n_epochs: 1
2017-10-28 17:06:39,921: INFO: n_hidden: 32
2017-10-28 17:06:39,921: INFO: batch_size: 5
2017-10-28 17:06:39,921: INFO: n_layers: 3
2017-10-28 17:06:39,921: INFO: exp_decay_enabled: False
2017-10-28 17:06:39,921: INFO: static_lr_val: 0.050
2017-10-28 17:06:39,922: INFO: Reg Type: None
2017-10-28 17:06:39,922: INFO:   Dropout Prob: 0.50
2017-10-28 17:06:39,922: INFO:   Beta: 0.010

2017-10-28 17:06:43,237: INFO: The training shall begin.
2017-10-28 17:06:43,238: INFO: The training is done.

2017-10-28 17:07:03,262: INFO: *** NEW RUN ***
2017-10-28 17:07:03,263: INFO: filename: trained_model_2017.10.28-17.07.03
2017-10-28 17:07:03,263: INFO: n_epochs: 1
2017-10-28 17:07:03,264: INFO: n_hidden: 32
2017-10-28 17:07:03,264: INFO: batch_size: 5
2017-10-28 17:07:03,264: INFO: n_layers: 3
2017-10-28 17:07:03,264: INFO: exp_decay_enabled: False
2017-10-28 17:07:03,264: INFO: static_lr_val: 0.050
2017-10-28 17:07:03,264: INFO: Reg Type: None
2017-10-28 17:07:03,265: INFO:   Dropout Prob: 0.50
2017-10-28 17:07:03,265: INFO:   Beta: 0.010

2017-10-28 17:07:06,571: INFO: The training shall begin.
2017-10-28 17:07:15,390: INFO: Epoch: 0, Iter: 0, Loss: 11.754, Accuracy: 0.400, Learning Rate: 0.050
2017-10-28 17:07:24,790: INFO: Epoch: 0, Iter: 5, Loss: 1.704, Accuracy: 0.400, Learning Rate: 0.050
2017-10-28 17:07:34,670: INFO: Epoch: 0, Iter: 10, Loss: 1.200, Accuracy: 0.400, Learning Rate: 0.050
2017-10-28 17:07:43,874: INFO: Epoch: 0, Iter: 15, Loss: 2.328, Accuracy: 0.200, Learning Rate: 0.050
2017-10-28 17:07:53,033: INFO: Epoch: 0, Iter: 20, Loss: 1.537, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 17:08:02,350: INFO: Epoch: 0, Iter: 25, Loss: 2.866, Accuracy: 0.800, Learning Rate: 0.050
2017-10-28 17:08:11,625: INFO: Epoch: 0, Iter: 30, Loss: 0.838, Accuracy: 0.800, Learning Rate: 0.050
2017-10-28 17:08:20,749: INFO: Epoch: 0, Iter: 35, Loss: 1.146, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 17:08:30,161: INFO: Epoch: 0, Iter: 40, Loss: 1.521, Accuracy: 0.000, Learning Rate: 0.050
2017-10-28 17:08:39,434: INFO: Epoch: 0, Iter: 45, Loss: 1.409, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 17:08:47,646: INFO: Cycled through epochs 1 times
2017-10-28 17:08:47,647: INFO: The training is done.

2017-10-28 17:12:41,871: INFO: *** NEW RUN ***
2017-10-28 17:12:41,872: INFO: filename: trained_model_2017.10.28-17.12.41
2017-10-28 17:12:41,873: INFO: n_epochs: 1
2017-10-28 17:12:41,873: INFO: n_hidden: 32
2017-10-28 17:12:41,873: INFO: batch_size: 5
2017-10-28 17:12:41,873: INFO: n_layers: 3
2017-10-28 17:12:41,874: INFO: exp_decay_enabled: False
2017-10-28 17:12:41,874: INFO: static_lr_val: 0.050
2017-10-28 17:12:41,874: INFO: Reg Type: None
2017-10-28 17:12:41,874: INFO:   Dropout Prob: 0.50
2017-10-28 17:12:41,874: INFO:   Beta: 0.010

2017-10-28 17:12:45,161: INFO: The training shall begin.
2017-10-28 17:12:51,660: INFO: Epoch: 0, Iter: 0, Loss: 1.186, Accuracy: 0.200, Learning Rate: 0.050
2017-10-28 17:12:58,922: INFO: Epoch: 0, Iter: 5, Loss: 5.576, Accuracy: 0.000, Learning Rate: 0.050
2017-10-28 17:13:06,814: INFO: Epoch: 0, Iter: 10, Loss: 1.121, Accuracy: 0.400, Learning Rate: 0.050
2017-10-28 17:13:13,975: INFO: Epoch: 0, Iter: 15, Loss: 1.093, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 17:13:21,006: INFO: Epoch: 0, Iter: 20, Loss: 1.034, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 17:13:28,273: INFO: Epoch: 0, Iter: 25, Loss: 0.855, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 17:13:35,700: INFO: Epoch: 0, Iter: 30, Loss: 1.452, Accuracy: 0.400, Learning Rate: 0.050
2017-10-28 17:13:42,856: INFO: Epoch: 0, Iter: 35, Loss: 1.222, Accuracy: 0.200, Learning Rate: 0.050
2017-10-28 17:13:50,044: INFO: Epoch: 0, Iter: 40, Loss: 1.345, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 17:13:57,290: INFO: Epoch: 0, Iter: 45, Loss: 1.910, Accuracy: 0.400, Learning Rate: 0.050
2017-10-28 17:14:04,671: INFO: Epoch: 0, Iter: 50, Loss: 1.261, Accuracy: 0.200, Learning Rate: 0.050
2017-10-28 17:14:11,838: INFO: Epoch: 0, Iter: 55, Loss: 1.491, Accuracy: 0.400, Learning Rate: 0.050
2017-10-28 17:14:18,909: INFO: Epoch: 0, Iter: 60, Loss: 1.405, Accuracy: 0.400, Learning Rate: 0.050
2017-10-28 17:14:26,021: INFO: Epoch: 0, Iter: 65, Loss: 0.865, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 17:14:33,501: INFO: Epoch: 0, Iter: 70, Loss: 0.945, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 17:14:40,858: INFO: Epoch: 0, Iter: 75, Loss: 0.965, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 17:14:48,819: INFO: Epoch: 0, Iter: 80, Loss: 1.149, Accuracy: 0.400, Learning Rate: 0.050
2017-10-28 17:14:57,270: INFO: Epoch: 0, Iter: 85, Loss: 1.427, Accuracy: 0.000, Learning Rate: 0.050
2017-10-28 17:15:05,746: INFO: Epoch: 0, Iter: 90, Loss: 0.932, Accuracy: 0.600, Learning Rate: 0.050
2017-10-28 17:15:14,450: INFO: Epoch: 0, Iter: 95, Loss: 1.172, Accuracy: 0.400, Learning Rate: 0.050
2017-10-28 17:15:22,350: INFO: Epoch: 0, Iter: 100, Loss: 1.264, Accuracy: 0.400, Learning Rate: 0.050
2017-10-28 17:15:23,750: INFO: Cycled through epochs 1 times
2017-10-28 17:15:23,750: INFO: The training is done.

2017-10-28 17:17:56,347: INFO: *** NEW RUN ***
2017-10-28 17:17:56,349: INFO: filename: trained_model_2017.10.28-17.17.56
2017-10-28 17:17:56,349: INFO: n_epochs: 1
2017-10-28 17:17:56,350: INFO: n_hidden: 32
2017-10-28 17:17:56,350: INFO: batch_size: 5
2017-10-28 17:17:56,350: INFO: n_layers: 3
2017-10-28 17:17:56,350: INFO: exp_decay_enabled: False
2017-10-28 17:17:56,350: INFO: static_lr_val: 0.050
2017-10-28 17:17:56,351: INFO: Reg Type: None
2017-10-28 17:17:56,351: INFO:   Dropout Prob: 0.50
2017-10-28 17:17:56,351: INFO:   Beta: 0.010

2017-10-28 17:17:59,693: INFO: The training shall begin.
2017-10-28 17:18:06,012: INFO: Epoch: 0, Iter: 0, Loss: 2.156, Accuracy: 0.000, Learning Rate: 0.050
2017-10-28 17:18:20,382: INFO: Cycled through epochs 1 times
2017-10-28 17:18:20,382: INFO: The training is done.

2017-10-30 09:39:46,163: INFO: *** NEW RUN ***
2017-10-30 09:39:46,164: INFO: filename: trained_model_2017.10.30-09.39.46
2017-10-30 09:39:46,165: INFO: n_epochs: 250
2017-10-30 09:39:46,165: INFO: n_hidden: 32
2017-10-30 09:39:46,165: INFO: batch_size: 5
2017-10-30 09:39:46,165: INFO: n_layers: 3
2017-10-30 09:39:46,165: INFO: Normalization: True
2017-10-30 09:39:46,165: INFO: exp_decay_enabled: False
2017-10-30 09:39:46,166: INFO: static_lr_val: 0.050
2017-10-30 09:39:46,166: INFO: Reg Type: Dropout
2017-10-30 09:39:46,166: INFO:   Dropout Prob: 0.50
2017-10-30 09:39:46,166: INFO:   Beta: 0.010

2017-10-30 09:39:50,063: INFO: The training shall begin.
2017-10-30 09:39:58,711: INFO: Keyboard Interrupt? Gracefully quitting
2017-10-30 09:39:58,712: INFO: The training is done.

2017-10-30 09:40:18,560: INFO: *** NEW RUN ***
2017-10-30 09:40:18,560: INFO: filename: trained_model_2017.10.30-09.40.18
2017-10-30 09:40:18,560: INFO: n_epochs: 250
2017-10-30 09:40:18,560: INFO: n_hidden: 32
2017-10-30 09:40:18,560: INFO: batch_size: 5
2017-10-30 09:40:18,561: INFO: n_layers: 3
2017-10-30 09:40:18,561: INFO: Normalization: False
2017-10-30 09:40:18,561: INFO: exp_decay_enabled: False
2017-10-30 09:40:18,561: INFO: static_lr_val: 0.050
2017-10-30 09:40:18,561: INFO: Reg Type: Dropout
2017-10-30 09:40:18,561: INFO:   Dropout Prob: 0.50
2017-10-30 09:40:18,562: INFO:   Beta: 0.010

2017-10-30 09:40:22,364: INFO: The training shall begin.
2017-10-30 09:40:31,127: INFO: Epoch: 0, Iter: 0, Loss: 0.962, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 09:41:38,443: INFO: Epoch: 0, Iter: 50, Loss: 10.862, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 09:42:45,815: INFO: Epoch: 0, Iter: 100, Loss: 9.638, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 09:43:53,201: INFO: Epoch: 0, Iter: 150, Loss: 5.646, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 09:45:00,557: INFO: Epoch: 0, Iter: 200, Loss: 3.016, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 09:46:07,583: INFO: Epoch: 1, Iter: 250, Loss: 0.049, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 09:47:16,464: INFO: Epoch: 1, Iter: 300, Loss: 3.817, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 09:48:27,185: INFO: Epoch: 1, Iter: 350, Loss: 1.322, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 09:49:36,185: INFO: Epoch: 1, Iter: 400, Loss: 0.327, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 09:49:39,628: INFO: Epoch: 2, Iter: 450, Loss: 1.180, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 09:50:46,345: INFO: Epoch: 2, Iter: 500, Loss: 0.635, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 09:51:53,639: INFO: Epoch: 2, Iter: 550, Loss: 1.142, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 09:53:01,066: INFO: Epoch: 2, Iter: 600, Loss: 0.162, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 09:54:08,283: INFO: Epoch: 3, Iter: 650, Loss: 0.259, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 09:55:15,692: INFO: Epoch: 3, Iter: 700, Loss: 1.100, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 09:56:23,148: INFO: Epoch: 3, Iter: 750, Loss: 0.183, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 09:57:30,847: INFO: Epoch: 3, Iter: 800, Loss: 0.187, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 09:58:37,995: INFO: Epoch: 4, Iter: 850, Loss: 0.796, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 09:59:45,012: INFO: Epoch: 4, Iter: 900, Loss: 1.356, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:00:52,383: INFO: Epoch: 4, Iter: 950, Loss: 0.261, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 10:01:59,970: INFO: Epoch: 4, Iter: 1000, Loss: 1.203, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:03:07,557: INFO: Epoch: 5, Iter: 1050, Loss: 0.896, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 10:04:14,672: INFO: Epoch: 5, Iter: 1100, Loss: 1.008, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 10:05:21,934: INFO: Epoch: 5, Iter: 1150, Loss: 1.252, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:06:29,356: INFO: Epoch: 5, Iter: 1200, Loss: 0.517, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 10:07:36,562: INFO: Epoch: 5, Iter: 1250, Loss: 0.964, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 10:08:44,937: INFO: Epoch: 6, Iter: 1300, Loss: 0.555, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 10:09:52,262: INFO: Epoch: 6, Iter: 1350, Loss: 1.017, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:10:59,634: INFO: Epoch: 6, Iter: 1400, Loss: 0.857, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 10:12:06,723: INFO: Epoch: 6, Iter: 1450, Loss: 1.534, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:13:13,952: INFO: Epoch: 7, Iter: 1500, Loss: 0.985, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:14:21,289: INFO: Epoch: 7, Iter: 1550, Loss: 1.699, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:15:28,531: INFO: Epoch: 7, Iter: 1600, Loss: 1.655, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:16:36,329: INFO: Epoch: 7, Iter: 1650, Loss: 0.609, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 10:17:43,688: INFO: Epoch: 8, Iter: 1700, Loss: 1.294, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:18:52,041: INFO: Epoch: 8, Iter: 1750, Loss: 1.520, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:19:58,893: INFO: Epoch: 8, Iter: 1800, Loss: 0.996, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 10:21:06,360: INFO: Epoch: 8, Iter: 1850, Loss: 1.258, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:22:13,974: INFO: Epoch: 9, Iter: 1900, Loss: 0.987, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:23:21,228: INFO: Epoch: 9, Iter: 1950, Loss: 0.641, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 10:24:28,331: INFO: Epoch: 9, Iter: 2000, Loss: 0.622, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 10:25:35,713: INFO: Epoch: 9, Iter: 2050, Loss: 0.383, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 10:26:42,771: INFO: Epoch: 10, Iter: 2100, Loss: 0.540, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 10:27:50,487: INFO: Epoch: 10, Iter: 2150, Loss: 1.354, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:28:57,917: INFO: Epoch: 10, Iter: 2200, Loss: 1.173, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:30:05,320: INFO: Epoch: 10, Iter: 2250, Loss: 2.383, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:31:12,770: INFO: Epoch: 10, Iter: 2300, Loss: 0.734, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 10:32:19,257: INFO: Epoch: 11, Iter: 2350, Loss: 2.519, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:33:26,700: INFO: Epoch: 11, Iter: 2400, Loss: 0.909, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 10:34:34,112: INFO: Epoch: 11, Iter: 2450, Loss: 1.510, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:35:41,257: INFO: Epoch: 11, Iter: 2500, Loss: 1.105, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:36:48,844: INFO: Epoch: 12, Iter: 2550, Loss: 0.672, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 10:37:56,327: INFO: Epoch: 12, Iter: 2600, Loss: 0.732, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 10:39:03,648: INFO: Epoch: 12, Iter: 2650, Loss: 0.997, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:40:10,868: INFO: Epoch: 12, Iter: 2700, Loss: 1.573, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:41:17,933: INFO: Epoch: 13, Iter: 2750, Loss: 1.955, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:42:25,079: INFO: Epoch: 13, Iter: 2800, Loss: 0.691, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 10:43:32,210: INFO: Epoch: 13, Iter: 2850, Loss: 1.557, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:44:39,157: INFO: Epoch: 13, Iter: 2900, Loss: 1.340, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:45:46,476: INFO: Epoch: 14, Iter: 2950, Loss: 1.043, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:46:53,891: INFO: Epoch: 14, Iter: 3000, Loss: 0.760, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 10:48:01,541: INFO: Epoch: 14, Iter: 3050, Loss: 0.714, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 10:49:09,172: INFO: Epoch: 14, Iter: 3100, Loss: 1.393, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:50:17,623: INFO: Epoch: 15, Iter: 3150, Loss: 0.900, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 10:51:24,732: INFO: Epoch: 15, Iter: 3200, Loss: 0.893, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 10:52:31,752: INFO: Epoch: 15, Iter: 3250, Loss: 0.641, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 10:53:39,172: INFO: Epoch: 15, Iter: 3300, Loss: 0.635, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 10:54:46,189: INFO: Epoch: 15, Iter: 3350, Loss: 1.734, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:55:53,348: INFO: Epoch: 16, Iter: 3400, Loss: 0.635, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 10:57:01,181: INFO: Epoch: 16, Iter: 3450, Loss: 1.601, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:58:08,583: INFO: Epoch: 16, Iter: 3500, Loss: 1.298, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 10:59:16,075: INFO: Epoch: 16, Iter: 3550, Loss: 0.829, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 11:00:23,740: INFO: Epoch: 17, Iter: 3600, Loss: 1.568, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:01:30,773: INFO: Epoch: 17, Iter: 3650, Loss: 1.151, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:02:38,162: INFO: Epoch: 17, Iter: 3700, Loss: 1.153, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:03:45,554: INFO: Epoch: 17, Iter: 3750, Loss: 1.415, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:04:52,879: INFO: Epoch: 18, Iter: 3800, Loss: 0.953, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 11:06:00,208: INFO: Epoch: 18, Iter: 3850, Loss: 0.928, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:07:07,847: INFO: Epoch: 18, Iter: 3900, Loss: 1.187, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:08:15,356: INFO: Epoch: 18, Iter: 3950, Loss: 1.035, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:09:22,672: INFO: Epoch: 19, Iter: 4000, Loss: 0.991, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 11:10:30,023: INFO: Epoch: 19, Iter: 4050, Loss: 1.021, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:11:37,480: INFO: Epoch: 19, Iter: 4100, Loss: 1.830, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:12:44,670: INFO: Epoch: 19, Iter: 4150, Loss: 1.495, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:13:53,271: INFO: Epoch: 20, Iter: 4200, Loss: 1.363, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:15:00,608: INFO: Epoch: 20, Iter: 4250, Loss: 0.714, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 11:16:07,795: INFO: Epoch: 20, Iter: 4300, Loss: 1.195, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:17:15,231: INFO: Epoch: 20, Iter: 4350, Loss: 1.551, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:18:22,482: INFO: Epoch: 20, Iter: 4400, Loss: 1.210, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:19:29,978: INFO: Epoch: 21, Iter: 4450, Loss: 1.553, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:20:37,819: INFO: Epoch: 21, Iter: 4500, Loss: 0.674, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 11:21:45,809: INFO: Epoch: 21, Iter: 4550, Loss: 0.788, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 11:22:53,475: INFO: Epoch: 21, Iter: 4600, Loss: 1.357, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:24:00,948: INFO: Epoch: 22, Iter: 4650, Loss: 0.649, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 11:25:08,321: INFO: Epoch: 22, Iter: 4700, Loss: 1.428, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:26:14,967: INFO: Epoch: 22, Iter: 4750, Loss: 1.259, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:27:22,579: INFO: Epoch: 22, Iter: 4800, Loss: 0.614, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 11:28:30,171: INFO: Epoch: 23, Iter: 4850, Loss: 0.688, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 11:29:37,242: INFO: Epoch: 23, Iter: 4900, Loss: 0.730, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 11:30:44,559: INFO: Epoch: 23, Iter: 4950, Loss: 1.241, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:31:52,372: INFO: Epoch: 23, Iter: 5000, Loss: 0.789, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 11:33:00,150: INFO: Epoch: 24, Iter: 5050, Loss: 1.158, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:34:07,331: INFO: Epoch: 24, Iter: 5100, Loss: 1.456, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:35:14,366: INFO: Epoch: 24, Iter: 5150, Loss: 1.007, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:36:21,686: INFO: Epoch: 24, Iter: 5200, Loss: 1.500, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:37:29,481: INFO: Epoch: 25, Iter: 5250, Loss: 1.089, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:38:38,021: INFO: Epoch: 25, Iter: 5300, Loss: 1.447, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:39:45,083: INFO: Epoch: 25, Iter: 5350, Loss: 0.853, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 11:40:52,379: INFO: Epoch: 25, Iter: 5400, Loss: 1.491, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:41:59,654: INFO: Epoch: 25, Iter: 5450, Loss: 1.169, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:43:07,434: INFO: Epoch: 26, Iter: 5500, Loss: 0.815, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 11:44:14,541: INFO: Epoch: 26, Iter: 5550, Loss: 1.289, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:45:21,725: INFO: Epoch: 26, Iter: 5600, Loss: 0.481, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 11:46:28,927: INFO: Epoch: 26, Iter: 5650, Loss: 0.709, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 11:47:36,708: INFO: Epoch: 27, Iter: 5700, Loss: 1.298, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:48:44,274: INFO: Epoch: 27, Iter: 5750, Loss: 0.773, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 11:49:51,459: INFO: Epoch: 27, Iter: 5800, Loss: 0.809, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 11:50:58,362: INFO: Epoch: 27, Iter: 5850, Loss: 1.285, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:52:05,693: INFO: Epoch: 28, Iter: 5900, Loss: 0.879, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 11:53:12,997: INFO: Epoch: 28, Iter: 5950, Loss: 1.206, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:54:20,383: INFO: Epoch: 28, Iter: 6000, Loss: 1.385, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:55:27,314: INFO: Epoch: 28, Iter: 6050, Loss: 0.753, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 11:56:34,832: INFO: Epoch: 29, Iter: 6100, Loss: 1.210, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:57:42,085: INFO: Epoch: 29, Iter: 6150, Loss: 1.114, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 11:58:49,903: INFO: Epoch: 29, Iter: 6200, Loss: 0.773, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 11:59:57,213: INFO: Epoch: 29, Iter: 6250, Loss: 0.679, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:01:04,384: INFO: Epoch: 30, Iter: 6300, Loss: 0.634, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:02:11,856: INFO: Epoch: 30, Iter: 6350, Loss: 1.491, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 12:03:19,677: INFO: Epoch: 30, Iter: 6400, Loss: 0.644, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:04:26,944: INFO: Epoch: 30, Iter: 6450, Loss: 0.625, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:05:34,194: INFO: Epoch: 30, Iter: 6500, Loss: 0.560, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:06:41,683: INFO: Epoch: 31, Iter: 6550, Loss: 1.489, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 12:07:48,722: INFO: Epoch: 31, Iter: 6600, Loss: 0.815, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:08:56,187: INFO: Epoch: 31, Iter: 6650, Loss: 1.156, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 12:10:03,520: INFO: Epoch: 31, Iter: 6700, Loss: 1.073, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 12:11:10,656: INFO: Epoch: 32, Iter: 6750, Loss: 0.917, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:12:17,532: INFO: Epoch: 32, Iter: 6800, Loss: 1.426, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 12:13:25,023: INFO: Epoch: 32, Iter: 6850, Loss: 0.559, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:14:32,344: INFO: Epoch: 32, Iter: 6900, Loss: 0.978, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:15:39,122: INFO: Epoch: 33, Iter: 6950, Loss: 0.916, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:16:46,406: INFO: Epoch: 33, Iter: 7000, Loss: 1.351, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 12:17:54,173: INFO: Epoch: 33, Iter: 7050, Loss: 0.774, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:19:01,470: INFO: Epoch: 33, Iter: 7100, Loss: 1.343, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 12:20:08,535: INFO: Epoch: 34, Iter: 7150, Loss: 0.628, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:21:15,579: INFO: Epoch: 34, Iter: 7200, Loss: 0.555, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:22:23,933: INFO: Epoch: 34, Iter: 7250, Loss: 0.569, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:23:31,197: INFO: Epoch: 34, Iter: 7300, Loss: 0.525, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:24:38,264: INFO: Epoch: 35, Iter: 7350, Loss: 0.546, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:25:45,492: INFO: Epoch: 35, Iter: 7400, Loss: 1.564, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 12:26:52,667: INFO: Epoch: 35, Iter: 7450, Loss: 1.404, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 12:28:00,732: INFO: Epoch: 35, Iter: 7500, Loss: 1.394, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 12:29:08,361: INFO: Epoch: 35, Iter: 7550, Loss: 1.229, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 12:30:15,758: INFO: Epoch: 36, Iter: 7600, Loss: 0.814, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:31:23,020: INFO: Epoch: 36, Iter: 7650, Loss: 0.727, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:32:30,311: INFO: Epoch: 36, Iter: 7700, Loss: 0.841, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:33:37,684: INFO: Epoch: 36, Iter: 7750, Loss: 1.253, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 12:34:44,958: INFO: Epoch: 37, Iter: 7800, Loss: 1.200, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 12:35:52,248: INFO: Epoch: 37, Iter: 7850, Loss: 1.067, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 12:37:00,109: INFO: Epoch: 37, Iter: 7900, Loss: 0.851, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:38:08,629: INFO: Epoch: 37, Iter: 7950, Loss: 0.713, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:39:15,846: INFO: Epoch: 38, Iter: 8000, Loss: 0.590, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:40:23,410: INFO: Epoch: 38, Iter: 8050, Loss: 1.519, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 12:41:30,876: INFO: Epoch: 38, Iter: 8100, Loss: 1.500, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 12:42:38,099: INFO: Epoch: 38, Iter: 8150, Loss: 0.617, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:43:45,958: INFO: Epoch: 39, Iter: 8200, Loss: 0.606, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:44:53,470: INFO: Epoch: 39, Iter: 8250, Loss: 1.221, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 12:46:00,367: INFO: Epoch: 39, Iter: 8300, Loss: 1.183, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 12:47:07,952: INFO: Epoch: 39, Iter: 8350, Loss: 0.742, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:48:15,449: INFO: Epoch: 40, Iter: 8400, Loss: 0.742, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:49:22,475: INFO: Epoch: 40, Iter: 8450, Loss: 1.637, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 12:50:29,385: INFO: Epoch: 40, Iter: 8500, Loss: 0.780, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:51:36,464: INFO: Epoch: 40, Iter: 8550, Loss: 0.704, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:52:43,921: INFO: Epoch: 40, Iter: 8600, Loss: 1.184, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 12:53:51,471: INFO: Epoch: 41, Iter: 8650, Loss: 0.782, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:54:59,014: INFO: Epoch: 41, Iter: 8700, Loss: 1.107, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 12:56:06,504: INFO: Epoch: 41, Iter: 8750, Loss: 0.689, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:57:14,162: INFO: Epoch: 41, Iter: 8800, Loss: 0.709, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:58:21,365: INFO: Epoch: 42, Iter: 8850, Loss: 0.700, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 12:59:28,322: INFO: Epoch: 42, Iter: 8900, Loss: 1.643, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:00:35,497: INFO: Epoch: 42, Iter: 8950, Loss: 0.713, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 13:01:42,648: INFO: Epoch: 42, Iter: 9000, Loss: 1.022, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:02:50,016: INFO: Epoch: 43, Iter: 9050, Loss: 0.861, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 13:03:57,221: INFO: Epoch: 43, Iter: 9100, Loss: 0.876, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 13:05:04,552: INFO: Epoch: 43, Iter: 9150, Loss: 0.914, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 13:06:11,587: INFO: Epoch: 43, Iter: 9200, Loss: 1.346, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:07:18,840: INFO: Epoch: 44, Iter: 9250, Loss: 1.183, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:08:26,070: INFO: Epoch: 44, Iter: 9300, Loss: 1.159, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:09:32,853: INFO: Epoch: 44, Iter: 9350, Loss: 1.404, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:10:40,255: INFO: Epoch: 44, Iter: 9400, Loss: 0.711, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 13:11:47,605: INFO: Epoch: 45, Iter: 9450, Loss: 1.407, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:12:55,199: INFO: Epoch: 45, Iter: 9500, Loss: 1.659, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:14:02,299: INFO: Epoch: 45, Iter: 9550, Loss: 0.659, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 13:15:10,023: INFO: Epoch: 45, Iter: 9600, Loss: 1.387, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:16:17,131: INFO: Epoch: 45, Iter: 9650, Loss: 1.333, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:17:24,689: INFO: Epoch: 46, Iter: 9700, Loss: 1.293, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:18:32,352: INFO: Epoch: 46, Iter: 9750, Loss: 0.851, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 13:19:39,703: INFO: Epoch: 46, Iter: 9800, Loss: 1.357, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:20:47,128: INFO: Epoch: 46, Iter: 9850, Loss: 1.345, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:21:54,575: INFO: Epoch: 47, Iter: 9900, Loss: 0.788, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 13:23:01,777: INFO: Epoch: 47, Iter: 9950, Loss: 0.699, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 13:24:09,279: INFO: Epoch: 47, Iter: 10000, Loss: 1.553, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:25:16,468: INFO: Epoch: 47, Iter: 10050, Loss: 1.191, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:26:23,621: INFO: Epoch: 48, Iter: 10100, Loss: 1.394, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:27:30,978: INFO: Epoch: 48, Iter: 10150, Loss: 1.077, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:28:38,884: INFO: Epoch: 48, Iter: 10200, Loss: 1.068, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:29:46,150: INFO: Epoch: 48, Iter: 10250, Loss: 0.790, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 13:30:53,285: INFO: Epoch: 49, Iter: 10300, Loss: 1.526, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:32:00,840: INFO: Epoch: 49, Iter: 10350, Loss: 0.615, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 13:33:08,093: INFO: Epoch: 49, Iter: 10400, Loss: 0.574, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 13:34:15,237: INFO: Epoch: 49, Iter: 10450, Loss: 1.555, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:35:22,540: INFO: Epoch: 50, Iter: 10500, Loss: 0.686, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 13:36:29,718: INFO: Epoch: 50, Iter: 10550, Loss: 1.341, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:37:36,942: INFO: Epoch: 50, Iter: 10600, Loss: 0.715, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 13:38:44,640: INFO: Epoch: 50, Iter: 10650, Loss: 1.356, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:39:51,697: INFO: Epoch: 50, Iter: 10700, Loss: 0.715, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 13:40:58,883: INFO: Epoch: 51, Iter: 10750, Loss: 0.686, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 13:42:06,444: INFO: Epoch: 51, Iter: 10800, Loss: 0.713, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 13:43:14,213: INFO: Epoch: 51, Iter: 10850, Loss: 0.856, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 13:44:21,077: INFO: Epoch: 51, Iter: 10900, Loss: 0.831, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 13:45:28,051: INFO: Epoch: 52, Iter: 10950, Loss: 0.755, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 13:46:35,253: INFO: Epoch: 52, Iter: 11000, Loss: 1.246, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:47:42,454: INFO: Epoch: 52, Iter: 11050, Loss: 0.620, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 13:48:49,995: INFO: Epoch: 52, Iter: 11100, Loss: 1.750, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:49:57,191: INFO: Epoch: 53, Iter: 11150, Loss: 0.540, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 13:51:04,663: INFO: Epoch: 53, Iter: 11200, Loss: 0.610, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 13:52:11,388: INFO: Epoch: 53, Iter: 11250, Loss: 1.660, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:53:18,671: INFO: Epoch: 53, Iter: 11300, Loss: 1.213, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:54:25,758: INFO: Epoch: 54, Iter: 11350, Loss: 0.977, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 13:55:32,848: INFO: Epoch: 54, Iter: 11400, Loss: 1.248, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:56:39,964: INFO: Epoch: 54, Iter: 11450, Loss: 1.148, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 13:57:47,030: INFO: Epoch: 54, Iter: 11500, Loss: 0.986, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 13:58:54,023: INFO: Epoch: 55, Iter: 11550, Loss: 0.789, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 14:00:01,127: INFO: Epoch: 55, Iter: 11600, Loss: 0.683, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 14:01:08,515: INFO: Epoch: 55, Iter: 11650, Loss: 1.569, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:02:14,981: INFO: Epoch: 55, Iter: 11700, Loss: 1.577, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:03:22,054: INFO: Epoch: 55, Iter: 11750, Loss: 0.615, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 14:04:29,024: INFO: Epoch: 56, Iter: 11800, Loss: 0.644, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 14:05:36,144: INFO: Epoch: 56, Iter: 11850, Loss: 1.345, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:06:43,706: INFO: Epoch: 56, Iter: 11900, Loss: 0.842, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 14:07:51,393: INFO: Epoch: 56, Iter: 11950, Loss: 0.829, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 14:08:58,202: INFO: Epoch: 57, Iter: 12000, Loss: 0.971, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:10:05,120: INFO: Epoch: 57, Iter: 12050, Loss: 0.943, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:11:11,864: INFO: Epoch: 57, Iter: 12100, Loss: 0.867, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 14:12:18,762: INFO: Epoch: 57, Iter: 12150, Loss: 0.860, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 14:13:26,574: INFO: Epoch: 58, Iter: 12200, Loss: 0.827, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 14:14:33,724: INFO: Epoch: 58, Iter: 12250, Loss: 1.455, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:15:40,897: INFO: Epoch: 58, Iter: 12300, Loss: 0.829, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 14:16:47,851: INFO: Epoch: 58, Iter: 12350, Loss: 0.868, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 14:17:54,874: INFO: Epoch: 59, Iter: 12400, Loss: 1.191, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:19:01,922: INFO: Epoch: 59, Iter: 12450, Loss: 0.649, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 14:20:09,206: INFO: Epoch: 59, Iter: 12500, Loss: 0.689, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 14:21:16,609: INFO: Epoch: 59, Iter: 12550, Loss: 0.694, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 14:22:23,972: INFO: Epoch: 60, Iter: 12600, Loss: 1.571, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:23:31,294: INFO: Epoch: 60, Iter: 12650, Loss: 0.704, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 14:24:38,345: INFO: Epoch: 60, Iter: 12700, Loss: 1.327, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:25:45,721: INFO: Epoch: 60, Iter: 12750, Loss: 1.773, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:26:52,878: INFO: Epoch: 60, Iter: 12800, Loss: 0.619, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 14:28:00,992: INFO: Epoch: 61, Iter: 12850, Loss: 1.396, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:29:08,217: INFO: Epoch: 61, Iter: 12900, Loss: 1.382, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:30:15,522: INFO: Epoch: 61, Iter: 12950, Loss: 1.391, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:31:22,685: INFO: Epoch: 61, Iter: 13000, Loss: 0.720, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 14:32:29,809: INFO: Epoch: 62, Iter: 13050, Loss: 1.564, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:33:37,165: INFO: Epoch: 62, Iter: 13100, Loss: 1.190, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:34:44,403: INFO: Epoch: 62, Iter: 13150, Loss: 1.227, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:35:51,756: INFO: Epoch: 62, Iter: 13200, Loss: 0.685, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 14:36:59,132: INFO: Epoch: 63, Iter: 13250, Loss: 1.356, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:38:06,666: INFO: Epoch: 63, Iter: 13300, Loss: 1.043, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:39:13,738: INFO: Epoch: 63, Iter: 13350, Loss: 1.484, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:40:20,888: INFO: Epoch: 63, Iter: 13400, Loss: 1.033, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:41:27,952: INFO: Epoch: 64, Iter: 13450, Loss: 1.192, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:42:35,141: INFO: Epoch: 64, Iter: 13500, Loss: 0.987, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 14:43:42,441: INFO: Epoch: 64, Iter: 13550, Loss: 0.903, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 14:44:49,961: INFO: Epoch: 64, Iter: 13600, Loss: 0.791, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 14:45:56,925: INFO: Epoch: 65, Iter: 13650, Loss: 0.737, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 14:47:04,334: INFO: Epoch: 65, Iter: 13700, Loss: 0.689, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 14:48:12,103: INFO: Epoch: 65, Iter: 13750, Loss: 1.845, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:49:19,390: INFO: Epoch: 65, Iter: 13800, Loss: 1.213, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:50:26,702: INFO: Epoch: 65, Iter: 13850, Loss: 1.551, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:51:33,824: INFO: Epoch: 66, Iter: 13900, Loss: 1.324, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:52:41,112: INFO: Epoch: 66, Iter: 13950, Loss: 1.181, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:53:48,189: INFO: Epoch: 66, Iter: 14000, Loss: 1.011, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:54:55,448: INFO: Epoch: 66, Iter: 14050, Loss: 0.850, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 14:56:02,773: INFO: Epoch: 67, Iter: 14100, Loss: 1.082, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:57:10,181: INFO: Epoch: 67, Iter: 14150, Loss: 0.840, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 14:58:18,013: INFO: Epoch: 67, Iter: 14200, Loss: 1.308, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 14:59:25,391: INFO: Epoch: 67, Iter: 14250, Loss: 0.860, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 15:00:32,718: INFO: Epoch: 68, Iter: 14300, Loss: 1.161, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:01:39,828: INFO: Epoch: 68, Iter: 14350, Loss: 0.728, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 15:02:46,974: INFO: Epoch: 68, Iter: 14400, Loss: 0.676, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 15:03:53,735: INFO: Epoch: 68, Iter: 14450, Loss: 0.626, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 15:05:00,844: INFO: Epoch: 69, Iter: 14500, Loss: 1.356, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:06:07,769: INFO: Epoch: 69, Iter: 14550, Loss: 1.860, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:07:15,176: INFO: Epoch: 69, Iter: 14600, Loss: 1.237, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:08:22,661: INFO: Epoch: 69, Iter: 14650, Loss: 1.067, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:09:30,024: INFO: Epoch: 70, Iter: 14700, Loss: 0.773, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 15:10:37,119: INFO: Epoch: 70, Iter: 14750, Loss: 1.192, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:11:44,443: INFO: Epoch: 70, Iter: 14800, Loss: 1.233, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:12:52,009: INFO: Epoch: 70, Iter: 14850, Loss: 0.596, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 15:13:59,235: INFO: Epoch: 70, Iter: 14900, Loss: 1.161, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:15:06,375: INFO: Epoch: 71, Iter: 14950, Loss: 1.913, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:16:13,627: INFO: Epoch: 71, Iter: 15000, Loss: 0.598, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 15:17:20,957: INFO: Epoch: 71, Iter: 15050, Loss: 0.588, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 15:18:28,060: INFO: Epoch: 71, Iter: 15100, Loss: 1.352, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:19:35,441: INFO: Epoch: 72, Iter: 15150, Loss: 1.396, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:20:42,016: INFO: Epoch: 72, Iter: 15200, Loss: 1.525, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:21:48,998: INFO: Epoch: 72, Iter: 15250, Loss: 1.268, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:22:56,084: INFO: Epoch: 72, Iter: 15300, Loss: 0.978, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 15:24:03,259: INFO: Epoch: 73, Iter: 15350, Loss: 0.969, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 15:25:10,375: INFO: Epoch: 73, Iter: 15400, Loss: 0.904, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 15:26:17,565: INFO: Epoch: 73, Iter: 15450, Loss: 0.843, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 15:27:25,515: INFO: Epoch: 73, Iter: 15500, Loss: 1.258, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:28:33,176: INFO: Epoch: 74, Iter: 15550, Loss: 0.825, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 15:29:40,228: INFO: Epoch: 74, Iter: 15600, Loss: 1.273, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:30:47,385: INFO: Epoch: 74, Iter: 15650, Loss: 1.174, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:31:54,652: INFO: Epoch: 74, Iter: 15700, Loss: 0.900, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 15:33:01,865: INFO: Epoch: 75, Iter: 15750, Loss: 0.865, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 15:34:08,942: INFO: Epoch: 75, Iter: 15800, Loss: 1.142, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:35:16,205: INFO: Epoch: 75, Iter: 15850, Loss: 0.930, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 15:36:23,253: INFO: Epoch: 75, Iter: 15900, Loss: 1.436, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:37:30,555: INFO: Epoch: 75, Iter: 15950, Loss: 1.298, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:38:39,192: INFO: Epoch: 76, Iter: 16000, Loss: 1.241, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:39:46,515: INFO: Epoch: 76, Iter: 16050, Loss: 1.331, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:40:53,788: INFO: Epoch: 76, Iter: 16100, Loss: 1.692, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:42:01,170: INFO: Epoch: 76, Iter: 16150, Loss: 0.647, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 15:43:08,908: INFO: Epoch: 77, Iter: 16200, Loss: 2.367, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:44:16,180: INFO: Epoch: 77, Iter: 16250, Loss: 1.594, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:45:23,604: INFO: Epoch: 77, Iter: 16300, Loss: 0.744, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 15:46:30,659: INFO: Epoch: 77, Iter: 16350, Loss: 1.474, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:47:37,995: INFO: Epoch: 78, Iter: 16400, Loss: 0.516, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 15:48:45,519: INFO: Epoch: 78, Iter: 16450, Loss: 0.452, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 15:49:52,773: INFO: Epoch: 78, Iter: 16500, Loss: 0.427, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 15:50:59,952: INFO: Epoch: 78, Iter: 16550, Loss: 1.779, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:52:06,596: INFO: Epoch: 79, Iter: 16600, Loss: 1.556, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:53:14,631: INFO: Epoch: 79, Iter: 16650, Loss: 1.321, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:54:21,896: INFO: Epoch: 79, Iter: 16700, Loss: 1.281, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:55:28,642: INFO: Epoch: 79, Iter: 16750, Loss: 1.067, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:56:35,856: INFO: Epoch: 80, Iter: 16800, Loss: 1.252, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:57:43,541: INFO: Epoch: 80, Iter: 16850, Loss: 1.177, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:58:51,006: INFO: Epoch: 80, Iter: 16900, Loss: 1.338, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 15:59:58,402: INFO: Epoch: 80, Iter: 16950, Loss: 0.861, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:01:05,745: INFO: Epoch: 80, Iter: 17000, Loss: 0.666, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:02:12,925: INFO: Epoch: 81, Iter: 17050, Loss: 1.324, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 16:03:21,855: INFO: Epoch: 81, Iter: 17100, Loss: 1.331, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 16:04:29,006: INFO: Epoch: 81, Iter: 17150, Loss: 0.691, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:05:36,031: INFO: Epoch: 81, Iter: 17200, Loss: 1.218, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 16:06:43,324: INFO: Epoch: 82, Iter: 17250, Loss: 0.971, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:07:50,837: INFO: Epoch: 82, Iter: 17300, Loss: 0.896, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:08:57,897: INFO: Epoch: 82, Iter: 17350, Loss: 0.796, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:10:05,345: INFO: Epoch: 82, Iter: 17400, Loss: 1.754, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 16:11:12,746: INFO: Epoch: 83, Iter: 17450, Loss: 0.677, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:12:20,181: INFO: Epoch: 83, Iter: 17500, Loss: 0.634, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:13:27,648: INFO: Epoch: 83, Iter: 17550, Loss: 1.217, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 16:14:35,023: INFO: Epoch: 83, Iter: 17600, Loss: 0.764, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:15:42,312: INFO: Epoch: 84, Iter: 17650, Loss: 0.850, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:16:49,754: INFO: Epoch: 84, Iter: 17700, Loss: 0.842, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:17:57,316: INFO: Epoch: 84, Iter: 17750, Loss: 1.617, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 16:19:04,832: INFO: Epoch: 84, Iter: 17800, Loss: 0.677, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:20:12,469: INFO: Epoch: 85, Iter: 17850, Loss: 1.146, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 16:21:19,734: INFO: Epoch: 85, Iter: 17900, Loss: 1.047, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 16:22:27,236: INFO: Epoch: 85, Iter: 17950, Loss: 1.006, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 16:23:35,174: INFO: Epoch: 85, Iter: 18000, Loss: 0.992, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:24:42,312: INFO: Epoch: 85, Iter: 18050, Loss: 0.995, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:25:49,757: INFO: Epoch: 86, Iter: 18100, Loss: 1.302, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 16:26:56,945: INFO: Epoch: 86, Iter: 18150, Loss: 0.681, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:28:04,483: INFO: Epoch: 86, Iter: 18200, Loss: 0.616, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:29:11,769: INFO: Epoch: 86, Iter: 18250, Loss: 1.582, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 16:30:18,979: INFO: Epoch: 87, Iter: 18300, Loss: 1.627, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 16:31:26,082: INFO: Epoch: 87, Iter: 18350, Loss: 1.513, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 16:32:33,428: INFO: Epoch: 87, Iter: 18400, Loss: 1.250, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 16:33:40,842: INFO: Epoch: 87, Iter: 18450, Loss: 1.689, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 16:34:48,432: INFO: Epoch: 88, Iter: 18500, Loss: 0.600, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:35:55,968: INFO: Epoch: 88, Iter: 18550, Loss: 0.540, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:37:03,436: INFO: Epoch: 88, Iter: 18600, Loss: 1.589, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 16:38:10,853: INFO: Epoch: 88, Iter: 18650, Loss: 1.463, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 16:39:17,965: INFO: Epoch: 89, Iter: 18700, Loss: 1.094, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 16:40:25,411: INFO: Epoch: 89, Iter: 18750, Loss: 1.332, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 16:41:32,258: INFO: Epoch: 89, Iter: 18800, Loss: 1.025, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:42:39,674: INFO: Epoch: 89, Iter: 18850, Loss: 1.027, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:43:47,119: INFO: Epoch: 90, Iter: 18900, Loss: 0.923, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:44:54,296: INFO: Epoch: 90, Iter: 18950, Loss: 1.007, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 16:46:00,845: INFO: Epoch: 90, Iter: 19000, Loss: 0.773, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:47:08,345: INFO: Epoch: 90, Iter: 19050, Loss: 1.292, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 16:48:15,888: INFO: Epoch: 90, Iter: 19100, Loss: 1.332, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 16:49:23,025: INFO: Epoch: 91, Iter: 19150, Loss: 0.697, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:50:30,734: INFO: Epoch: 91, Iter: 19200, Loss: 0.676, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:51:38,374: INFO: Epoch: 91, Iter: 19250, Loss: 1.187, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 16:52:45,327: INFO: Epoch: 91, Iter: 19300, Loss: 0.719, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:53:52,549: INFO: Epoch: 92, Iter: 19350, Loss: 1.478, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 16:54:59,754: INFO: Epoch: 92, Iter: 19400, Loss: 1.335, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 16:56:07,271: INFO: Epoch: 92, Iter: 19450, Loss: 0.704, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:57:14,724: INFO: Epoch: 92, Iter: 19500, Loss: 0.692, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:58:22,058: INFO: Epoch: 93, Iter: 19550, Loss: 0.712, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 16:59:28,860: INFO: Epoch: 93, Iter: 19600, Loss: 0.748, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 17:00:36,169: INFO: Epoch: 93, Iter: 19650, Loss: 1.643, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:01:43,590: INFO: Epoch: 93, Iter: 19700, Loss: 0.803, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 17:02:51,027: INFO: Epoch: 94, Iter: 19750, Loss: 0.741, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 17:03:58,183: INFO: Epoch: 94, Iter: 19800, Loss: 0.701, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 17:05:05,121: INFO: Epoch: 94, Iter: 19850, Loss: 0.681, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 17:06:12,181: INFO: Epoch: 94, Iter: 19900, Loss: 1.381, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:07:19,505: INFO: Epoch: 95, Iter: 19950, Loss: 1.269, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:08:26,843: INFO: Epoch: 95, Iter: 20000, Loss: 1.173, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:09:34,151: INFO: Epoch: 95, Iter: 20050, Loss: 1.129, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:10:41,078: INFO: Epoch: 95, Iter: 20100, Loss: 0.880, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 17:11:48,353: INFO: Epoch: 95, Iter: 20150, Loss: 1.099, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:12:55,620: INFO: Epoch: 96, Iter: 20200, Loss: 1.578, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:14:02,625: INFO: Epoch: 96, Iter: 20250, Loss: 1.531, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:15:09,606: INFO: Epoch: 96, Iter: 20300, Loss: 1.328, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:16:16,707: INFO: Epoch: 96, Iter: 20350, Loss: 1.185, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:17:24,029: INFO: Epoch: 97, Iter: 20400, Loss: 1.147, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:18:31,420: INFO: Epoch: 97, Iter: 20450, Loss: 1.191, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:19:38,456: INFO: Epoch: 97, Iter: 20500, Loss: 1.199, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:20:45,758: INFO: Epoch: 97, Iter: 20550, Loss: 1.453, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:21:53,137: INFO: Epoch: 98, Iter: 20600, Loss: 0.756, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 17:23:00,792: INFO: Epoch: 98, Iter: 20650, Loss: 1.346, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:24:07,875: INFO: Epoch: 98, Iter: 20700, Loss: 1.276, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:25:14,990: INFO: Epoch: 98, Iter: 20750, Loss: 0.754, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 17:26:22,137: INFO: Epoch: 99, Iter: 20800, Loss: 0.570, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 17:27:29,709: INFO: Epoch: 99, Iter: 20850, Loss: 1.384, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:28:37,051: INFO: Epoch: 99, Iter: 20900, Loss: 0.691, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 17:29:44,463: INFO: Epoch: 99, Iter: 20950, Loss: 1.501, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:30:51,839: INFO: Epoch: 100, Iter: 21000, Loss: 0.820, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 17:31:59,056: INFO: Epoch: 100, Iter: 21050, Loss: 1.305, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:33:06,774: INFO: Epoch: 100, Iter: 21100, Loss: 1.321, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:34:13,894: INFO: Epoch: 100, Iter: 21150, Loss: 1.319, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:35:21,107: INFO: Epoch: 100, Iter: 21200, Loss: 1.178, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:36:28,181: INFO: Epoch: 101, Iter: 21250, Loss: 1.023, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:37:35,830: INFO: Epoch: 101, Iter: 21300, Loss: 0.930, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 17:38:43,411: INFO: Epoch: 101, Iter: 21350, Loss: 1.094, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:39:50,654: INFO: Epoch: 101, Iter: 21400, Loss: 1.370, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:40:57,799: INFO: Epoch: 102, Iter: 21450, Loss: 1.339, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:42:04,758: INFO: Epoch: 102, Iter: 21500, Loss: 1.346, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:43:12,161: INFO: Epoch: 102, Iter: 21550, Loss: 0.928, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 17:44:19,746: INFO: Epoch: 102, Iter: 21600, Loss: 1.488, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:45:26,744: INFO: Epoch: 103, Iter: 21650, Loss: 0.719, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 17:46:33,524: INFO: Epoch: 103, Iter: 21700, Loss: 0.724, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 17:47:41,654: INFO: Epoch: 103, Iter: 21750, Loss: 1.284, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:48:49,335: INFO: Epoch: 103, Iter: 21800, Loss: 0.816, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 17:49:56,613: INFO: Epoch: 104, Iter: 21850, Loss: 0.727, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 17:51:04,687: INFO: Epoch: 104, Iter: 21900, Loss: 0.640, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 17:52:11,988: INFO: Epoch: 104, Iter: 21950, Loss: 0.593, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 17:53:19,228: INFO: Epoch: 104, Iter: 22000, Loss: 0.555, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 17:54:26,733: INFO: Epoch: 105, Iter: 22050, Loss: 1.585, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:55:34,359: INFO: Epoch: 105, Iter: 22100, Loss: 1.564, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 17:56:41,839: INFO: Epoch: 105, Iter: 22150, Loss: 0.807, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 17:57:49,402: INFO: Epoch: 105, Iter: 22200, Loss: 0.920, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 17:58:56,869: INFO: Epoch: 105, Iter: 22250, Loss: 0.894, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 18:00:03,874: INFO: Epoch: 106, Iter: 22300, Loss: 1.237, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:01:11,321: INFO: Epoch: 106, Iter: 22350, Loss: 1.299, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:02:18,499: INFO: Epoch: 106, Iter: 22400, Loss: 0.907, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 18:03:26,050: INFO: Epoch: 106, Iter: 22450, Loss: 0.755, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 18:04:32,974: INFO: Epoch: 107, Iter: 22500, Loss: 0.667, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 18:05:40,515: INFO: Epoch: 107, Iter: 22550, Loss: 1.273, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:06:48,080: INFO: Epoch: 107, Iter: 22600, Loss: 0.714, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 18:07:55,326: INFO: Epoch: 107, Iter: 22650, Loss: 0.680, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 18:09:02,430: INFO: Epoch: 108, Iter: 22700, Loss: 0.612, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 18:10:09,422: INFO: Epoch: 108, Iter: 22750, Loss: 0.608, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 18:11:16,876: INFO: Epoch: 108, Iter: 22800, Loss: 1.528, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:12:24,164: INFO: Epoch: 108, Iter: 22850, Loss: 0.728, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 18:13:32,040: INFO: Epoch: 109, Iter: 22900, Loss: 0.691, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 18:14:39,194: INFO: Epoch: 109, Iter: 22950, Loss: 1.200, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:15:45,936: INFO: Epoch: 109, Iter: 23000, Loss: 1.278, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:16:53,002: INFO: Epoch: 109, Iter: 23050, Loss: 1.643, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:18:00,558: INFO: Epoch: 110, Iter: 23100, Loss: 1.245, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:19:07,615: INFO: Epoch: 110, Iter: 23150, Loss: 1.163, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:20:14,918: INFO: Epoch: 110, Iter: 23200, Loss: 1.011, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:21:22,190: INFO: Epoch: 110, Iter: 23250, Loss: 0.952, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:22:29,636: INFO: Epoch: 110, Iter: 23300, Loss: 0.993, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:23:37,415: INFO: Epoch: 111, Iter: 23350, Loss: 1.542, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:24:44,292: INFO: Epoch: 111, Iter: 23400, Loss: 1.279, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:25:51,609: INFO: Epoch: 111, Iter: 23450, Loss: 1.072, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:26:59,521: INFO: Epoch: 111, Iter: 23500, Loss: 0.831, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 18:28:06,866: INFO: Epoch: 112, Iter: 23550, Loss: 0.685, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 18:29:14,339: INFO: Epoch: 112, Iter: 23600, Loss: 1.747, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:30:21,840: INFO: Epoch: 112, Iter: 23650, Loss: 0.594, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 18:31:29,158: INFO: Epoch: 112, Iter: 23700, Loss: 1.561, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:32:36,243: INFO: Epoch: 113, Iter: 23750, Loss: 1.587, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:33:43,295: INFO: Epoch: 113, Iter: 23800, Loss: 1.266, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:34:50,514: INFO: Epoch: 113, Iter: 23850, Loss: 1.669, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:35:57,635: INFO: Epoch: 113, Iter: 23900, Loss: 0.811, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 18:37:05,371: INFO: Epoch: 114, Iter: 23950, Loss: 0.771, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 18:38:12,989: INFO: Epoch: 114, Iter: 24000, Loss: 1.468, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:39:20,241: INFO: Epoch: 114, Iter: 24050, Loss: 1.565, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:40:27,330: INFO: Epoch: 114, Iter: 24100, Loss: 1.309, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:41:34,611: INFO: Epoch: 115, Iter: 24150, Loss: 1.416, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:42:41,510: INFO: Epoch: 115, Iter: 24200, Loss: 1.353, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:43:49,214: INFO: Epoch: 115, Iter: 24250, Loss: 0.829, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 18:44:56,425: INFO: Epoch: 115, Iter: 24300, Loss: 0.826, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 18:46:03,643: INFO: Epoch: 115, Iter: 24350, Loss: 1.474, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:47:11,109: INFO: Epoch: 116, Iter: 24400, Loss: 1.459, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:48:18,811: INFO: Epoch: 116, Iter: 24450, Loss: 1.278, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:49:26,243: INFO: Epoch: 116, Iter: 24500, Loss: 1.199, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:50:33,572: INFO: Epoch: 116, Iter: 24550, Loss: 1.417, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:51:41,033: INFO: Epoch: 117, Iter: 24600, Loss: 0.800, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 18:52:48,116: INFO: Epoch: 117, Iter: 24650, Loss: 1.181, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:53:55,393: INFO: Epoch: 117, Iter: 24700, Loss: 0.926, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 18:55:02,569: INFO: Epoch: 117, Iter: 24750, Loss: 1.048, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:56:09,800: INFO: Epoch: 118, Iter: 24800, Loss: 1.226, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:57:17,570: INFO: Epoch: 118, Iter: 24850, Loss: 0.904, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 18:58:24,976: INFO: Epoch: 118, Iter: 24900, Loss: 1.246, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 18:59:32,127: INFO: Epoch: 118, Iter: 24950, Loss: 0.709, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 19:00:39,510: INFO: Epoch: 119, Iter: 25000, Loss: 0.663, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 19:01:46,616: INFO: Epoch: 119, Iter: 25050, Loss: 1.347, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:02:54,357: INFO: Epoch: 119, Iter: 25100, Loss: 1.766, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:04:01,569: INFO: Epoch: 119, Iter: 25150, Loss: 1.655, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:05:09,023: INFO: Epoch: 120, Iter: 25200, Loss: 0.643, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 19:06:16,219: INFO: Epoch: 120, Iter: 25250, Loss: 1.241, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:07:23,852: INFO: Epoch: 120, Iter: 25300, Loss: 1.775, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:08:31,104: INFO: Epoch: 120, Iter: 25350, Loss: 1.139, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:09:38,295: INFO: Epoch: 120, Iter: 25400, Loss: 0.818, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 19:10:45,428: INFO: Epoch: 121, Iter: 25450, Loss: 0.890, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 19:11:52,981: INFO: Epoch: 121, Iter: 25500, Loss: 1.717, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:13:00,476: INFO: Epoch: 121, Iter: 25550, Loss: 0.801, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 19:14:08,615: INFO: Epoch: 121, Iter: 25600, Loss: 0.714, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 19:15:18,928: INFO: Epoch: 122, Iter: 25650, Loss: 0.659, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 19:16:31,080: INFO: Epoch: 122, Iter: 25700, Loss: 0.693, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 19:17:43,924: INFO: Epoch: 122, Iter: 25750, Loss: 0.714, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 19:18:57,556: INFO: Epoch: 122, Iter: 25800, Loss: 0.759, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 19:20:04,682: INFO: Epoch: 123, Iter: 25850, Loss: 0.744, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 19:21:11,447: INFO: Epoch: 123, Iter: 25900, Loss: 1.368, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:22:18,138: INFO: Epoch: 123, Iter: 25950, Loss: 1.580, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:23:25,900: INFO: Epoch: 123, Iter: 26000, Loss: 1.420, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:24:32,320: INFO: Epoch: 124, Iter: 26050, Loss: 1.583, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:25:38,954: INFO: Epoch: 124, Iter: 26100, Loss: 0.832, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 19:26:45,892: INFO: Epoch: 124, Iter: 26150, Loss: 1.120, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:27:52,619: INFO: Epoch: 124, Iter: 26200, Loss: 0.826, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 19:28:59,874: INFO: Epoch: 125, Iter: 26250, Loss: 0.826, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 19:30:08,508: INFO: Epoch: 125, Iter: 26300, Loss: 1.234, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:31:24,867: INFO: Epoch: 125, Iter: 26350, Loss: 1.309, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:32:40,570: INFO: Epoch: 125, Iter: 26400, Loss: 1.095, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:33:47,193: INFO: Epoch: 125, Iter: 26450, Loss: 0.244, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 19:34:53,949: INFO: Epoch: 126, Iter: 26500, Loss: 1.029, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:36:00,487: INFO: Epoch: 126, Iter: 26550, Loss: 0.928, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 19:37:07,114: INFO: Epoch: 126, Iter: 26600, Loss: 0.877, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 19:38:13,890: INFO: Epoch: 126, Iter: 26650, Loss: 1.381, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:39:20,753: INFO: Epoch: 127, Iter: 26700, Loss: 0.878, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 19:40:27,224: INFO: Epoch: 127, Iter: 26750, Loss: 1.284, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:41:33,640: INFO: Epoch: 127, Iter: 26800, Loss: 1.334, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:42:40,026: INFO: Epoch: 127, Iter: 26850, Loss: 0.757, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 19:43:46,487: INFO: Epoch: 128, Iter: 26900, Loss: 0.611, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 19:44:52,980: INFO: Epoch: 128, Iter: 26950, Loss: 0.485, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 19:45:59,820: INFO: Epoch: 128, Iter: 27000, Loss: 1.416, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:47:05,857: INFO: Epoch: 128, Iter: 27050, Loss: 0.484, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 19:48:12,209: INFO: Epoch: 129, Iter: 27100, Loss: 2.126, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:49:18,425: INFO: Epoch: 129, Iter: 27150, Loss: 1.397, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:50:24,766: INFO: Epoch: 129, Iter: 27200, Loss: 1.190, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:51:31,186: INFO: Epoch: 129, Iter: 27250, Loss: 1.612, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:52:37,814: INFO: Epoch: 130, Iter: 27300, Loss: 1.212, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:53:45,016: INFO: Epoch: 130, Iter: 27350, Loss: 0.819, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 19:54:51,109: INFO: Epoch: 130, Iter: 27400, Loss: 1.304, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:55:57,799: INFO: Epoch: 130, Iter: 27450, Loss: 1.099, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:57:04,160: INFO: Epoch: 130, Iter: 27500, Loss: 1.195, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:58:10,886: INFO: Epoch: 131, Iter: 27550, Loss: 1.063, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 19:59:17,454: INFO: Epoch: 131, Iter: 27600, Loss: 0.969, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 20:00:24,431: INFO: Epoch: 131, Iter: 27650, Loss: 1.129, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 20:01:30,419: INFO: Epoch: 131, Iter: 27700, Loss: 0.710, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 20:02:36,522: INFO: Epoch: 132, Iter: 27750, Loss: 0.626, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 20:03:43,639: INFO: Epoch: 132, Iter: 27800, Loss: 1.699, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 20:04:50,154: INFO: Epoch: 132, Iter: 27850, Loss: 1.585, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 20:05:55,906: INFO: Epoch: 132, Iter: 27900, Loss: 0.687, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 20:07:01,999: INFO: Epoch: 133, Iter: 27950, Loss: 1.580, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 20:08:08,801: INFO: Epoch: 133, Iter: 28000, Loss: 1.359, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 20:09:15,086: INFO: Epoch: 133, Iter: 28050, Loss: 1.448, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 20:10:21,742: INFO: Epoch: 133, Iter: 28100, Loss: 0.706, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 20:11:28,291: INFO: Epoch: 134, Iter: 28150, Loss: 0.730, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 20:12:34,746: INFO: Epoch: 134, Iter: 28200, Loss: 1.537, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 20:13:41,317: INFO: Epoch: 134, Iter: 28250, Loss: 1.628, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 20:14:47,980: INFO: Epoch: 134, Iter: 28300, Loss: 0.784, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 20:15:54,645: INFO: Epoch: 135, Iter: 28350, Loss: 0.765, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 20:17:00,847: INFO: Epoch: 135, Iter: 28400, Loss: 1.166, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 20:18:07,537: INFO: Epoch: 135, Iter: 28450, Loss: 0.663, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 20:19:13,765: INFO: Epoch: 135, Iter: 28500, Loss: 1.794, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 20:20:20,245: INFO: Epoch: 135, Iter: 28550, Loss: 1.128, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 20:21:26,113: INFO: Epoch: 136, Iter: 28600, Loss: 0.772, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 20:22:32,752: INFO: Epoch: 136, Iter: 28650, Loss: 1.301, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 20:23:40,526: INFO: Epoch: 136, Iter: 28700, Loss: 1.367, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 20:24:46,955: INFO: Epoch: 136, Iter: 28750, Loss: 0.598, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 20:26:08,017: INFO: Epoch: 137, Iter: 28800, Loss: 0.588, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 20:27:15,545: INFO: Epoch: 137, Iter: 28850, Loss: 0.569, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 20:28:21,795: INFO: Epoch: 137, Iter: 28900, Loss: 0.604, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 20:29:28,109: INFO: Epoch: 137, Iter: 28950, Loss: 1.500, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 21:16:11,555: INFO: Epoch: 138, Iter: 29000, Loss: 1.330, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 21:17:18,883: INFO: Epoch: 138, Iter: 29050, Loss: 1.205, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 21:18:25,569: INFO: Epoch: 138, Iter: 29100, Loss: 1.010, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 21:19:32,012: INFO: Epoch: 138, Iter: 29150, Loss: 1.311, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 21:20:38,139: INFO: Epoch: 139, Iter: 29200, Loss: 1.080, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 21:21:43,821: INFO: Epoch: 139, Iter: 29250, Loss: 1.559, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 21:22:49,815: INFO: Epoch: 139, Iter: 29300, Loss: 1.482, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 21:23:56,080: INFO: Epoch: 139, Iter: 29350, Loss: 1.365, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 21:25:02,133: INFO: Epoch: 140, Iter: 29400, Loss: 1.312, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 21:26:07,962: INFO: Epoch: 140, Iter: 29450, Loss: 1.121, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 21:27:14,327: INFO: Epoch: 140, Iter: 29500, Loss: 0.997, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 21:28:20,257: INFO: Epoch: 140, Iter: 29550, Loss: 0.824, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 21:29:25,971: INFO: Epoch: 140, Iter: 29600, Loss: 0.649, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 21:30:31,488: INFO: Epoch: 141, Iter: 29650, Loss: 1.605, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 21:31:15,063: INFO: Epoch: 141, Iter: 29700, Loss: 0.627, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 21:32:20,976: INFO: Epoch: 141, Iter: 29750, Loss: 0.661, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 21:33:27,466: INFO: Epoch: 141, Iter: 29800, Loss: 0.944, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 21:34:33,773: INFO: Epoch: 142, Iter: 29850, Loss: 1.622, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 21:35:40,054: INFO: Epoch: 142, Iter: 29900, Loss: 1.535, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 21:36:46,111: INFO: Epoch: 142, Iter: 29950, Loss: 0.983, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 21:37:52,437: INFO: Epoch: 142, Iter: 30000, Loss: 0.893, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 21:38:58,075: INFO: Epoch: 143, Iter: 30050, Loss: 0.852, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 21:40:04,016: INFO: Epoch: 143, Iter: 30100, Loss: 0.746, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 21:41:09,696: INFO: Epoch: 143, Iter: 30150, Loss: 1.499, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 21:42:15,694: INFO: Epoch: 143, Iter: 30200, Loss: 1.512, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 21:43:22,894: INFO: Epoch: 144, Iter: 30250, Loss: 0.593, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 21:44:28,624: INFO: Epoch: 144, Iter: 30300, Loss: 0.675, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 21:45:34,732: INFO: Epoch: 144, Iter: 30350, Loss: 1.283, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 21:46:41,079: INFO: Epoch: 144, Iter: 30400, Loss: 0.691, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 21:47:46,997: INFO: Epoch: 145, Iter: 30450, Loss: 0.735, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 21:48:53,133: INFO: Epoch: 145, Iter: 30500, Loss: 0.745, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 21:49:58,984: INFO: Epoch: 145, Iter: 30550, Loss: 0.730, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 21:51:04,946: INFO: Epoch: 145, Iter: 30600, Loss: 1.431, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 21:52:11,003: INFO: Epoch: 145, Iter: 30650, Loss: 0.760, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 21:53:17,894: INFO: Epoch: 146, Iter: 30700, Loss: 0.789, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 21:54:23,705: INFO: Epoch: 146, Iter: 30750, Loss: 1.328, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 21:55:30,266: INFO: Epoch: 146, Iter: 30800, Loss: 1.146, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 21:56:41,443: INFO: Epoch: 146, Iter: 30850, Loss: 1.335, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 21:57:48,344: INFO: Epoch: 147, Iter: 30900, Loss: 0.925, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 21:58:54,810: INFO: Epoch: 147, Iter: 30950, Loss: 0.920, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 22:00:03,243: INFO: Epoch: 147, Iter: 31000, Loss: 0.944, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 22:01:18,839: INFO: Epoch: 147, Iter: 31050, Loss: 0.881, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 22:02:25,407: INFO: Epoch: 148, Iter: 31100, Loss: 1.229, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 22:03:31,944: INFO: Epoch: 148, Iter: 31150, Loss: 1.173, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 22:04:51,170: INFO: Epoch: 148, Iter: 31200, Loss: 1.435, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 22:06:10,570: INFO: Epoch: 148, Iter: 31250, Loss: 1.230, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 22:07:25,551: INFO: Epoch: 149, Iter: 31300, Loss: 1.344, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 22:08:38,751: INFO: Epoch: 149, Iter: 31350, Loss: 0.501, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 22:09:53,301: INFO: Epoch: 149, Iter: 31400, Loss: 0.445, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 22:11:07,543: INFO: Epoch: 149, Iter: 31450, Loss: 0.433, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 22:12:22,853: INFO: Epoch: 150, Iter: 31500, Loss: 1.407, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 22:13:37,484: INFO: Epoch: 150, Iter: 31550, Loss: 1.662, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 22:14:56,844: INFO: Epoch: 150, Iter: 31600, Loss: 1.598, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 22:16:16,243: INFO: Epoch: 150, Iter: 31650, Loss: 1.100, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 22:17:27,214: INFO: Epoch: 150, Iter: 31700, Loss: 0.840, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 22:18:39,949: INFO: Epoch: 151, Iter: 31750, Loss: 0.906, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 22:19:52,150: INFO: Epoch: 151, Iter: 31800, Loss: 0.893, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 22:20:58,945: INFO: Epoch: 151, Iter: 31850, Loss: 0.860, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 22:22:05,649: INFO: Epoch: 151, Iter: 31900, Loss: 0.787, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 22:23:12,650: INFO: Epoch: 152, Iter: 31950, Loss: 1.472, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 22:24:23,341: INFO: Epoch: 152, Iter: 32000, Loss: 1.298, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 22:25:45,855: INFO: Epoch: 152, Iter: 32050, Loss: 1.501, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 22:27:08,181: INFO: Epoch: 152, Iter: 32100, Loss: 0.716, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 22:28:32,401: INFO: Epoch: 153, Iter: 32150, Loss: 1.585, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 22:29:52,353: INFO: Epoch: 153, Iter: 32200, Loss: 1.298, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 22:31:15,487: INFO: Epoch: 153, Iter: 32250, Loss: 0.896, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 22:32:50,315: INFO: Epoch: 153, Iter: 32300, Loss: 0.743, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 22:34:19,244: INFO: Epoch: 154, Iter: 32350, Loss: 1.644, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 22:35:47,826: INFO: Epoch: 154, Iter: 32400, Loss: 1.418, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 22:37:15,499: INFO: Epoch: 154, Iter: 32450, Loss: 0.648, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 22:38:52,039: INFO: Epoch: 154, Iter: 32500, Loss: 1.322, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 22:40:31,157: INFO: Epoch: 155, Iter: 32550, Loss: 1.553, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 22:42:08,001: INFO: Epoch: 155, Iter: 32600, Loss: 0.694, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 22:43:45,987: INFO: Epoch: 155, Iter: 32650, Loss: 0.657, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 22:45:24,713: INFO: Epoch: 155, Iter: 32700, Loss: 1.381, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 22:47:03,770: INFO: Epoch: 155, Iter: 32750, Loss: 0.729, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 22:48:38,221: INFO: Epoch: 156, Iter: 32800, Loss: 0.791, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 22:50:12,452: INFO: Epoch: 156, Iter: 32850, Loss: 0.756, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 22:51:48,616: INFO: Epoch: 156, Iter: 32900, Loss: 1.191, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 22:53:24,861: INFO: Epoch: 156, Iter: 32950, Loss: 1.711, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 22:54:59,467: INFO: Epoch: 157, Iter: 33000, Loss: 0.781, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 22:56:34,779: INFO: Epoch: 157, Iter: 33050, Loss: 1.538, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 22:58:09,094: INFO: Epoch: 157, Iter: 33100, Loss: 0.808, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 22:59:44,722: INFO: Epoch: 157, Iter: 33150, Loss: 1.312, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 23:01:11,626: INFO: Epoch: 158, Iter: 33200, Loss: 1.268, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 23:02:34,617: INFO: Epoch: 158, Iter: 33250, Loss: 1.108, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 23:03:59,474: INFO: Epoch: 158, Iter: 33300, Loss: 0.957, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 23:05:40,538: INFO: Epoch: 158, Iter: 33350, Loss: 0.742, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 23:07:04,793: INFO: Epoch: 159, Iter: 33400, Loss: 1.356, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 23:08:33,898: INFO: Epoch: 159, Iter: 33450, Loss: 0.732, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 23:10:00,388: INFO: Epoch: 159, Iter: 33500, Loss: 1.364, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 23:11:15,054: INFO: Epoch: 159, Iter: 33550, Loss: 1.554, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 23:12:28,758: INFO: Epoch: 160, Iter: 33600, Loss: 1.451, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 23:13:43,324: INFO: Epoch: 160, Iter: 33650, Loss: 0.554, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 23:14:56,442: INFO: Epoch: 160, Iter: 33700, Loss: 1.598, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 23:16:10,091: INFO: Epoch: 160, Iter: 33750, Loss: 0.528, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 23:17:24,086: INFO: Epoch: 160, Iter: 33800, Loss: 0.670, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 23:18:41,664: INFO: Epoch: 161, Iter: 33850, Loss: 0.823, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 23:20:00,110: INFO: Epoch: 161, Iter: 33900, Loss: 0.816, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 23:21:21,269: INFO: Epoch: 161, Iter: 33950, Loss: 1.571, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 23:22:51,261: INFO: Epoch: 161, Iter: 34000, Loss: 0.692, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 23:24:05,338: INFO: Epoch: 162, Iter: 34050, Loss: 1.489, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 23:25:22,177: INFO: Epoch: 162, Iter: 34100, Loss: 0.719, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 23:26:39,295: INFO: Epoch: 162, Iter: 34150, Loss: 0.689, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 23:27:52,891: INFO: Epoch: 162, Iter: 34200, Loss: 0.656, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 23:29:09,408: INFO: Epoch: 163, Iter: 34250, Loss: 0.602, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 23:30:32,177: INFO: Epoch: 163, Iter: 34300, Loss: 1.521, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 23:31:53,959: INFO: Epoch: 163, Iter: 34350, Loss: 1.337, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 23:33:20,471: INFO: Epoch: 163, Iter: 34400, Loss: 0.738, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 23:34:49,071: INFO: Epoch: 164, Iter: 34450, Loss: 1.114, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 23:36:20,801: INFO: Epoch: 164, Iter: 34500, Loss: 0.902, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 23:37:41,355: INFO: Epoch: 164, Iter: 34550, Loss: 1.442, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 23:39:02,178: INFO: Epoch: 164, Iter: 34600, Loss: 1.373, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 23:40:23,635: INFO: Epoch: 165, Iter: 34650, Loss: 0.806, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 23:41:42,887: INFO: Epoch: 165, Iter: 34700, Loss: 0.842, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 23:43:03,628: INFO: Epoch: 165, Iter: 34750, Loss: 0.874, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 23:44:21,079: INFO: Epoch: 165, Iter: 34800, Loss: 0.800, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 23:45:45,431: INFO: Epoch: 165, Iter: 34850, Loss: 1.561, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 23:47:01,096: INFO: Epoch: 166, Iter: 34900, Loss: 1.297, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 23:48:13,572: INFO: Epoch: 166, Iter: 34950, Loss: 1.462, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 23:49:32,671: INFO: Epoch: 166, Iter: 35000, Loss: 1.156, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 23:50:44,667: INFO: Epoch: 166, Iter: 35050, Loss: 0.845, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 23:51:56,402: INFO: Epoch: 167, Iter: 35100, Loss: 1.134, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 23:53:07,890: INFO: Epoch: 167, Iter: 35150, Loss: 0.892, Accuracy: 1.000, Learning Rate: 0.050
2017-10-30 23:54:19,538: INFO: Epoch: 167, Iter: 35200, Loss: 1.079, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 23:55:30,709: INFO: Epoch: 167, Iter: 35250, Loss: 1.493, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 23:56:41,926: INFO: Epoch: 168, Iter: 35300, Loss: 1.151, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 23:57:56,797: INFO: Epoch: 168, Iter: 35350, Loss: 1.468, Accuracy: 0.000, Learning Rate: 0.050
2017-10-30 23:59:12,493: INFO: Epoch: 168, Iter: 35400, Loss: 0.801, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:00:29,529: INFO: Epoch: 168, Iter: 35450, Loss: 1.343, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 00:01:41,988: INFO: Epoch: 169, Iter: 35500, Loss: 1.694, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 00:02:53,042: INFO: Epoch: 169, Iter: 35550, Loss: 0.610, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:04:08,959: INFO: Epoch: 169, Iter: 35600, Loss: 0.609, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:05:19,782: INFO: Epoch: 169, Iter: 35650, Loss: 0.651, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:06:32,039: INFO: Epoch: 170, Iter: 35700, Loss: 0.707, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:07:48,936: INFO: Epoch: 170, Iter: 35750, Loss: 0.733, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:08:59,280: INFO: Epoch: 170, Iter: 35800, Loss: 1.422, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 00:10:09,478: INFO: Epoch: 170, Iter: 35850, Loss: 0.731, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:11:19,835: INFO: Epoch: 170, Iter: 35900, Loss: 0.853, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:12:30,832: INFO: Epoch: 171, Iter: 35950, Loss: 0.946, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:13:38,418: INFO: Epoch: 171, Iter: 36000, Loss: 0.849, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:14:46,022: INFO: Epoch: 171, Iter: 36050, Loss: 0.822, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:15:52,177: INFO: Epoch: 171, Iter: 36100, Loss: 1.401, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 00:16:58,635: INFO: Epoch: 172, Iter: 36150, Loss: 1.442, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 00:18:05,347: INFO: Epoch: 172, Iter: 36200, Loss: 0.788, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:19:11,485: INFO: Epoch: 172, Iter: 36250, Loss: 0.701, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:20:17,809: INFO: Epoch: 172, Iter: 36300, Loss: 0.567, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:21:24,338: INFO: Epoch: 173, Iter: 36350, Loss: 0.533, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:22:31,416: INFO: Epoch: 173, Iter: 36400, Loss: 1.698, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 00:23:38,300: INFO: Epoch: 173, Iter: 36450, Loss: 1.420, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 00:24:44,898: INFO: Epoch: 173, Iter: 36500, Loss: 1.233, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 00:25:51,790: INFO: Epoch: 174, Iter: 36550, Loss: 0.794, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:27:01,879: INFO: Epoch: 174, Iter: 36600, Loss: 0.883, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:28:12,426: INFO: Epoch: 174, Iter: 36650, Loss: 1.489, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 00:29:23,749: INFO: Epoch: 174, Iter: 36700, Loss: 1.056, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 00:30:38,722: INFO: Epoch: 175, Iter: 36750, Loss: 1.209, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 00:31:51,964: INFO: Epoch: 175, Iter: 36800, Loss: 0.703, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:33:02,995: INFO: Epoch: 175, Iter: 36850, Loss: 0.714, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:34:16,303: INFO: Epoch: 175, Iter: 36900, Loss: 0.776, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:35:33,844: INFO: Epoch: 175, Iter: 36950, Loss: 1.429, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 00:36:58,322: INFO: Epoch: 176, Iter: 37000, Loss: 0.861, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:38:29,266: INFO: Epoch: 176, Iter: 37050, Loss: 0.787, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:40:03,574: INFO: Epoch: 176, Iter: 37100, Loss: 0.780, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:41:38,333: INFO: Epoch: 176, Iter: 37150, Loss: 1.254, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 00:43:12,993: INFO: Epoch: 177, Iter: 37200, Loss: 0.785, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:44:33,447: INFO: Epoch: 177, Iter: 37250, Loss: 1.330, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 00:46:08,427: INFO: Epoch: 177, Iter: 37300, Loss: 0.668, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:47:45,022: INFO: Epoch: 177, Iter: 37350, Loss: 1.477, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 00:49:19,495: INFO: Epoch: 178, Iter: 37400, Loss: 1.292, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 00:50:53,093: INFO: Epoch: 178, Iter: 37450, Loss: 0.754, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:52:26,805: INFO: Epoch: 178, Iter: 37500, Loss: 0.688, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:54:01,806: INFO: Epoch: 178, Iter: 37550, Loss: 0.659, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:55:31,583: INFO: Epoch: 179, Iter: 37600, Loss: 1.524, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 00:57:05,183: INFO: Epoch: 179, Iter: 37650, Loss: 0.617, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 00:58:41,582: INFO: Epoch: 179, Iter: 37700, Loss: 1.399, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:00:16,162: INFO: Epoch: 179, Iter: 37750, Loss: 0.711, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 01:01:50,606: INFO: Epoch: 180, Iter: 37800, Loss: 1.521, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:03:23,916: INFO: Epoch: 180, Iter: 37850, Loss: 0.884, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 01:04:56,125: INFO: Epoch: 180, Iter: 37900, Loss: 1.028, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:06:28,654: INFO: Epoch: 180, Iter: 37950, Loss: 0.943, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 01:08:01,186: INFO: Epoch: 180, Iter: 38000, Loss: 1.008, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:09:33,717: INFO: Epoch: 181, Iter: 38050, Loss: 1.668, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:11:05,733: INFO: Epoch: 181, Iter: 38100, Loss: 0.940, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:12:37,062: INFO: Epoch: 181, Iter: 38150, Loss: 1.618, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:14:09,801: INFO: Epoch: 181, Iter: 38200, Loss: 1.563, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:15:42,476: INFO: Epoch: 182, Iter: 38250, Loss: 0.748, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 01:17:15,105: INFO: Epoch: 182, Iter: 38300, Loss: 1.511, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:18:47,115: INFO: Epoch: 182, Iter: 38350, Loss: 0.674, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 01:20:21,035: INFO: Epoch: 182, Iter: 38400, Loss: 1.476, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:21:54,643: INFO: Epoch: 183, Iter: 38450, Loss: 1.420, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:23:27,732: INFO: Epoch: 183, Iter: 38500, Loss: 1.463, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:24:49,355: INFO: Epoch: 183, Iter: 38550, Loss: 1.443, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:25:57,118: INFO: Epoch: 183, Iter: 38600, Loss: 0.744, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 01:27:04,486: INFO: Epoch: 184, Iter: 38650, Loss: 0.763, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 01:28:11,847: INFO: Epoch: 184, Iter: 38700, Loss: 1.337, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:29:18,820: INFO: Epoch: 184, Iter: 38750, Loss: 0.809, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 01:30:25,439: INFO: Epoch: 184, Iter: 38800, Loss: 1.339, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:31:32,370: INFO: Epoch: 185, Iter: 38850, Loss: 1.329, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:32:39,369: INFO: Epoch: 185, Iter: 38900, Loss: 0.713, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 01:33:46,781: INFO: Epoch: 185, Iter: 38950, Loss: 0.631, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 01:34:53,673: INFO: Epoch: 185, Iter: 39000, Loss: 1.514, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:36:00,445: INFO: Epoch: 185, Iter: 39050, Loss: 0.544, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 01:37:07,375: INFO: Epoch: 186, Iter: 39100, Loss: 0.638, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 01:38:14,000: INFO: Epoch: 186, Iter: 39150, Loss: 1.160, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:39:20,931: INFO: Epoch: 186, Iter: 39200, Loss: 0.577, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 01:40:28,048: INFO: Epoch: 186, Iter: 39250, Loss: 1.345, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:41:35,291: INFO: Epoch: 187, Iter: 39300, Loss: 2.036, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:42:41,946: INFO: Epoch: 187, Iter: 39350, Loss: 0.540, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 01:43:48,680: INFO: Epoch: 187, Iter: 39400, Loss: 0.685, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 01:44:55,981: INFO: Epoch: 187, Iter: 39450, Loss: 1.412, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:46:02,786: INFO: Epoch: 188, Iter: 39500, Loss: 1.207, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:47:09,697: INFO: Epoch: 188, Iter: 39550, Loss: 0.933, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 01:48:17,020: INFO: Epoch: 188, Iter: 39600, Loss: 0.999, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:49:23,766: INFO: Epoch: 188, Iter: 39650, Loss: 1.385, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:50:30,693: INFO: Epoch: 189, Iter: 39700, Loss: 0.930, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 01:51:37,514: INFO: Epoch: 189, Iter: 39750, Loss: 0.920, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 01:52:44,199: INFO: Epoch: 189, Iter: 39800, Loss: 1.393, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:53:51,235: INFO: Epoch: 189, Iter: 39850, Loss: 0.826, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 01:54:58,610: INFO: Epoch: 190, Iter: 39900, Loss: 1.048, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:56:05,295: INFO: Epoch: 190, Iter: 39950, Loss: 1.572, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:57:11,808: INFO: Epoch: 190, Iter: 40000, Loss: 0.881, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 01:58:18,683: INFO: Epoch: 190, Iter: 40050, Loss: 0.911, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 01:59:25,365: INFO: Epoch: 190, Iter: 40100, Loss: 0.746, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:00:31,755: INFO: Epoch: 191, Iter: 40150, Loss: 0.624, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:01:38,726: INFO: Epoch: 191, Iter: 40200, Loss: 0.549, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:02:45,416: INFO: Epoch: 191, Iter: 40250, Loss: 1.757, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:03:52,771: INFO: Epoch: 191, Iter: 40300, Loss: 1.468, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:04:59,953: INFO: Epoch: 192, Iter: 40350, Loss: 1.663, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:06:06,646: INFO: Epoch: 192, Iter: 40400, Loss: 1.455, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:07:13,437: INFO: Epoch: 192, Iter: 40450, Loss: 0.875, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:08:23,901: INFO: Epoch: 192, Iter: 40500, Loss: 0.870, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:09:31,969: INFO: Epoch: 193, Iter: 40550, Loss: 1.464, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:10:39,415: INFO: Epoch: 193, Iter: 40600, Loss: 0.712, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:11:46,665: INFO: Epoch: 193, Iter: 40650, Loss: 0.635, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:12:54,038: INFO: Epoch: 193, Iter: 40700, Loss: 1.620, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:14:00,916: INFO: Epoch: 194, Iter: 40750, Loss: 1.499, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:15:07,822: INFO: Epoch: 194, Iter: 40800, Loss: 0.999, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:16:14,452: INFO: Epoch: 194, Iter: 40850, Loss: 1.000, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:17:21,226: INFO: Epoch: 194, Iter: 40900, Loss: 0.988, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:18:27,937: INFO: Epoch: 195, Iter: 40950, Loss: 1.125, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:19:34,790: INFO: Epoch: 195, Iter: 41000, Loss: 1.216, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:20:42,078: INFO: Epoch: 195, Iter: 41050, Loss: 0.729, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:21:48,465: INFO: Epoch: 195, Iter: 41100, Loss: 1.466, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:22:55,444: INFO: Epoch: 195, Iter: 41150, Loss: 0.793, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:24:02,010: INFO: Epoch: 196, Iter: 41200, Loss: 1.245, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:25:09,395: INFO: Epoch: 196, Iter: 41250, Loss: 0.762, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:26:16,013: INFO: Epoch: 196, Iter: 41300, Loss: 0.809, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:27:22,910: INFO: Epoch: 196, Iter: 41350, Loss: 1.449, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:28:29,874: INFO: Epoch: 197, Iter: 41400, Loss: 0.798, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:29:36,730: INFO: Epoch: 197, Iter: 41450, Loss: 0.752, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:30:43,795: INFO: Epoch: 197, Iter: 41500, Loss: 0.714, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:31:50,807: INFO: Epoch: 197, Iter: 41550, Loss: 1.536, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:32:57,375: INFO: Epoch: 198, Iter: 41600, Loss: 1.425, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:34:03,818: INFO: Epoch: 198, Iter: 41650, Loss: 1.235, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:35:10,982: INFO: Epoch: 198, Iter: 41700, Loss: 1.325, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:36:17,915: INFO: Epoch: 198, Iter: 41750, Loss: 1.306, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:37:24,541: INFO: Epoch: 199, Iter: 41800, Loss: 0.722, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:38:32,160: INFO: Epoch: 199, Iter: 41850, Loss: 1.155, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:39:39,092: INFO: Epoch: 199, Iter: 41900, Loss: 0.754, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:40:45,664: INFO: Epoch: 199, Iter: 41950, Loss: 1.623, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:41:52,524: INFO: Epoch: 200, Iter: 42000, Loss: 0.611, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:43:00,013: INFO: Epoch: 200, Iter: 42050, Loss: 1.417, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:44:06,912: INFO: Epoch: 200, Iter: 42100, Loss: 0.597, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:45:14,170: INFO: Epoch: 200, Iter: 42150, Loss: 1.878, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:46:21,079: INFO: Epoch: 200, Iter: 42200, Loss: 0.764, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:47:27,926: INFO: Epoch: 201, Iter: 42250, Loss: 1.150, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:48:35,037: INFO: Epoch: 201, Iter: 42300, Loss: 1.535, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:49:42,424: INFO: Epoch: 201, Iter: 42350, Loss: 0.763, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:50:49,170: INFO: Epoch: 201, Iter: 42400, Loss: 0.730, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:51:55,681: INFO: Epoch: 202, Iter: 42450, Loss: 0.706, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:53:03,020: INFO: Epoch: 202, Iter: 42500, Loss: 1.211, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:54:09,808: INFO: Epoch: 202, Iter: 42550, Loss: 0.906, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:55:16,914: INFO: Epoch: 202, Iter: 42600, Loss: 1.052, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:56:23,491: INFO: Epoch: 203, Iter: 42650, Loss: 0.731, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:57:30,207: INFO: Epoch: 203, Iter: 42700, Loss: 1.399, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 02:58:37,286: INFO: Epoch: 203, Iter: 42750, Loss: 0.556, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 02:59:44,380: INFO: Epoch: 203, Iter: 42800, Loss: 1.664, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:00:51,393: INFO: Epoch: 204, Iter: 42850, Loss: 0.545, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:01:58,206: INFO: Epoch: 204, Iter: 42900, Loss: 0.676, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:03:05,036: INFO: Epoch: 204, Iter: 42950, Loss: 1.485, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:04:11,523: INFO: Epoch: 204, Iter: 43000, Loss: 1.186, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:05:18,433: INFO: Epoch: 205, Iter: 43050, Loss: 1.246, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:06:25,114: INFO: Epoch: 205, Iter: 43100, Loss: 0.929, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:07:31,671: INFO: Epoch: 205, Iter: 43150, Loss: 0.954, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:08:38,941: INFO: Epoch: 205, Iter: 43200, Loss: 1.122, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:09:45,740: INFO: Epoch: 205, Iter: 43250, Loss: 0.902, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:10:52,385: INFO: Epoch: 206, Iter: 43300, Loss: 0.900, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:11:59,086: INFO: Epoch: 206, Iter: 43350, Loss: 0.889, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:13:05,766: INFO: Epoch: 206, Iter: 43400, Loss: 1.132, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:14:12,762: INFO: Epoch: 206, Iter: 43450, Loss: 0.683, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:15:20,115: INFO: Epoch: 207, Iter: 43500, Loss: 1.388, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:16:26,817: INFO: Epoch: 207, Iter: 43550, Loss: 0.552, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:17:33,796: INFO: Epoch: 207, Iter: 43600, Loss: 0.514, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:18:40,626: INFO: Epoch: 207, Iter: 43650, Loss: 0.517, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:19:47,568: INFO: Epoch: 208, Iter: 43700, Loss: 0.564, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:20:54,116: INFO: Epoch: 208, Iter: 43750, Loss: 0.636, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:22:01,135: INFO: Epoch: 208, Iter: 43800, Loss: 1.470, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:23:08,650: INFO: Epoch: 208, Iter: 43850, Loss: 0.704, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:24:15,562: INFO: Epoch: 209, Iter: 43900, Loss: 0.679, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:25:22,813: INFO: Epoch: 209, Iter: 43950, Loss: 0.655, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:26:29,789: INFO: Epoch: 209, Iter: 44000, Loss: 1.329, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:27:36,282: INFO: Epoch: 209, Iter: 44050, Loss: 1.464, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:28:43,091: INFO: Epoch: 210, Iter: 44100, Loss: 1.016, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:29:50,094: INFO: Epoch: 210, Iter: 44150, Loss: 1.050, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:30:56,663: INFO: Epoch: 210, Iter: 44200, Loss: 0.857, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:32:03,475: INFO: Epoch: 210, Iter: 44250, Loss: 1.264, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:33:11,176: INFO: Epoch: 210, Iter: 44300, Loss: 1.557, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:34:17,957: INFO: Epoch: 211, Iter: 44350, Loss: 1.249, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:35:24,944: INFO: Epoch: 211, Iter: 44400, Loss: 1.492, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:36:31,876: INFO: Epoch: 211, Iter: 44450, Loss: 1.431, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:37:38,764: INFO: Epoch: 211, Iter: 44500, Loss: 1.078, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:38:45,841: INFO: Epoch: 212, Iter: 44550, Loss: 1.002, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:39:52,737: INFO: Epoch: 212, Iter: 44600, Loss: 0.947, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:40:59,236: INFO: Epoch: 212, Iter: 44650, Loss: 0.820, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:42:06,426: INFO: Epoch: 212, Iter: 44700, Loss: 1.458, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:43:13,789: INFO: Epoch: 213, Iter: 44750, Loss: 0.743, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:44:20,460: INFO: Epoch: 213, Iter: 44800, Loss: 0.675, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:45:27,167: INFO: Epoch: 213, Iter: 44850, Loss: 0.639, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:46:34,155: INFO: Epoch: 213, Iter: 44900, Loss: 0.616, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:47:40,591: INFO: Epoch: 214, Iter: 44950, Loss: 1.508, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:48:48,756: INFO: Epoch: 214, Iter: 45000, Loss: 1.370, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:49:56,292: INFO: Epoch: 214, Iter: 45050, Loss: 1.249, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:51:03,112: INFO: Epoch: 214, Iter: 45100, Loss: 0.937, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:52:09,972: INFO: Epoch: 215, Iter: 45150, Loss: 0.811, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:53:16,824: INFO: Epoch: 215, Iter: 45200, Loss: 1.233, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:54:23,611: INFO: Epoch: 215, Iter: 45250, Loss: 0.768, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:55:30,558: INFO: Epoch: 215, Iter: 45300, Loss: 0.740, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:56:37,083: INFO: Epoch: 215, Iter: 45350, Loss: 1.509, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:57:43,903: INFO: Epoch: 216, Iter: 45400, Loss: 1.239, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 03:58:51,762: INFO: Epoch: 216, Iter: 45450, Loss: 0.736, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 03:59:58,908: INFO: Epoch: 216, Iter: 45500, Loss: 1.445, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:01:05,933: INFO: Epoch: 216, Iter: 45550, Loss: 0.718, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 04:02:12,941: INFO: Epoch: 217, Iter: 45600, Loss: 1.670, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:03:20,429: INFO: Epoch: 217, Iter: 45650, Loss: 1.381, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:04:27,409: INFO: Epoch: 217, Iter: 45700, Loss: 1.410, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:05:34,238: INFO: Epoch: 217, Iter: 45750, Loss: 1.007, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:06:41,216: INFO: Epoch: 218, Iter: 45800, Loss: 0.965, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:07:48,207: INFO: Epoch: 218, Iter: 45850, Loss: 0.919, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 04:08:55,290: INFO: Epoch: 218, Iter: 45900, Loss: 0.889, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 04:10:02,591: INFO: Epoch: 218, Iter: 45950, Loss: 0.856, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 04:11:09,242: INFO: Epoch: 219, Iter: 46000, Loss: 0.934, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:12:16,381: INFO: Epoch: 219, Iter: 46050, Loss: 0.845, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 04:13:24,024: INFO: Epoch: 219, Iter: 46100, Loss: 0.934, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:14:31,316: INFO: Epoch: 219, Iter: 46150, Loss: 0.598, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 04:15:38,512: INFO: Epoch: 220, Iter: 46200, Loss: 2.189, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:16:45,066: INFO: Epoch: 220, Iter: 46250, Loss: 2.049, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:17:51,831: INFO: Epoch: 220, Iter: 46300, Loss: 0.583, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 04:18:59,559: INFO: Epoch: 220, Iter: 46350, Loss: 2.063, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:20:06,265: INFO: Epoch: 220, Iter: 46400, Loss: 0.813, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:21:12,971: INFO: Epoch: 221, Iter: 46450, Loss: 0.678, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 04:22:19,928: INFO: Epoch: 221, Iter: 46500, Loss: 1.117, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:23:26,984: INFO: Epoch: 221, Iter: 46550, Loss: 1.609, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:24:34,002: INFO: Epoch: 221, Iter: 46600, Loss: 0.617, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 04:25:41,223: INFO: Epoch: 222, Iter: 46650, Loss: 1.402, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:26:47,603: INFO: Epoch: 222, Iter: 46700, Loss: 0.646, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 04:27:54,397: INFO: Epoch: 222, Iter: 46750, Loss: 1.367, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:29:01,564: INFO: Epoch: 222, Iter: 46800, Loss: 1.650, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:30:08,348: INFO: Epoch: 223, Iter: 46850, Loss: 1.322, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:31:14,874: INFO: Epoch: 223, Iter: 46900, Loss: 1.631, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:32:21,351: INFO: Epoch: 223, Iter: 46950, Loss: 1.202, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:33:28,095: INFO: Epoch: 223, Iter: 47000, Loss: 1.804, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:34:35,184: INFO: Epoch: 224, Iter: 47050, Loss: 1.012, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:35:42,348: INFO: Epoch: 224, Iter: 47100, Loss: 0.817, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 04:36:48,681: INFO: Epoch: 224, Iter: 47150, Loss: 0.788, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 04:37:55,681: INFO: Epoch: 224, Iter: 47200, Loss: 0.732, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 04:39:02,471: INFO: Epoch: 225, Iter: 47250, Loss: 0.711, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 04:40:09,224: INFO: Epoch: 225, Iter: 47300, Loss: 0.671, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 04:41:15,700: INFO: Epoch: 225, Iter: 47350, Loss: 0.681, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 04:42:22,632: INFO: Epoch: 225, Iter: 47400, Loss: 0.634, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 04:43:29,626: INFO: Epoch: 225, Iter: 47450, Loss: 1.519, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:44:36,540: INFO: Epoch: 226, Iter: 47500, Loss: 1.168, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:45:43,654: INFO: Epoch: 226, Iter: 47550, Loss: 0.809, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 04:46:50,421: INFO: Epoch: 226, Iter: 47600, Loss: 0.800, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 04:47:57,525: INFO: Epoch: 226, Iter: 47650, Loss: 1.270, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:49:04,690: INFO: Epoch: 227, Iter: 47700, Loss: 1.461, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:50:10,839: INFO: Epoch: 227, Iter: 47750, Loss: 0.506, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 04:51:17,482: INFO: Epoch: 227, Iter: 47800, Loss: 0.520, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 04:52:24,037: INFO: Epoch: 227, Iter: 47850, Loss: 0.660, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 04:53:31,308: INFO: Epoch: 228, Iter: 47900, Loss: 1.101, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:54:38,041: INFO: Epoch: 228, Iter: 47950, Loss: 1.019, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:55:45,116: INFO: Epoch: 228, Iter: 48000, Loss: 0.944, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 04:56:52,166: INFO: Epoch: 228, Iter: 48050, Loss: 1.592, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:57:59,247: INFO: Epoch: 229, Iter: 48100, Loss: 1.584, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 04:59:06,279: INFO: Epoch: 229, Iter: 48150, Loss: 1.520, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:00:13,239: INFO: Epoch: 229, Iter: 48200, Loss: 1.275, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:01:19,716: INFO: Epoch: 229, Iter: 48250, Loss: 1.259, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:02:26,488: INFO: Epoch: 230, Iter: 48300, Loss: 1.299, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:03:33,278: INFO: Epoch: 230, Iter: 48350, Loss: 0.805, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 05:04:40,311: INFO: Epoch: 230, Iter: 48400, Loss: 1.331, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:05:46,773: INFO: Epoch: 230, Iter: 48450, Loss: 1.318, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:06:53,471: INFO: Epoch: 230, Iter: 48500, Loss: 1.163, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:08:00,589: INFO: Epoch: 231, Iter: 48550, Loss: 0.969, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:09:07,804: INFO: Epoch: 231, Iter: 48600, Loss: 0.908, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 05:10:14,614: INFO: Epoch: 231, Iter: 48650, Loss: 0.838, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 05:11:21,415: INFO: Epoch: 231, Iter: 48700, Loss: 1.281, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:12:27,874: INFO: Epoch: 232, Iter: 48750, Loss: 1.676, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:13:35,252: INFO: Epoch: 232, Iter: 48800, Loss: 1.691, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:14:43,647: INFO: Epoch: 232, Iter: 48850, Loss: 0.681, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 05:15:52,079: INFO: Epoch: 232, Iter: 48900, Loss: 1.668, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:17:00,152: INFO: Epoch: 233, Iter: 48950, Loss: 1.574, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:18:08,425: INFO: Epoch: 233, Iter: 49000, Loss: 1.501, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:19:16,679: INFO: Epoch: 233, Iter: 49050, Loss: 0.668, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 05:20:25,006: INFO: Epoch: 233, Iter: 49100, Loss: 0.700, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 05:21:34,421: INFO: Epoch: 234, Iter: 49150, Loss: 1.348, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:22:42,296: INFO: Epoch: 234, Iter: 49200, Loss: 0.789, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 05:23:50,782: INFO: Epoch: 234, Iter: 49250, Loss: 1.331, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:24:59,170: INFO: Epoch: 234, Iter: 49300, Loss: 0.957, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 05:26:07,607: INFO: Epoch: 235, Iter: 49350, Loss: 1.229, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:27:15,615: INFO: Epoch: 235, Iter: 49400, Loss: 1.295, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:28:24,216: INFO: Epoch: 235, Iter: 49450, Loss: 1.145, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:29:32,318: INFO: Epoch: 235, Iter: 49500, Loss: 0.845, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 05:30:40,245: INFO: Epoch: 235, Iter: 49550, Loss: 1.377, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:31:48,433: INFO: Epoch: 236, Iter: 49600, Loss: 0.896, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 05:32:56,313: INFO: Epoch: 236, Iter: 49650, Loss: 0.850, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 05:34:04,702: INFO: Epoch: 236, Iter: 49700, Loss: 0.788, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 05:35:12,795: INFO: Epoch: 236, Iter: 49750, Loss: 1.513, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:36:20,902: INFO: Epoch: 237, Iter: 49800, Loss: 1.504, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:37:29,073: INFO: Epoch: 237, Iter: 49850, Loss: 0.988, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:38:37,633: INFO: Epoch: 237, Iter: 49900, Loss: 0.902, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 05:39:46,050: INFO: Epoch: 237, Iter: 49950, Loss: 1.139, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:40:54,287: INFO: Epoch: 238, Iter: 50000, Loss: 1.387, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:42:02,905: INFO: Epoch: 238, Iter: 50050, Loss: 0.855, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 05:43:11,406: INFO: Epoch: 238, Iter: 50100, Loss: 1.505, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:44:19,455: INFO: Epoch: 238, Iter: 50150, Loss: 1.497, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:45:28,053: INFO: Epoch: 239, Iter: 50200, Loss: 0.663, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 05:46:36,418: INFO: Epoch: 239, Iter: 50250, Loss: 1.703, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:47:44,425: INFO: Epoch: 239, Iter: 50300, Loss: 0.484, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 05:48:53,013: INFO: Epoch: 239, Iter: 50350, Loss: 1.779, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:50:01,863: INFO: Epoch: 240, Iter: 50400, Loss: 0.564, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 05:51:10,287: INFO: Epoch: 240, Iter: 50450, Loss: 1.539, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:52:18,385: INFO: Epoch: 240, Iter: 50500, Loss: 1.276, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:53:26,532: INFO: Epoch: 240, Iter: 50550, Loss: 1.282, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:54:35,103: INFO: Epoch: 240, Iter: 50600, Loss: 0.906, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 05:55:43,606: INFO: Epoch: 241, Iter: 50650, Loss: 0.889, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 05:56:51,973: INFO: Epoch: 241, Iter: 50700, Loss: 1.332, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:58:00,423: INFO: Epoch: 241, Iter: 50750, Loss: 1.299, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 05:59:08,755: INFO: Epoch: 241, Iter: 50800, Loss: 1.212, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:00:17,111: INFO: Epoch: 242, Iter: 50850, Loss: 1.200, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:01:25,233: INFO: Epoch: 242, Iter: 50900, Loss: 1.213, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:02:33,167: INFO: Epoch: 242, Iter: 50950, Loss: 1.286, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:03:41,701: INFO: Epoch: 242, Iter: 51000, Loss: 0.680, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 06:04:49,780: INFO: Epoch: 243, Iter: 51050, Loss: 0.802, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 06:05:58,399: INFO: Epoch: 243, Iter: 51100, Loss: 1.304, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:07:06,320: INFO: Epoch: 243, Iter: 51150, Loss: 1.423, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:08:14,799: INFO: Epoch: 243, Iter: 51200, Loss: 1.390, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:09:23,148: INFO: Epoch: 244, Iter: 51250, Loss: 1.077, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:10:31,327: INFO: Epoch: 244, Iter: 51300, Loss: 1.099, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:11:39,686: INFO: Epoch: 244, Iter: 51350, Loss: 0.573, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 06:12:48,301: INFO: Epoch: 244, Iter: 51400, Loss: 0.762, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 06:13:56,316: INFO: Epoch: 245, Iter: 51450, Loss: 0.673, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 06:15:04,850: INFO: Epoch: 245, Iter: 51500, Loss: 1.658, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:16:13,245: INFO: Epoch: 245, Iter: 51550, Loss: 1.678, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:17:21,526: INFO: Epoch: 245, Iter: 51600, Loss: 0.593, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 06:18:29,791: INFO: Epoch: 245, Iter: 51650, Loss: 0.591, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 06:19:38,194: INFO: Epoch: 246, Iter: 51700, Loss: 1.267, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:20:46,574: INFO: Epoch: 246, Iter: 51750, Loss: 1.580, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:21:54,655: INFO: Epoch: 246, Iter: 51800, Loss: 0.802, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 06:23:02,973: INFO: Epoch: 246, Iter: 51850, Loss: 0.843, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 06:24:11,397: INFO: Epoch: 247, Iter: 51900, Loss: 0.787, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 06:25:20,089: INFO: Epoch: 247, Iter: 51950, Loss: 1.441, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:26:28,282: INFO: Epoch: 247, Iter: 52000, Loss: 1.494, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:27:37,863: INFO: Epoch: 247, Iter: 52050, Loss: 0.628, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 06:28:46,693: INFO: Epoch: 248, Iter: 52100, Loss: 1.319, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:29:57,035: INFO: Epoch: 248, Iter: 52150, Loss: 0.807, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 06:31:05,137: INFO: Epoch: 248, Iter: 52200, Loss: 0.909, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 06:32:13,486: INFO: Epoch: 248, Iter: 52250, Loss: 0.840, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 06:33:21,698: INFO: Epoch: 249, Iter: 52300, Loss: 1.316, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:34:29,595: INFO: Epoch: 249, Iter: 52350, Loss: 0.888, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 06:35:37,895: INFO: Epoch: 249, Iter: 52400, Loss: 4.121, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:36:46,030: INFO: Epoch: 249, Iter: 52450, Loss: 1.407, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:37:54,707: INFO: Epoch: 250, Iter: 52500, Loss: 1.147, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:39:02,704: INFO: Epoch: 250, Iter: 52550, Loss: 0.959, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 06:40:10,675: INFO: Epoch: 250, Iter: 52600, Loss: 1.404, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:41:18,565: INFO: Epoch: 250, Iter: 52650, Loss: 1.173, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:42:26,763: INFO: Epoch: 250, Iter: 52700, Loss: 1.046, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 06:43:35,233: INFO: Epoch: 251, Iter: 52750, Loss: 1.191, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:44:43,664: INFO: Epoch: 251, Iter: 52800, Loss: 1.524, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:45:52,257: INFO: Epoch: 251, Iter: 52850, Loss: 1.560, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:47:00,506: INFO: Epoch: 251, Iter: 52900, Loss: 0.718, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 06:48:08,868: INFO: Epoch: 252, Iter: 52950, Loss: 1.535, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:49:17,107: INFO: Epoch: 252, Iter: 53000, Loss: 0.695, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 06:50:25,121: INFO: Epoch: 252, Iter: 53050, Loss: 0.673, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 06:51:33,140: INFO: Epoch: 252, Iter: 53100, Loss: 1.682, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:52:41,608: INFO: Epoch: 253, Iter: 53150, Loss: 0.552, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 06:53:50,095: INFO: Epoch: 253, Iter: 53200, Loss: 0.634, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 06:54:58,550: INFO: Epoch: 253, Iter: 53250, Loss: 1.185, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:56:07,292: INFO: Epoch: 253, Iter: 53300, Loss: 0.774, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 06:57:15,592: INFO: Epoch: 254, Iter: 53350, Loss: 1.061, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:58:24,020: INFO: Epoch: 254, Iter: 53400, Loss: 1.723, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 06:59:31,974: INFO: Epoch: 254, Iter: 53450, Loss: 1.209, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:00:40,153: INFO: Epoch: 254, Iter: 53500, Loss: 1.545, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:01:48,986: INFO: Epoch: 255, Iter: 53550, Loss: 1.378, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:02:57,558: INFO: Epoch: 255, Iter: 53600, Loss: 0.752, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 07:04:05,844: INFO: Epoch: 255, Iter: 53650, Loss: 1.344, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:05:14,237: INFO: Epoch: 255, Iter: 53700, Loss: 0.923, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 07:06:22,582: INFO: Epoch: 255, Iter: 53750, Loss: 1.216, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:07:30,912: INFO: Epoch: 256, Iter: 53800, Loss: 0.717, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 07:08:39,311: INFO: Epoch: 256, Iter: 53850, Loss: 0.697, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 07:09:47,535: INFO: Epoch: 256, Iter: 53900, Loss: 1.480, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:10:56,225: INFO: Epoch: 256, Iter: 53950, Loss: 1.349, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:12:04,309: INFO: Epoch: 257, Iter: 54000, Loss: 1.295, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:13:12,879: INFO: Epoch: 257, Iter: 54050, Loss: 0.741, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 07:14:21,106: INFO: Epoch: 257, Iter: 54100, Loss: 1.227, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:15:29,705: INFO: Epoch: 257, Iter: 54150, Loss: 1.015, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:16:38,305: INFO: Epoch: 258, Iter: 54200, Loss: 1.074, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:17:46,475: INFO: Epoch: 258, Iter: 54250, Loss: 0.881, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 07:18:54,765: INFO: Epoch: 258, Iter: 54300, Loss: 0.806, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 07:20:02,910: INFO: Epoch: 258, Iter: 54350, Loss: 1.549, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:21:11,285: INFO: Epoch: 259, Iter: 54400, Loss: 0.727, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 07:22:19,514: INFO: Epoch: 259, Iter: 54450, Loss: 0.625, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 07:23:29,065: INFO: Epoch: 259, Iter: 54500, Loss: 0.617, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 07:24:37,234: INFO: Epoch: 259, Iter: 54550, Loss: 1.360, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:25:45,407: INFO: Epoch: 260, Iter: 54600, Loss: 1.245, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:26:53,536: INFO: Epoch: 260, Iter: 54650, Loss: 1.580, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:28:01,893: INFO: Epoch: 260, Iter: 54700, Loss: 0.811, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 07:29:10,153: INFO: Epoch: 260, Iter: 54750, Loss: 0.730, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 07:30:17,999: INFO: Epoch: 260, Iter: 54800, Loss: 0.640, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 07:31:26,412: INFO: Epoch: 261, Iter: 54850, Loss: 0.508, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 07:32:34,602: INFO: Epoch: 261, Iter: 54900, Loss: 1.613, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:33:42,995: INFO: Epoch: 261, Iter: 54950, Loss: 5.934, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:34:51,087: INFO: Epoch: 261, Iter: 55000, Loss: 1.465, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:35:59,452: INFO: Epoch: 262, Iter: 55050, Loss: 1.498, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:37:07,633: INFO: Epoch: 262, Iter: 55100, Loss: 1.416, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:38:15,867: INFO: Epoch: 262, Iter: 55150, Loss: 1.211, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:39:23,992: INFO: Epoch: 262, Iter: 55200, Loss: 1.376, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:40:32,428: INFO: Epoch: 263, Iter: 55250, Loss: 0.775, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 07:41:40,572: INFO: Epoch: 263, Iter: 55300, Loss: 0.760, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 07:42:49,746: INFO: Epoch: 263, Iter: 55350, Loss: 0.787, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 07:43:57,859: INFO: Epoch: 263, Iter: 55400, Loss: 0.755, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 07:45:05,730: INFO: Epoch: 264, Iter: 55450, Loss: 1.315, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:46:13,869: INFO: Epoch: 264, Iter: 55500, Loss: 1.394, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:47:21,877: INFO: Epoch: 264, Iter: 55550, Loss: 1.299, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:48:30,275: INFO: Epoch: 264, Iter: 55600, Loss: 1.642, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:49:38,426: INFO: Epoch: 265, Iter: 55650, Loss: 0.846, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 07:50:46,658: INFO: Epoch: 265, Iter: 55700, Loss: 1.174, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:51:54,653: INFO: Epoch: 265, Iter: 55750, Loss: 0.823, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 07:53:03,158: INFO: Epoch: 265, Iter: 55800, Loss: 0.463, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 07:54:11,855: INFO: Epoch: 265, Iter: 55850, Loss: 1.138, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:55:20,396: INFO: Epoch: 266, Iter: 55900, Loss: 0.646, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 07:56:28,545: INFO: Epoch: 266, Iter: 55950, Loss: 0.679, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 07:57:36,668: INFO: Epoch: 266, Iter: 56000, Loss: 1.341, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 07:58:45,172: INFO: Epoch: 266, Iter: 56050, Loss: 0.672, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 07:59:53,381: INFO: Epoch: 267, Iter: 56100, Loss: 0.000, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 08:01:01,711: INFO: Epoch: 267, Iter: 56150, Loss: 0.689, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 08:02:09,885: INFO: Epoch: 267, Iter: 56200, Loss: 0.010, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 08:03:18,403: INFO: Epoch: 267, Iter: 56250, Loss: 0.995, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:04:26,421: INFO: Epoch: 268, Iter: 56300, Loss: 1.421, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:05:34,930: INFO: Epoch: 268, Iter: 56350, Loss: 1.713, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:06:42,873: INFO: Epoch: 268, Iter: 56400, Loss: 1.223, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:07:51,076: INFO: Epoch: 268, Iter: 56450, Loss: 1.001, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 08:08:59,617: INFO: Epoch: 269, Iter: 56500, Loss: 1.252, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:10:07,924: INFO: Epoch: 269, Iter: 56550, Loss: 1.180, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:11:16,233: INFO: Epoch: 269, Iter: 56600, Loss: 1.008, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 08:12:24,669: INFO: Epoch: 269, Iter: 56650, Loss: 1.059, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:13:33,919: INFO: Epoch: 270, Iter: 56700, Loss: 1.164, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:14:42,455: INFO: Epoch: 270, Iter: 56750, Loss: 0.892, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:15:50,992: INFO: Epoch: 270, Iter: 56800, Loss: 1.204, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:16:59,436: INFO: Epoch: 270, Iter: 56850, Loss: 1.819, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:18:07,867: INFO: Epoch: 270, Iter: 56900, Loss: 1.143, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:19:16,001: INFO: Epoch: 271, Iter: 56950, Loss: 2.101, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:20:23,724: INFO: Epoch: 271, Iter: 57000, Loss: 1.111, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:21:32,863: INFO: Epoch: 271, Iter: 57050, Loss: 0.949, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 08:22:40,995: INFO: Epoch: 271, Iter: 57100, Loss: 1.090, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:23:49,495: INFO: Epoch: 272, Iter: 57150, Loss: 1.487, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:24:58,004: INFO: Epoch: 272, Iter: 57200, Loss: 0.866, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 08:26:06,446: INFO: Epoch: 272, Iter: 57250, Loss: 1.118, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:27:14,808: INFO: Epoch: 272, Iter: 57300, Loss: 0.817, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 08:28:22,953: INFO: Epoch: 273, Iter: 57350, Loss: 1.405, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:29:31,181: INFO: Epoch: 273, Iter: 57400, Loss: 0.538, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 08:30:39,625: INFO: Epoch: 273, Iter: 57450, Loss: 1.251, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:31:47,834: INFO: Epoch: 273, Iter: 57500, Loss: 1.550, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:32:56,071: INFO: Epoch: 274, Iter: 57550, Loss: 1.550, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:34:04,240: INFO: Epoch: 274, Iter: 57600, Loss: 1.593, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:35:12,492: INFO: Epoch: 274, Iter: 57650, Loss: 1.172, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:36:20,749: INFO: Epoch: 274, Iter: 57700, Loss: 1.137, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:37:29,286: INFO: Epoch: 275, Iter: 57750, Loss: 0.965, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 08:38:38,008: INFO: Epoch: 275, Iter: 57800, Loss: 0.965, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 08:39:46,434: INFO: Epoch: 275, Iter: 57850, Loss: 1.275, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:40:54,295: INFO: Epoch: 275, Iter: 57900, Loss: 1.655, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:42:02,293: INFO: Epoch: 275, Iter: 57950, Loss: 1.446, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:43:10,923: INFO: Epoch: 276, Iter: 58000, Loss: 0.873, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 08:44:18,825: INFO: Epoch: 276, Iter: 58050, Loss: 0.425, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 08:45:27,477: INFO: Epoch: 276, Iter: 58100, Loss: 1.137, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:46:35,945: INFO: Epoch: 276, Iter: 58150, Loss: 0.802, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 08:47:44,229: INFO: Epoch: 277, Iter: 58200, Loss: 0.500, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 08:48:52,388: INFO: Epoch: 277, Iter: 58250, Loss: 0.930, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 08:49:59,987: INFO: Epoch: 277, Iter: 58300, Loss: 1.159, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:51:06,501: INFO: Epoch: 277, Iter: 58350, Loss: 1.426, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:52:13,569: INFO: Epoch: 278, Iter: 58400, Loss: 0.787, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 08:53:20,434: INFO: Epoch: 278, Iter: 58450, Loss: 2.618, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:54:27,241: INFO: Epoch: 278, Iter: 58500, Loss: 0.792, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 08:55:33,805: INFO: Epoch: 278, Iter: 58550, Loss: 1.302, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:56:40,626: INFO: Epoch: 279, Iter: 58600, Loss: 1.187, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:57:47,353: INFO: Epoch: 279, Iter: 58650, Loss: 1.216, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 08:58:54,172: INFO: Epoch: 279, Iter: 58700, Loss: 1.292, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:00:00,861: INFO: Epoch: 279, Iter: 58750, Loss: 0.957, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 09:01:07,279: INFO: Epoch: 280, Iter: 58800, Loss: 2.434, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:02:13,480: INFO: Epoch: 280, Iter: 58850, Loss: 2.718, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:03:20,479: INFO: Epoch: 280, Iter: 58900, Loss: 1.731, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:04:27,206: INFO: Epoch: 280, Iter: 58950, Loss: 1.208, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:05:34,003: INFO: Epoch: 280, Iter: 59000, Loss: 1.367, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:06:40,433: INFO: Epoch: 281, Iter: 59050, Loss: 1.028, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:07:47,394: INFO: Epoch: 281, Iter: 59100, Loss: 1.303, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:08:54,047: INFO: Epoch: 281, Iter: 59150, Loss: 0.804, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 09:10:00,848: INFO: Epoch: 281, Iter: 59200, Loss: 0.770, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 09:11:07,747: INFO: Epoch: 282, Iter: 59250, Loss: 1.054, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:12:14,514: INFO: Epoch: 282, Iter: 59300, Loss: 0.743, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 09:13:21,489: INFO: Epoch: 282, Iter: 59350, Loss: 0.959, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:14:28,379: INFO: Epoch: 282, Iter: 59400, Loss: 1.209, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:15:35,384: INFO: Epoch: 283, Iter: 59450, Loss: 2.164, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:16:41,891: INFO: Epoch: 283, Iter: 59500, Loss: 0.910, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:17:49,235: INFO: Epoch: 283, Iter: 59550, Loss: 0.697, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 09:18:55,969: INFO: Epoch: 283, Iter: 59600, Loss: 0.768, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 09:20:02,600: INFO: Epoch: 284, Iter: 59650, Loss: 0.667, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 09:21:08,998: INFO: Epoch: 284, Iter: 59700, Loss: 1.129, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:22:15,545: INFO: Epoch: 284, Iter: 59750, Loss: 1.561, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:23:22,429: INFO: Epoch: 284, Iter: 59800, Loss: 1.453, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:24:29,313: INFO: Epoch: 285, Iter: 59850, Loss: 1.672, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:25:36,615: INFO: Epoch: 285, Iter: 59900, Loss: 0.498, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 09:26:43,112: INFO: Epoch: 285, Iter: 59950, Loss: 0.606, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 09:27:50,717: INFO: Epoch: 285, Iter: 60000, Loss: 1.676, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:28:57,019: INFO: Epoch: 285, Iter: 60050, Loss: 0.828, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:30:03,795: INFO: Epoch: 286, Iter: 60100, Loss: 0.671, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 09:31:10,299: INFO: Epoch: 286, Iter: 60150, Loss: 1.037, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:32:16,589: INFO: Epoch: 286, Iter: 60200, Loss: 1.519, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:33:23,318: INFO: Epoch: 286, Iter: 60250, Loss: 1.008, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:34:30,399: INFO: Epoch: 287, Iter: 60300, Loss: 1.711, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:35:37,427: INFO: Epoch: 287, Iter: 60350, Loss: 0.721, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 09:36:43,794: INFO: Epoch: 287, Iter: 60400, Loss: 0.631, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 09:37:50,225: INFO: Epoch: 287, Iter: 60450, Loss: 0.595, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 09:38:56,692: INFO: Epoch: 288, Iter: 60500, Loss: 0.429, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 09:40:03,123: INFO: Epoch: 288, Iter: 60550, Loss: 0.931, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:41:09,896: INFO: Epoch: 288, Iter: 60600, Loss: 1.336, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:42:16,753: INFO: Epoch: 288, Iter: 60650, Loss: 1.369, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:43:24,029: INFO: Epoch: 289, Iter: 60700, Loss: 1.450, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:44:30,987: INFO: Epoch: 289, Iter: 60750, Loss: 1.300, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:45:37,915: INFO: Epoch: 289, Iter: 60800, Loss: 1.574, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:46:44,629: INFO: Epoch: 289, Iter: 60850, Loss: 0.892, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 09:47:52,063: INFO: Epoch: 290, Iter: 60900, Loss: 0.720, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 09:48:58,679: INFO: Epoch: 290, Iter: 60950, Loss: 0.685, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 09:50:05,136: INFO: Epoch: 290, Iter: 61000, Loss: 1.049, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 09:51:11,829: INFO: Epoch: 290, Iter: 61050, Loss: 0.800, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 09:52:18,609: INFO: Epoch: 290, Iter: 61100, Loss: 1.090, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:53:26,841: INFO: Epoch: 291, Iter: 61150, Loss: 0.846, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 09:54:33,531: INFO: Epoch: 291, Iter: 61200, Loss: 1.584, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 09:55:40,283: INFO: Epoch: 291, Iter: 61250, Loss: 0.407, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 09:56:47,375: INFO: Epoch: 291, Iter: 61300, Loss: 0.678, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 09:57:53,962: INFO: Epoch: 292, Iter: 61350, Loss: 0.777, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 09:59:01,192: INFO: Epoch: 292, Iter: 61400, Loss: 2.035, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:00:07,644: INFO: Epoch: 292, Iter: 61450, Loss: 0.351, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:01:14,466: INFO: Epoch: 292, Iter: 61500, Loss: 1.391, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:02:21,391: INFO: Epoch: 293, Iter: 61550, Loss: 0.419, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:03:28,566: INFO: Epoch: 293, Iter: 61600, Loss: 0.543, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:04:34,955: INFO: Epoch: 293, Iter: 61650, Loss: 1.474, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:05:42,721: INFO: Epoch: 293, Iter: 61700, Loss: 0.680, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:06:49,697: INFO: Epoch: 294, Iter: 61750, Loss: 1.363, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:07:57,240: INFO: Epoch: 294, Iter: 61800, Loss: 1.559, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:09:03,759: INFO: Epoch: 294, Iter: 61850, Loss: 0.961, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:10:10,440: INFO: Epoch: 294, Iter: 61900, Loss: 1.469, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:11:16,905: INFO: Epoch: 295, Iter: 61950, Loss: 0.867, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:12:23,932: INFO: Epoch: 295, Iter: 62000, Loss: 0.788, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:13:30,835: INFO: Epoch: 295, Iter: 62050, Loss: 0.685, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:14:37,840: INFO: Epoch: 295, Iter: 62100, Loss: 1.328, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:15:44,507: INFO: Epoch: 295, Iter: 62150, Loss: 0.683, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:16:51,336: INFO: Epoch: 296, Iter: 62200, Loss: 0.634, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:17:58,330: INFO: Epoch: 296, Iter: 62250, Loss: 0.551, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:19:05,691: INFO: Epoch: 296, Iter: 62300, Loss: 0.564, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:20:12,522: INFO: Epoch: 296, Iter: 62350, Loss: 0.439, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:21:20,904: INFO: Epoch: 297, Iter: 62400, Loss: 0.419, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:22:29,449: INFO: Epoch: 297, Iter: 62450, Loss: 0.684, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:23:37,890: INFO: Epoch: 297, Iter: 62500, Loss: 1.204, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:24:47,057: INFO: Epoch: 297, Iter: 62550, Loss: 2.034, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:25:55,442: INFO: Epoch: 298, Iter: 62600, Loss: 1.171, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:27:03,832: INFO: Epoch: 298, Iter: 62650, Loss: 1.723, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:28:12,301: INFO: Epoch: 298, Iter: 62700, Loss: 1.961, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:29:20,549: INFO: Epoch: 298, Iter: 62750, Loss: 0.719, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:30:28,665: INFO: Epoch: 299, Iter: 62800, Loss: 0.866, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:31:36,579: INFO: Epoch: 299, Iter: 62850, Loss: 1.436, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:32:47,269: INFO: Epoch: 299, Iter: 62900, Loss: 2.745, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:33:55,452: INFO: Epoch: 299, Iter: 62950, Loss: 0.951, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:35:03,943: INFO: Epoch: 300, Iter: 63000, Loss: 1.201, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:36:10,834: INFO: Epoch: 300, Iter: 63050, Loss: 0.681, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:37:18,067: INFO: Epoch: 300, Iter: 63100, Loss: 0.830, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:38:24,690: INFO: Epoch: 300, Iter: 63150, Loss: 0.814, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:39:31,513: INFO: Epoch: 300, Iter: 63200, Loss: 0.674, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:40:37,491: INFO: Epoch: 301, Iter: 63250, Loss: 1.565, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:41:44,230: INFO: Epoch: 301, Iter: 63300, Loss: 0.688, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:42:51,338: INFO: Epoch: 301, Iter: 63350, Loss: 0.630, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:43:59,192: INFO: Epoch: 301, Iter: 63400, Loss: 0.681, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:45:07,537: INFO: Epoch: 302, Iter: 63450, Loss: 0.785, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:46:15,840: INFO: Epoch: 302, Iter: 63500, Loss: 1.561, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:47:24,308: INFO: Epoch: 302, Iter: 63550, Loss: 1.453, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:48:32,918: INFO: Epoch: 302, Iter: 63600, Loss: 1.172, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:49:41,151: INFO: Epoch: 303, Iter: 63650, Loss: 0.972, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:50:49,392: INFO: Epoch: 303, Iter: 63700, Loss: 1.579, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:51:58,249: INFO: Epoch: 303, Iter: 63750, Loss: 1.376, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:53:07,062: INFO: Epoch: 303, Iter: 63800, Loss: 0.526, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:54:15,261: INFO: Epoch: 304, Iter: 63850, Loss: 0.458, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 10:55:23,372: INFO: Epoch: 304, Iter: 63900, Loss: 1.729, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:56:30,430: INFO: Epoch: 304, Iter: 63950, Loss: 1.625, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:57:37,382: INFO: Epoch: 304, Iter: 64000, Loss: 1.174, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:58:44,134: INFO: Epoch: 305, Iter: 64050, Loss: 1.556, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 10:59:51,158: INFO: Epoch: 305, Iter: 64100, Loss: 0.052, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 11:00:57,331: INFO: Epoch: 305, Iter: 64150, Loss: 1.151, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:02:04,308: INFO: Epoch: 305, Iter: 64200, Loss: 0.822, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 11:03:11,751: INFO: Epoch: 305, Iter: 64250, Loss: 1.545, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:04:18,169: INFO: Epoch: 306, Iter: 64300, Loss: 0.851, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 11:05:24,980: INFO: Epoch: 306, Iter: 64350, Loss: 1.545, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:06:31,581: INFO: Epoch: 306, Iter: 64400, Loss: 1.250, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:07:38,190: INFO: Epoch: 306, Iter: 64450, Loss: 1.683, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:08:45,288: INFO: Epoch: 307, Iter: 64500, Loss: 1.144, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:09:52,101: INFO: Epoch: 307, Iter: 64550, Loss: 1.023, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 11:10:58,720: INFO: Epoch: 307, Iter: 64600, Loss: 1.141, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:12:05,420: INFO: Epoch: 307, Iter: 64650, Loss: 1.605, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:13:11,954: INFO: Epoch: 308, Iter: 64700, Loss: 0.457, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 11:14:18,531: INFO: Epoch: 308, Iter: 64750, Loss: 1.367, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:15:25,698: INFO: Epoch: 308, Iter: 64800, Loss: 1.415, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:16:32,346: INFO: Epoch: 308, Iter: 64850, Loss: 1.332, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:17:39,179: INFO: Epoch: 309, Iter: 64900, Loss: 1.821, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:18:48,756: INFO: Epoch: 309, Iter: 64950, Loss: 0.873, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 11:19:56,786: INFO: Epoch: 309, Iter: 65000, Loss: 1.191, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:21:05,396: INFO: Epoch: 309, Iter: 65050, Loss: 0.898, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:22:13,434: INFO: Epoch: 310, Iter: 65100, Loss: 1.215, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:23:21,400: INFO: Epoch: 310, Iter: 65150, Loss: 1.875, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:24:29,460: INFO: Epoch: 310, Iter: 65200, Loss: 0.597, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 11:25:37,919: INFO: Epoch: 310, Iter: 65250, Loss: 0.538, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 11:26:46,109: INFO: Epoch: 310, Iter: 65300, Loss: 1.219, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:27:54,304: INFO: Epoch: 311, Iter: 65350, Loss: 1.393, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:29:02,929: INFO: Epoch: 311, Iter: 65400, Loss: 1.138, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:30:11,049: INFO: Epoch: 311, Iter: 65450, Loss: 0.904, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 11:31:19,575: INFO: Epoch: 311, Iter: 65500, Loss: 1.097, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:32:27,767: INFO: Epoch: 312, Iter: 65550, Loss: 1.028, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:33:35,906: INFO: Epoch: 312, Iter: 65600, Loss: 1.229, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:34:44,055: INFO: Epoch: 312, Iter: 65650, Loss: 0.864, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 11:35:52,586: INFO: Epoch: 312, Iter: 65700, Loss: 1.159, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:37:00,715: INFO: Epoch: 313, Iter: 65750, Loss: 0.783, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 11:38:08,926: INFO: Epoch: 313, Iter: 65800, Loss: 0.616, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 11:39:16,970: INFO: Epoch: 313, Iter: 65850, Loss: 1.824, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:40:25,161: INFO: Epoch: 313, Iter: 65900, Loss: 0.770, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 11:41:33,245: INFO: Epoch: 314, Iter: 65950, Loss: 1.486, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:42:41,805: INFO: Epoch: 314, Iter: 66000, Loss: 0.868, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 11:43:50,086: INFO: Epoch: 314, Iter: 66050, Loss: 1.237, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:44:57,989: INFO: Epoch: 314, Iter: 66100, Loss: 1.337, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:46:06,257: INFO: Epoch: 315, Iter: 66150, Loss: 1.570, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:47:14,527: INFO: Epoch: 315, Iter: 66200, Loss: 0.653, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 11:48:23,495: INFO: Epoch: 315, Iter: 66250, Loss: 1.289, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:49:31,579: INFO: Epoch: 315, Iter: 66300, Loss: 0.556, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 11:50:40,401: INFO: Epoch: 315, Iter: 66350, Loss: 0.824, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 11:51:48,908: INFO: Epoch: 316, Iter: 66400, Loss: 0.957, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:52:57,061: INFO: Epoch: 316, Iter: 66450, Loss: 1.421, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:54:04,927: INFO: Epoch: 316, Iter: 66500, Loss: 0.554, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 11:55:13,882: INFO: Epoch: 316, Iter: 66550, Loss: 1.248, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:56:22,289: INFO: Epoch: 317, Iter: 66600, Loss: 0.817, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 11:57:30,471: INFO: Epoch: 317, Iter: 66650, Loss: 1.163, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 11:58:39,150: INFO: Epoch: 317, Iter: 66700, Loss: 0.987, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 11:59:47,293: INFO: Epoch: 317, Iter: 66750, Loss: 0.837, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:00:55,592: INFO: Epoch: 318, Iter: 66800, Loss: 0.805, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:02:03,714: INFO: Epoch: 318, Iter: 66850, Loss: 1.550, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:03:12,781: INFO: Epoch: 318, Iter: 66900, Loss: 0.636, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:04:20,879: INFO: Epoch: 318, Iter: 66950, Loss: 1.400, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:05:29,206: INFO: Epoch: 319, Iter: 67000, Loss: 1.812, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:06:37,319: INFO: Epoch: 319, Iter: 67050, Loss: 0.589, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:07:45,850: INFO: Epoch: 319, Iter: 67100, Loss: 0.562, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:08:55,137: INFO: Epoch: 319, Iter: 67150, Loss: 1.366, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:10:03,612: INFO: Epoch: 320, Iter: 67200, Loss: 0.753, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:11:11,635: INFO: Epoch: 320, Iter: 67250, Loss: 1.090, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:12:19,703: INFO: Epoch: 320, Iter: 67300, Loss: 0.893, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:13:28,544: INFO: Epoch: 320, Iter: 67350, Loss: 1.561, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:14:36,713: INFO: Epoch: 320, Iter: 67400, Loss: 0.788, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:15:44,831: INFO: Epoch: 321, Iter: 67450, Loss: 1.210, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:16:52,780: INFO: Epoch: 321, Iter: 67500, Loss: 1.121, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:18:01,040: INFO: Epoch: 321, Iter: 67550, Loss: 0.944, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:19:09,245: INFO: Epoch: 321, Iter: 67600, Loss: 0.968, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:20:17,348: INFO: Epoch: 322, Iter: 67650, Loss: 0.997, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:21:25,700: INFO: Epoch: 322, Iter: 67700, Loss: 1.113, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:22:33,927: INFO: Epoch: 322, Iter: 67750, Loss: 1.065, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:23:42,794: INFO: Epoch: 322, Iter: 67800, Loss: 1.419, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:24:50,796: INFO: Epoch: 323, Iter: 67850, Loss: 1.671, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:25:59,112: INFO: Epoch: 323, Iter: 67900, Loss: 1.564, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:27:11,135: INFO: Epoch: 323, Iter: 67950, Loss: 2.357, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:28:19,435: INFO: Epoch: 323, Iter: 68000, Loss: 1.338, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:29:27,308: INFO: Epoch: 324, Iter: 68050, Loss: 1.192, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:30:35,755: INFO: Epoch: 324, Iter: 68100, Loss: 1.083, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:31:44,219: INFO: Epoch: 324, Iter: 68150, Loss: 0.763, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:32:52,517: INFO: Epoch: 324, Iter: 68200, Loss: 0.789, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:34:00,485: INFO: Epoch: 325, Iter: 68250, Loss: 1.238, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:35:08,579: INFO: Epoch: 325, Iter: 68300, Loss: 0.722, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:36:16,923: INFO: Epoch: 325, Iter: 68350, Loss: 1.443, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:37:25,279: INFO: Epoch: 325, Iter: 68400, Loss: 1.223, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:38:33,538: INFO: Epoch: 325, Iter: 68450, Loss: 0.494, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:39:41,745: INFO: Epoch: 326, Iter: 68500, Loss: 0.863, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:40:49,799: INFO: Epoch: 326, Iter: 68550, Loss: 1.169, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:41:57,885: INFO: Epoch: 326, Iter: 68600, Loss: 1.370, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:43:06,798: INFO: Epoch: 326, Iter: 68650, Loss: 1.323, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:44:15,113: INFO: Epoch: 327, Iter: 68700, Loss: 0.953, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:45:23,639: INFO: Epoch: 327, Iter: 68750, Loss: 0.815, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:46:32,042: INFO: Epoch: 327, Iter: 68800, Loss: 1.337, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:47:39,928: INFO: Epoch: 327, Iter: 68850, Loss: 1.672, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:48:48,116: INFO: Epoch: 328, Iter: 68900, Loss: 0.623, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:49:56,411: INFO: Epoch: 328, Iter: 68950, Loss: 0.643, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:51:04,700: INFO: Epoch: 328, Iter: 69000, Loss: 1.383, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:52:12,845: INFO: Epoch: 328, Iter: 69050, Loss: 0.696, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:53:21,154: INFO: Epoch: 329, Iter: 69100, Loss: 0.713, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:54:29,563: INFO: Epoch: 329, Iter: 69150, Loss: 0.710, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:55:37,660: INFO: Epoch: 329, Iter: 69200, Loss: 0.661, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:56:46,021: INFO: Epoch: 329, Iter: 69250, Loss: 0.653, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 12:57:54,367: INFO: Epoch: 330, Iter: 69300, Loss: 1.213, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 12:59:02,332: INFO: Epoch: 330, Iter: 69350, Loss: 1.696, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:00:10,515: INFO: Epoch: 330, Iter: 69400, Loss: 1.567, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:01:18,762: INFO: Epoch: 330, Iter: 69450, Loss: 0.825, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:02:27,015: INFO: Epoch: 330, Iter: 69500, Loss: 0.793, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:03:35,419: INFO: Epoch: 331, Iter: 69550, Loss: 0.754, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:04:43,643: INFO: Epoch: 331, Iter: 69600, Loss: 1.242, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:05:51,728: INFO: Epoch: 331, Iter: 69650, Loss: 1.263, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:06:59,228: INFO: Epoch: 331, Iter: 69700, Loss: 1.640, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:08:06,200: INFO: Epoch: 332, Iter: 69750, Loss: 0.856, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:09:12,386: INFO: Epoch: 332, Iter: 69800, Loss: 0.785, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:10:19,439: INFO: Epoch: 332, Iter: 69850, Loss: 1.178, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:11:26,232: INFO: Epoch: 332, Iter: 69900, Loss: 0.718, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:12:32,602: INFO: Epoch: 333, Iter: 69950, Loss: 1.550, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:13:40,548: INFO: Epoch: 333, Iter: 70000, Loss: 1.305, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:14:47,155: INFO: Epoch: 333, Iter: 70050, Loss: 0.772, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:15:53,774: INFO: Epoch: 333, Iter: 70100, Loss: 0.911, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:17:00,215: INFO: Epoch: 334, Iter: 70150, Loss: 0.994, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:18:07,151: INFO: Epoch: 334, Iter: 70200, Loss: 1.257, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:19:13,652: INFO: Epoch: 334, Iter: 70250, Loss: 0.751, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:20:20,546: INFO: Epoch: 334, Iter: 70300, Loss: 0.617, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:21:27,561: INFO: Epoch: 335, Iter: 70350, Loss: 0.572, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:22:37,123: INFO: Epoch: 335, Iter: 70400, Loss: 1.587, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:23:44,872: INFO: Epoch: 335, Iter: 70450, Loss: 1.563, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:24:51,619: INFO: Epoch: 335, Iter: 70500, Loss: 0.594, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:25:58,309: INFO: Epoch: 335, Iter: 70550, Loss: 1.211, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:27:05,051: INFO: Epoch: 336, Iter: 70600, Loss: 1.664, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:28:12,219: INFO: Epoch: 336, Iter: 70650, Loss: 0.863, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:29:18,674: INFO: Epoch: 336, Iter: 70700, Loss: 1.098, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:30:24,970: INFO: Epoch: 336, Iter: 70750, Loss: 0.877, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:31:31,084: INFO: Epoch: 337, Iter: 70800, Loss: 0.911, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:32:38,026: INFO: Epoch: 337, Iter: 70850, Loss: 0.902, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:33:45,278: INFO: Epoch: 337, Iter: 70900, Loss: 0.960, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:34:51,739: INFO: Epoch: 337, Iter: 70950, Loss: 1.268, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:35:58,671: INFO: Epoch: 338, Iter: 71000, Loss: 1.299, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:37:05,017: INFO: Epoch: 338, Iter: 71050, Loss: 1.485, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:38:12,112: INFO: Epoch: 338, Iter: 71100, Loss: 0.754, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:39:18,579: INFO: Epoch: 338, Iter: 71150, Loss: 0.748, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:40:24,777: INFO: Epoch: 339, Iter: 71200, Loss: 0.696, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:41:31,433: INFO: Epoch: 339, Iter: 71250, Loss: 0.674, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:42:38,102: INFO: Epoch: 339, Iter: 71300, Loss: 1.336, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:43:45,288: INFO: Epoch: 339, Iter: 71350, Loss: 0.730, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:44:50,989: INFO: Epoch: 340, Iter: 71400, Loss: 1.512, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:45:57,814: INFO: Epoch: 340, Iter: 71450, Loss: 1.455, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:47:04,170: INFO: Epoch: 340, Iter: 71500, Loss: 0.556, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:48:10,503: INFO: Epoch: 340, Iter: 71550, Loss: 1.469, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:49:17,023: INFO: Epoch: 340, Iter: 71600, Loss: 0.622, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:50:24,715: INFO: Epoch: 341, Iter: 71650, Loss: 1.649, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:51:31,284: INFO: Epoch: 341, Iter: 71700, Loss: 1.305, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:52:37,367: INFO: Epoch: 341, Iter: 71750, Loss: 1.277, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:53:43,796: INFO: Epoch: 341, Iter: 71800, Loss: 0.781, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 13:54:50,586: INFO: Epoch: 342, Iter: 71850, Loss: 1.465, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:55:57,946: INFO: Epoch: 342, Iter: 71900, Loss: 1.153, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:57:05,033: INFO: Epoch: 342, Iter: 71950, Loss: 1.368, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:58:11,930: INFO: Epoch: 342, Iter: 72000, Loss: 1.356, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 13:59:18,852: INFO: Epoch: 343, Iter: 72050, Loss: 0.894, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:00:25,130: INFO: Epoch: 343, Iter: 72100, Loss: 1.279, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 14:01:31,635: INFO: Epoch: 343, Iter: 72150, Loss: 0.809, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:02:38,472: INFO: Epoch: 343, Iter: 72200, Loss: 1.314, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 14:03:47,058: INFO: Epoch: 344, Iter: 72250, Loss: 1.376, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 14:04:55,188: INFO: Epoch: 344, Iter: 72300, Loss: 0.570, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:06:03,595: INFO: Epoch: 344, Iter: 72350, Loss: 0.523, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:07:11,864: INFO: Epoch: 344, Iter: 72400, Loss: 1.628, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 14:08:20,371: INFO: Epoch: 345, Iter: 72450, Loss: 1.414, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 14:09:28,436: INFO: Epoch: 345, Iter: 72500, Loss: 0.717, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:10:36,664: INFO: Epoch: 345, Iter: 72550, Loss: 0.695, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:11:45,036: INFO: Epoch: 345, Iter: 72600, Loss: 1.491, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 14:12:53,564: INFO: Epoch: 345, Iter: 72650, Loss: 0.886, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:14:01,905: INFO: Epoch: 346, Iter: 72700, Loss: 0.588, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:15:10,011: INFO: Epoch: 346, Iter: 72750, Loss: 1.657, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 14:16:18,290: INFO: Epoch: 346, Iter: 72800, Loss: 1.664, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 14:17:26,604: INFO: Epoch: 346, Iter: 72850, Loss: 1.112, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 14:18:35,024: INFO: Epoch: 347, Iter: 72900, Loss: 1.003, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 14:19:43,802: INFO: Epoch: 347, Iter: 72950, Loss: 0.704, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:20:52,326: INFO: Epoch: 347, Iter: 73000, Loss: 0.680, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:22:00,305: INFO: Epoch: 347, Iter: 73050, Loss: 1.302, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 14:23:08,717: INFO: Epoch: 348, Iter: 73100, Loss: 1.237, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 14:24:17,059: INFO: Epoch: 348, Iter: 73150, Loss: 0.984, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:25:25,673: INFO: Epoch: 348, Iter: 73200, Loss: 0.928, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:26:33,776: INFO: Epoch: 348, Iter: 73250, Loss: 0.907, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:27:42,395: INFO: Epoch: 349, Iter: 73300, Loss: 1.120, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 14:28:50,827: INFO: Epoch: 349, Iter: 73350, Loss: 1.601, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 14:29:59,049: INFO: Epoch: 349, Iter: 73400, Loss: 1.549, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 14:31:06,911: INFO: Epoch: 349, Iter: 73450, Loss: 1.456, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 14:32:14,933: INFO: Epoch: 350, Iter: 73500, Loss: 1.326, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 14:33:23,386: INFO: Epoch: 350, Iter: 73550, Loss: 0.723, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:34:31,266: INFO: Epoch: 350, Iter: 73600, Loss: 1.300, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 14:35:39,545: INFO: Epoch: 350, Iter: 73650, Loss: 1.562, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 14:36:47,811: INFO: Epoch: 350, Iter: 73700, Loss: 0.672, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:37:56,067: INFO: Epoch: 351, Iter: 73750, Loss: 0.587, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:39:04,380: INFO: Epoch: 351, Iter: 73800, Loss: 0.631, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:40:13,019: INFO: Epoch: 351, Iter: 73850, Loss: 0.737, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:41:21,343: INFO: Epoch: 351, Iter: 73900, Loss: 0.816, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:42:29,856: INFO: Epoch: 352, Iter: 73950, Loss: 0.905, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:43:38,843: INFO: Epoch: 352, Iter: 74000, Loss: 1.231, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 14:44:47,086: INFO: Epoch: 352, Iter: 74050, Loss: 1.053, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:45:55,513: INFO: Epoch: 352, Iter: 74100, Loss: 1.053, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:47:03,247: INFO: Epoch: 353, Iter: 74150, Loss: 0.945, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:48:12,470: INFO: Epoch: 353, Iter: 74200, Loss: 0.864, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:49:20,508: INFO: Epoch: 353, Iter: 74250, Loss: 1.206, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 14:50:28,932: INFO: Epoch: 353, Iter: 74300, Loss: 1.105, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 14:51:36,908: INFO: Epoch: 354, Iter: 74350, Loss: 0.827, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:52:45,001: INFO: Epoch: 354, Iter: 74400, Loss: 1.172, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 14:53:53,477: INFO: Epoch: 354, Iter: 74450, Loss: 0.817, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:55:01,645: INFO: Epoch: 354, Iter: 74500, Loss: 0.712, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:56:09,629: INFO: Epoch: 355, Iter: 74550, Loss: 0.550, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 14:57:17,845: INFO: Epoch: 355, Iter: 74600, Loss: 1.536, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 14:58:26,200: INFO: Epoch: 355, Iter: 74650, Loss: 1.810, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 14:59:34,412: INFO: Epoch: 355, Iter: 74700, Loss: 1.308, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:00:42,654: INFO: Epoch: 355, Iter: 74750, Loss: 0.730, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 15:01:51,075: INFO: Epoch: 356, Iter: 74800, Loss: 0.666, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 15:02:59,742: INFO: Epoch: 356, Iter: 74850, Loss: 1.653, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:04:07,733: INFO: Epoch: 356, Iter: 74900, Loss: 1.299, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:05:15,985: INFO: Epoch: 356, Iter: 74950, Loss: 1.258, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:06:24,270: INFO: Epoch: 357, Iter: 75000, Loss: 1.470, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:07:32,387: INFO: Epoch: 357, Iter: 75050, Loss: 0.975, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:08:40,747: INFO: Epoch: 357, Iter: 75100, Loss: 0.890, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 15:09:48,825: INFO: Epoch: 357, Iter: 75150, Loss: 1.496, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:10:57,080: INFO: Epoch: 358, Iter: 75200, Loss: 1.463, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:12:05,331: INFO: Epoch: 358, Iter: 75250, Loss: 0.751, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 15:13:14,217: INFO: Epoch: 358, Iter: 75300, Loss: 0.680, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 15:14:22,251: INFO: Epoch: 358, Iter: 75350, Loss: 0.662, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 15:15:30,077: INFO: Epoch: 359, Iter: 75400, Loss: 1.303, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:16:36,917: INFO: Epoch: 359, Iter: 75450, Loss: 1.445, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:17:43,744: INFO: Epoch: 359, Iter: 75500, Loss: 1.379, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:18:50,849: INFO: Epoch: 359, Iter: 75550, Loss: 1.369, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:19:58,148: INFO: Epoch: 360, Iter: 75600, Loss: 1.313, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:21:04,541: INFO: Epoch: 360, Iter: 75650, Loss: 0.789, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 15:22:11,251: INFO: Epoch: 360, Iter: 75700, Loss: 1.412, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:23:18,817: INFO: Epoch: 360, Iter: 75750, Loss: 0.646, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 15:24:25,026: INFO: Epoch: 360, Iter: 75800, Loss: 0.581, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 15:25:34,943: INFO: Epoch: 361, Iter: 75850, Loss: 1.527, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:26:41,266: INFO: Epoch: 361, Iter: 75900, Loss: 1.446, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:27:48,019: INFO: Epoch: 361, Iter: 75950, Loss: 0.598, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 15:28:54,649: INFO: Epoch: 361, Iter: 76000, Loss: 0.615, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 15:30:01,112: INFO: Epoch: 362, Iter: 76050, Loss: 1.283, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:31:07,840: INFO: Epoch: 362, Iter: 76100, Loss: 0.667, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 15:32:14,632: INFO: Epoch: 362, Iter: 76150, Loss: 1.390, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:33:20,785: INFO: Epoch: 362, Iter: 76200, Loss: 1.311, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:34:27,531: INFO: Epoch: 363, Iter: 76250, Loss: 1.180, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:35:34,350: INFO: Epoch: 363, Iter: 76300, Loss: 1.068, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:36:41,440: INFO: Epoch: 363, Iter: 76350, Loss: 1.181, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:37:48,190: INFO: Epoch: 363, Iter: 76400, Loss: 1.188, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:38:55,153: INFO: Epoch: 364, Iter: 76450, Loss: 0.964, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 15:40:01,758: INFO: Epoch: 364, Iter: 76500, Loss: 0.774, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 15:41:08,200: INFO: Epoch: 364, Iter: 76550, Loss: 1.396, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:42:14,651: INFO: Epoch: 364, Iter: 76600, Loss: 0.709, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 15:43:24,644: INFO: Epoch: 365, Iter: 76650, Loss: 0.759, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 15:44:31,589: INFO: Epoch: 365, Iter: 76700, Loss: 0.773, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 15:45:38,225: INFO: Epoch: 365, Iter: 76750, Loss: 1.617, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:46:45,059: INFO: Epoch: 365, Iter: 76800, Loss: 0.566, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 15:47:51,621: INFO: Epoch: 365, Iter: 76850, Loss: 1.655, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:48:58,180: INFO: Epoch: 366, Iter: 76900, Loss: 1.455, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:50:05,684: INFO: Epoch: 366, Iter: 76950, Loss: 1.302, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:51:12,120: INFO: Epoch: 366, Iter: 77000, Loss: 1.319, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:52:18,658: INFO: Epoch: 366, Iter: 77050, Loss: 1.141, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:53:25,939: INFO: Epoch: 367, Iter: 77100, Loss: 0.978, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 15:54:32,446: INFO: Epoch: 367, Iter: 77150, Loss: 1.027, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:55:39,157: INFO: Epoch: 367, Iter: 77200, Loss: 1.055, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:56:46,294: INFO: Epoch: 367, Iter: 77250, Loss: 1.101, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:57:54,934: INFO: Epoch: 368, Iter: 77300, Loss: 1.154, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 15:59:03,095: INFO: Epoch: 368, Iter: 77350, Loss: 0.691, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:00:11,455: INFO: Epoch: 368, Iter: 77400, Loss: 0.691, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:01:19,516: INFO: Epoch: 368, Iter: 77450, Loss: 0.648, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:02:27,614: INFO: Epoch: 369, Iter: 77500, Loss: 0.763, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:03:36,046: INFO: Epoch: 369, Iter: 77550, Loss: 1.197, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:04:42,783: INFO: Epoch: 369, Iter: 77600, Loss: 1.532, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:05:49,505: INFO: Epoch: 369, Iter: 77650, Loss: 1.415, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:06:55,883: INFO: Epoch: 370, Iter: 77700, Loss: 1.197, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:08:02,060: INFO: Epoch: 370, Iter: 77750, Loss: 0.754, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:09:09,947: INFO: Epoch: 370, Iter: 77800, Loss: 1.361, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:10:16,728: INFO: Epoch: 370, Iter: 77850, Loss: 1.118, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:11:23,347: INFO: Epoch: 370, Iter: 77900, Loss: 0.736, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:12:29,859: INFO: Epoch: 371, Iter: 77950, Loss: 0.715, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:13:37,400: INFO: Epoch: 371, Iter: 78000, Loss: 0.723, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:14:44,535: INFO: Epoch: 371, Iter: 78050, Loss: 0.814, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:15:51,417: INFO: Epoch: 371, Iter: 78100, Loss: 0.769, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:16:57,352: INFO: Epoch: 372, Iter: 78150, Loss: 0.645, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:18:05,430: INFO: Epoch: 372, Iter: 78200, Loss: 1.500, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:19:13,262: INFO: Epoch: 372, Iter: 78250, Loss: 1.845, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:20:22,079: INFO: Epoch: 372, Iter: 78300, Loss: 0.569, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:21:30,281: INFO: Epoch: 373, Iter: 78350, Loss: 0.664, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:22:38,348: INFO: Epoch: 373, Iter: 78400, Loss: 1.534, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:23:48,508: INFO: Epoch: 373, Iter: 78450, Loss: 1.536, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:24:56,882: INFO: Epoch: 373, Iter: 78500, Loss: 0.748, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:26:05,239: INFO: Epoch: 374, Iter: 78550, Loss: 1.452, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:27:13,493: INFO: Epoch: 374, Iter: 78600, Loss: 1.455, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:28:21,867: INFO: Epoch: 374, Iter: 78650, Loss: 1.280, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:29:29,959: INFO: Epoch: 374, Iter: 78700, Loss: 1.174, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:30:38,031: INFO: Epoch: 375, Iter: 78750, Loss: 1.412, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:31:45,890: INFO: Epoch: 375, Iter: 78800, Loss: 0.956, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:32:53,987: INFO: Epoch: 375, Iter: 78850, Loss: 1.064, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:34:01,738: INFO: Epoch: 375, Iter: 78900, Loss: 0.866, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:35:09,777: INFO: Epoch: 375, Iter: 78950, Loss: 0.830, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:36:17,040: INFO: Epoch: 376, Iter: 79000, Loss: 1.251, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:37:24,060: INFO: Epoch: 376, Iter: 79050, Loss: 1.026, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:38:31,004: INFO: Epoch: 376, Iter: 79100, Loss: 1.474, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:39:37,643: INFO: Epoch: 376, Iter: 79150, Loss: 0.774, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:40:44,330: INFO: Epoch: 377, Iter: 79200, Loss: 0.710, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:41:50,506: INFO: Epoch: 377, Iter: 79250, Loss: 0.684, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:42:57,379: INFO: Epoch: 377, Iter: 79300, Loss: 0.620, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:44:03,906: INFO: Epoch: 377, Iter: 79350, Loss: 0.515, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:45:10,564: INFO: Epoch: 378, Iter: 79400, Loss: 1.644, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:46:17,300: INFO: Epoch: 378, Iter: 79450, Loss: 0.522, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:47:24,676: INFO: Epoch: 378, Iter: 79500, Loss: 0.612, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:48:31,650: INFO: Epoch: 378, Iter: 79550, Loss: 1.346, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:49:38,286: INFO: Epoch: 379, Iter: 79600, Loss: 0.802, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:50:44,639: INFO: Epoch: 379, Iter: 79650, Loss: 0.770, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:51:51,543: INFO: Epoch: 379, Iter: 79700, Loss: 0.818, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:52:58,605: INFO: Epoch: 379, Iter: 79750, Loss: 1.896, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:54:05,196: INFO: Epoch: 380, Iter: 79800, Loss: 0.771, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:55:11,599: INFO: Epoch: 380, Iter: 79850, Loss: 0.963, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:56:18,495: INFO: Epoch: 380, Iter: 79900, Loss: 0.989, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:57:25,179: INFO: Epoch: 380, Iter: 79950, Loss: 0.756, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 16:58:32,000: INFO: Epoch: 380, Iter: 80000, Loss: 1.828, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 16:59:38,716: INFO: Epoch: 381, Iter: 80050, Loss: 1.730, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 17:00:45,657: INFO: Epoch: 381, Iter: 80100, Loss: 1.573, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 17:01:52,057: INFO: Epoch: 381, Iter: 80150, Loss: 1.315, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 17:02:58,531: INFO: Epoch: 381, Iter: 80200, Loss: 0.706, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:04:05,354: INFO: Epoch: 382, Iter: 80250, Loss: 1.240, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 17:05:12,031: INFO: Epoch: 382, Iter: 80300, Loss: 0.717, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:06:18,942: INFO: Epoch: 382, Iter: 80350, Loss: 1.480, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 17:07:25,751: INFO: Epoch: 382, Iter: 80400, Loss: 1.218, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 17:08:32,359: INFO: Epoch: 383, Iter: 80450, Loss: 0.818, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:09:38,955: INFO: Epoch: 383, Iter: 80500, Loss: 1.073, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 17:10:45,689: INFO: Epoch: 383, Iter: 80550, Loss: 0.962, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 17:11:52,786: INFO: Epoch: 383, Iter: 80600, Loss: 0.828, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:12:59,960: INFO: Epoch: 384, Iter: 80650, Loss: 0.781, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:14:06,744: INFO: Epoch: 384, Iter: 80700, Loss: 0.671, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:15:13,764: INFO: Epoch: 384, Iter: 80750, Loss: 1.567, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 17:16:20,826: INFO: Epoch: 384, Iter: 80800, Loss: 1.383, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 17:17:27,500: INFO: Epoch: 385, Iter: 80850, Loss: 0.783, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:18:34,063: INFO: Epoch: 385, Iter: 80900, Loss: 1.286, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 17:19:40,924: INFO: Epoch: 385, Iter: 80950, Loss: 1.260, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 17:20:47,595: INFO: Epoch: 385, Iter: 81000, Loss: 0.752, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:21:54,981: INFO: Epoch: 385, Iter: 81050, Loss: 0.712, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:23:06,540: INFO: Epoch: 386, Iter: 81100, Loss: 0.638, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:24:15,467: INFO: Epoch: 386, Iter: 81150, Loss: 0.644, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:25:24,131: INFO: Epoch: 386, Iter: 81200, Loss: 0.672, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:26:32,621: INFO: Epoch: 386, Iter: 81250, Loss: 0.702, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:27:41,203: INFO: Epoch: 387, Iter: 81300, Loss: 0.733, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:28:49,777: INFO: Epoch: 387, Iter: 81350, Loss: 0.966, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 17:29:58,152: INFO: Epoch: 387, Iter: 81400, Loss: 1.769, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 17:31:07,111: INFO: Epoch: 387, Iter: 81450, Loss: 0.807, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:32:15,538: INFO: Epoch: 388, Iter: 81500, Loss: 1.189, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 17:33:24,508: INFO: Epoch: 388, Iter: 81550, Loss: 0.775, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:34:33,457: INFO: Epoch: 388, Iter: 81600, Loss: 1.365, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 17:35:42,153: INFO: Epoch: 388, Iter: 81650, Loss: 0.915, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:36:50,833: INFO: Epoch: 389, Iter: 81700, Loss: 0.966, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:37:59,332: INFO: Epoch: 389, Iter: 81750, Loss: 1.394, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 17:39:07,806: INFO: Epoch: 389, Iter: 81800, Loss: 0.683, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:40:16,248: INFO: Epoch: 389, Iter: 81850, Loss: 0.738, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:41:24,840: INFO: Epoch: 390, Iter: 81900, Loss: 1.448, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 17:42:33,482: INFO: Epoch: 390, Iter: 81950, Loss: 0.328, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:43:41,983: INFO: Epoch: 390, Iter: 82000, Loss: 1.540, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 17:44:50,354: INFO: Epoch: 390, Iter: 82050, Loss: 0.970, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 17:45:59,257: INFO: Epoch: 390, Iter: 82100, Loss: 1.392, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 17:47:08,385: INFO: Epoch: 391, Iter: 82150, Loss: 2.113, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 17:48:17,155: INFO: Epoch: 391, Iter: 82200, Loss: 0.321, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:49:25,431: INFO: Epoch: 391, Iter: 82250, Loss: 0.825, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:50:34,115: INFO: Epoch: 391, Iter: 82300, Loss: 0.701, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:51:42,827: INFO: Epoch: 392, Iter: 82350, Loss: 0.599, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:52:51,175: INFO: Epoch: 392, Iter: 82400, Loss: 0.639, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:53:59,567: INFO: Epoch: 392, Iter: 82450, Loss: 0.578, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:55:08,338: INFO: Epoch: 392, Iter: 82500, Loss: 0.514, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 17:56:17,477: INFO: Epoch: 393, Iter: 82550, Loss: 1.589, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 17:57:25,718: INFO: Epoch: 393, Iter: 82600, Loss: 1.509, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 17:58:34,787: INFO: Epoch: 393, Iter: 82650, Loss: 1.335, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 17:59:43,571: INFO: Epoch: 393, Iter: 82700, Loss: 0.984, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:00:52,135: INFO: Epoch: 394, Iter: 82750, Loss: 1.305, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 18:02:00,783: INFO: Epoch: 394, Iter: 82800, Loss: 0.904, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:03:09,069: INFO: Epoch: 394, Iter: 82850, Loss: 0.752, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:04:18,318: INFO: Epoch: 394, Iter: 82900, Loss: 0.679, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:05:27,382: INFO: Epoch: 395, Iter: 82950, Loss: 0.659, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:06:35,961: INFO: Epoch: 395, Iter: 83000, Loss: 1.680, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 18:07:44,599: INFO: Epoch: 395, Iter: 83050, Loss: 1.373, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 18:08:53,729: INFO: Epoch: 395, Iter: 83100, Loss: 0.790, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:10:02,215: INFO: Epoch: 395, Iter: 83150, Loss: 1.358, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 18:11:10,774: INFO: Epoch: 396, Iter: 83200, Loss: 1.491, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 18:12:19,139: INFO: Epoch: 396, Iter: 83250, Loss: 0.633, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:13:28,110: INFO: Epoch: 396, Iter: 83300, Loss: 1.626, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 18:14:36,821: INFO: Epoch: 396, Iter: 83350, Loss: 1.073, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 18:15:45,617: INFO: Epoch: 397, Iter: 83400, Loss: 0.987, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 18:16:54,330: INFO: Epoch: 397, Iter: 83450, Loss: 0.974, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 18:18:02,945: INFO: Epoch: 397, Iter: 83500, Loss: 0.989, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 18:19:12,396: INFO: Epoch: 397, Iter: 83550, Loss: 0.799, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:20:20,776: INFO: Epoch: 398, Iter: 83600, Loss: 1.489, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 18:21:29,255: INFO: Epoch: 398, Iter: 83650, Loss: 0.828, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:22:37,853: INFO: Epoch: 398, Iter: 83700, Loss: 1.253, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 18:23:46,392: INFO: Epoch: 398, Iter: 83750, Loss: 0.719, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:24:55,162: INFO: Epoch: 399, Iter: 83800, Loss: 0.563, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:26:03,847: INFO: Epoch: 399, Iter: 83850, Loss: 1.505, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 18:27:12,578: INFO: Epoch: 399, Iter: 83900, Loss: 1.729, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 18:28:21,362: INFO: Epoch: 399, Iter: 83950, Loss: 0.431, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:29:29,388: INFO: Epoch: 400, Iter: 84000, Loss: 1.340, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 18:30:37,666: INFO: Epoch: 400, Iter: 84050, Loss: 0.952, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:31:45,764: INFO: Epoch: 400, Iter: 84100, Loss: 1.012, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:32:54,137: INFO: Epoch: 400, Iter: 84150, Loss: 0.939, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:34:02,551: INFO: Epoch: 400, Iter: 84200, Loss: 1.213, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 18:35:10,863: INFO: Epoch: 401, Iter: 84250, Loss: 0.827, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:36:18,904: INFO: Epoch: 401, Iter: 84300, Loss: 0.749, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:37:26,994: INFO: Epoch: 401, Iter: 84350, Loss: 1.331, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 18:38:35,190: INFO: Epoch: 401, Iter: 84400, Loss: 1.201, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 18:39:43,640: INFO: Epoch: 402, Iter: 84450, Loss: 3.047, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 18:40:52,269: INFO: Epoch: 402, Iter: 84500, Loss: 0.764, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:42:00,436: INFO: Epoch: 402, Iter: 84550, Loss: 1.511, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 18:43:08,866: INFO: Epoch: 402, Iter: 84600, Loss: 0.752, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:44:16,922: INFO: Epoch: 403, Iter: 84650, Loss: 0.705, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:45:25,330: INFO: Epoch: 403, Iter: 84700, Loss: 0.660, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:46:33,575: INFO: Epoch: 403, Iter: 84750, Loss: 0.618, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:47:41,270: INFO: Epoch: 403, Iter: 84800, Loss: 0.652, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:48:49,591: INFO: Epoch: 404, Iter: 84850, Loss: 0.643, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:49:57,805: INFO: Epoch: 404, Iter: 84900, Loss: 1.518, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 18:51:06,801: INFO: Epoch: 404, Iter: 84950, Loss: 1.446, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 18:52:14,697: INFO: Epoch: 404, Iter: 85000, Loss: 0.849, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:53:22,928: INFO: Epoch: 405, Iter: 85050, Loss: 1.527, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 18:54:30,999: INFO: Epoch: 405, Iter: 85100, Loss: 1.353, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 18:55:39,606: INFO: Epoch: 405, Iter: 85150, Loss: 1.213, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 18:56:47,698: INFO: Epoch: 405, Iter: 85200, Loss: 0.986, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:57:55,559: INFO: Epoch: 405, Iter: 85250, Loss: 0.897, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 18:59:03,531: INFO: Epoch: 406, Iter: 85300, Loss: 1.220, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 19:00:11,584: INFO: Epoch: 406, Iter: 85350, Loss: 0.773, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:01:19,759: INFO: Epoch: 406, Iter: 85400, Loss: 0.779, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:02:27,994: INFO: Epoch: 406, Iter: 85450, Loss: 0.692, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:03:36,371: INFO: Epoch: 407, Iter: 85500, Loss: 0.620, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:04:44,538: INFO: Epoch: 407, Iter: 85550, Loss: 1.520, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 19:05:52,851: INFO: Epoch: 407, Iter: 85600, Loss: 1.483, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 19:07:00,905: INFO: Epoch: 407, Iter: 85650, Loss: 0.577, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:08:09,110: INFO: Epoch: 408, Iter: 85700, Loss: 1.739, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 19:09:17,302: INFO: Epoch: 408, Iter: 85750, Loss: 1.799, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 19:10:25,706: INFO: Epoch: 408, Iter: 85800, Loss: 1.129, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 19:11:33,671: INFO: Epoch: 408, Iter: 85850, Loss: 1.732, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 19:12:41,729: INFO: Epoch: 409, Iter: 85900, Loss: 0.664, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:13:50,241: INFO: Epoch: 409, Iter: 85950, Loss: 0.731, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:14:58,791: INFO: Epoch: 409, Iter: 86000, Loss: 0.783, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:16:06,948: INFO: Epoch: 409, Iter: 86050, Loss: 0.765, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:17:14,999: INFO: Epoch: 410, Iter: 86100, Loss: 0.782, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:18:23,517: INFO: Epoch: 410, Iter: 86150, Loss: 0.727, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:19:31,906: INFO: Epoch: 410, Iter: 86200, Loss: 1.428, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 19:20:40,401: INFO: Epoch: 410, Iter: 86250, Loss: 1.196, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 19:21:48,641: INFO: Epoch: 410, Iter: 86300, Loss: 0.818, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:22:57,028: INFO: Epoch: 411, Iter: 86350, Loss: 0.753, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:24:04,946: INFO: Epoch: 411, Iter: 86400, Loss: 1.336, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 19:25:13,582: INFO: Epoch: 411, Iter: 86450, Loss: 0.750, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:26:24,447: INFO: Epoch: 411, Iter: 86500, Loss: 0.687, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:27:32,532: INFO: Epoch: 412, Iter: 86550, Loss: 0.629, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:28:40,614: INFO: Epoch: 412, Iter: 86600, Loss: 0.593, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:29:48,936: INFO: Epoch: 412, Iter: 86650, Loss: 0.670, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:30:57,223: INFO: Epoch: 412, Iter: 86700, Loss: 1.253, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 19:32:05,024: INFO: Epoch: 413, Iter: 86750, Loss: 1.483, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 19:33:13,525: INFO: Epoch: 413, Iter: 86800, Loss: 0.768, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:34:21,804: INFO: Epoch: 413, Iter: 86850, Loss: 1.188, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 19:35:30,288: INFO: Epoch: 413, Iter: 86900, Loss: 0.774, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:36:38,300: INFO: Epoch: 414, Iter: 86950, Loss: 1.275, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 19:37:46,325: INFO: Epoch: 414, Iter: 87000, Loss: 0.757, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:38:56,932: INFO: Epoch: 414, Iter: 87050, Loss: 0.816, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:40:04,940: INFO: Epoch: 414, Iter: 87100, Loss: 1.049, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 19:41:13,162: INFO: Epoch: 415, Iter: 87150, Loss: 0.982, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 19:42:21,284: INFO: Epoch: 415, Iter: 87200, Loss: 0.839, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:43:29,738: INFO: Epoch: 415, Iter: 87250, Loss: 0.647, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:44:38,190: INFO: Epoch: 415, Iter: 87300, Loss: 0.553, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:45:46,391: INFO: Epoch: 415, Iter: 87350, Loss: 1.606, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 19:46:54,710: INFO: Epoch: 416, Iter: 87400, Loss: 1.421, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 19:48:03,111: INFO: Epoch: 416, Iter: 87450, Loss: 0.690, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:49:11,423: INFO: Epoch: 416, Iter: 87500, Loss: 0.667, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:50:19,128: INFO: Epoch: 416, Iter: 87550, Loss: 1.208, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 19:51:27,146: INFO: Epoch: 417, Iter: 87600, Loss: 1.427, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 19:52:35,903: INFO: Epoch: 417, Iter: 87650, Loss: 0.991, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:53:44,043: INFO: Epoch: 417, Iter: 87700, Loss: 1.216, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 19:54:52,653: INFO: Epoch: 417, Iter: 87750, Loss: 1.126, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 19:56:00,879: INFO: Epoch: 418, Iter: 87800, Loss: 1.467, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 19:57:08,743: INFO: Epoch: 418, Iter: 87850, Loss: 1.047, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 19:58:17,364: INFO: Epoch: 418, Iter: 87900, Loss: 0.773, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 19:59:24,221: INFO: Epoch: 418, Iter: 87950, Loss: 1.050, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 20:00:31,019: INFO: Epoch: 419, Iter: 88000, Loss: 1.926, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 20:01:38,078: INFO: Epoch: 419, Iter: 88050, Loss: 1.688, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 20:02:44,959: INFO: Epoch: 419, Iter: 88100, Loss: 1.438, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 20:03:52,038: INFO: Epoch: 419, Iter: 88150, Loss: 0.755, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:04:59,227: INFO: Epoch: 420, Iter: 88200, Loss: 0.705, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:06:05,776: INFO: Epoch: 420, Iter: 88250, Loss: 0.596, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:07:12,392: INFO: Epoch: 420, Iter: 88300, Loss: 1.344, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 20:08:19,558: INFO: Epoch: 420, Iter: 88350, Loss: 0.646, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:09:25,523: INFO: Epoch: 420, Iter: 88400, Loss: 1.541, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 20:10:31,956: INFO: Epoch: 421, Iter: 88450, Loss: 1.434, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 20:11:38,811: INFO: Epoch: 421, Iter: 88500, Loss: 0.843, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:12:45,395: INFO: Epoch: 421, Iter: 88550, Loss: 0.860, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:13:52,144: INFO: Epoch: 421, Iter: 88600, Loss: 0.784, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:14:59,416: INFO: Epoch: 422, Iter: 88650, Loss: 0.809, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:16:06,120: INFO: Epoch: 422, Iter: 88700, Loss: 0.825, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:17:12,965: INFO: Epoch: 422, Iter: 88750, Loss: 0.742, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:18:20,175: INFO: Epoch: 422, Iter: 88800, Loss: 1.336, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 20:19:26,638: INFO: Epoch: 423, Iter: 88850, Loss: 0.693, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:20:33,079: INFO: Epoch: 423, Iter: 88900, Loss: 0.643, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:21:39,873: INFO: Epoch: 423, Iter: 88950, Loss: 1.350, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 20:22:47,244: INFO: Epoch: 423, Iter: 89000, Loss: 0.660, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:23:54,253: INFO: Epoch: 424, Iter: 89050, Loss: 1.530, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 20:25:01,044: INFO: Epoch: 424, Iter: 89100, Loss: 0.754, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:26:07,243: INFO: Epoch: 424, Iter: 89150, Loss: 0.828, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:27:13,739: INFO: Epoch: 424, Iter: 89200, Loss: 1.138, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 20:28:20,261: INFO: Epoch: 425, Iter: 89250, Loss: 0.988, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 20:29:27,066: INFO: Epoch: 425, Iter: 89300, Loss: 0.835, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:30:33,728: INFO: Epoch: 425, Iter: 89350, Loss: 1.032, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 20:31:40,068: INFO: Epoch: 425, Iter: 89400, Loss: 0.917, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:32:46,185: INFO: Epoch: 425, Iter: 89450, Loss: 0.647, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:33:53,071: INFO: Epoch: 426, Iter: 89500, Loss: 0.616, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:34:59,233: INFO: Epoch: 426, Iter: 89550, Loss: 0.641, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:36:05,594: INFO: Epoch: 426, Iter: 89600, Loss: 1.678, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 20:37:12,359: INFO: Epoch: 426, Iter: 89650, Loss: 0.747, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:38:19,072: INFO: Epoch: 427, Iter: 89700, Loss: 0.756, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:39:25,789: INFO: Epoch: 427, Iter: 89750, Loss: 0.822, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:40:32,211: INFO: Epoch: 427, Iter: 89800, Loss: 0.852, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:41:38,582: INFO: Epoch: 427, Iter: 89850, Loss: 1.289, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 20:42:45,784: INFO: Epoch: 428, Iter: 89900, Loss: 1.246, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 20:43:52,942: INFO: Epoch: 428, Iter: 89950, Loss: 1.728, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 20:44:59,324: INFO: Epoch: 428, Iter: 90000, Loss: 1.361, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 20:46:05,925: INFO: Epoch: 428, Iter: 90050, Loss: 0.713, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:47:12,953: INFO: Epoch: 429, Iter: 90100, Loss: 1.695, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 20:48:20,071: INFO: Epoch: 429, Iter: 90150, Loss: 1.014, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 20:49:26,677: INFO: Epoch: 429, Iter: 90200, Loss: 1.783, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 20:50:33,451: INFO: Epoch: 429, Iter: 90250, Loss: 0.839, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:51:40,297: INFO: Epoch: 430, Iter: 90300, Loss: 0.938, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 20:52:47,318: INFO: Epoch: 430, Iter: 90350, Loss: 0.951, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:53:53,990: INFO: Epoch: 430, Iter: 90400, Loss: 1.600, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 20:55:01,185: INFO: Epoch: 430, Iter: 90450, Loss: 1.629, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 20:56:07,957: INFO: Epoch: 430, Iter: 90500, Loss: 0.641, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:57:14,854: INFO: Epoch: 431, Iter: 90550, Loss: 1.510, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 20:58:21,882: INFO: Epoch: 431, Iter: 90600, Loss: 0.796, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 20:59:28,513: INFO: Epoch: 431, Iter: 90650, Loss: 0.716, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 21:00:35,432: INFO: Epoch: 431, Iter: 90700, Loss: 0.669, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 21:01:41,990: INFO: Epoch: 432, Iter: 90750, Loss: 2.246, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:02:48,220: INFO: Epoch: 432, Iter: 90800, Loss: 0.751, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 21:03:54,922: INFO: Epoch: 432, Iter: 90850, Loss: 0.799, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 21:05:02,233: INFO: Epoch: 432, Iter: 90900, Loss: 1.344, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:06:09,743: INFO: Epoch: 433, Iter: 90950, Loss: 1.412, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:07:16,132: INFO: Epoch: 433, Iter: 91000, Loss: 0.926, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 21:08:22,902: INFO: Epoch: 433, Iter: 91050, Loss: 0.844, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 21:09:29,399: INFO: Epoch: 433, Iter: 91100, Loss: 0.888, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 21:10:35,762: INFO: Epoch: 434, Iter: 91150, Loss: 1.380, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:11:42,794: INFO: Epoch: 434, Iter: 91200, Loss: 0.608, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 21:12:49,883: INFO: Epoch: 434, Iter: 91250, Loss: 0.403, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 21:13:56,527: INFO: Epoch: 434, Iter: 91300, Loss: 0.625, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 21:15:03,686: INFO: Epoch: 435, Iter: 91350, Loss: 1.136, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:16:10,581: INFO: Epoch: 435, Iter: 91400, Loss: 0.574, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 21:17:17,583: INFO: Epoch: 435, Iter: 91450, Loss: 1.443, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:18:25,332: INFO: Epoch: 435, Iter: 91500, Loss: 1.137, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:19:32,402: INFO: Epoch: 435, Iter: 91550, Loss: 0.735, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 21:20:39,555: INFO: Epoch: 436, Iter: 91600, Loss: 0.270, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 21:21:46,724: INFO: Epoch: 436, Iter: 91650, Loss: 1.227, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:22:53,993: INFO: Epoch: 436, Iter: 91700, Loss: 1.059, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:24:00,983: INFO: Epoch: 436, Iter: 91750, Loss: 0.935, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:25:08,147: INFO: Epoch: 437, Iter: 91800, Loss: 0.261, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 21:26:16,030: INFO: Epoch: 437, Iter: 91850, Loss: 1.195, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:27:22,270: INFO: Epoch: 437, Iter: 91900, Loss: 1.032, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:28:29,729: INFO: Epoch: 437, Iter: 91950, Loss: 1.179, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:29:36,249: INFO: Epoch: 438, Iter: 92000, Loss: 0.997, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 21:30:42,853: INFO: Epoch: 438, Iter: 92050, Loss: 0.939, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 21:31:49,560: INFO: Epoch: 438, Iter: 92100, Loss: 0.630, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 21:32:56,560: INFO: Epoch: 438, Iter: 92150, Loss: 1.198, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:34:03,096: INFO: Epoch: 439, Iter: 92200, Loss: 1.134, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:35:09,730: INFO: Epoch: 439, Iter: 92250, Loss: 2.061, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:36:16,282: INFO: Epoch: 439, Iter: 92300, Loss: 1.184, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:37:23,048: INFO: Epoch: 439, Iter: 92350, Loss: 1.349, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:38:30,175: INFO: Epoch: 440, Iter: 92400, Loss: 1.158, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:39:36,701: INFO: Epoch: 440, Iter: 92450, Loss: 0.792, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 21:40:43,463: INFO: Epoch: 440, Iter: 92500, Loss: 0.992, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 21:41:50,080: INFO: Epoch: 440, Iter: 92550, Loss: 0.938, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 21:42:56,918: INFO: Epoch: 440, Iter: 92600, Loss: 8.371, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:44:03,343: INFO: Epoch: 441, Iter: 92650, Loss: 0.699, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 21:45:10,318: INFO: Epoch: 441, Iter: 92700, Loss: 1.292, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:46:16,660: INFO: Epoch: 441, Iter: 92750, Loss: 1.480, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:47:23,023: INFO: Epoch: 441, Iter: 92800, Loss: 1.974, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:48:29,777: INFO: Epoch: 442, Iter: 92850, Loss: 1.201, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:49:36,003: INFO: Epoch: 442, Iter: 92900, Loss: 1.127, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:50:41,698: INFO: Epoch: 442, Iter: 92950, Loss: 1.510, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:51:48,626: INFO: Epoch: 442, Iter: 93000, Loss: 0.820, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 21:52:55,493: INFO: Epoch: 443, Iter: 93050, Loss: 1.512, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:54:02,642: INFO: Epoch: 443, Iter: 93100, Loss: 1.394, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:55:09,167: INFO: Epoch: 443, Iter: 93150, Loss: 0.908, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:56:15,570: INFO: Epoch: 443, Iter: 93200, Loss: 0.863, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:57:22,433: INFO: Epoch: 444, Iter: 93250, Loss: 0.965, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 21:58:28,863: INFO: Epoch: 444, Iter: 93300, Loss: 0.626, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 21:59:35,786: INFO: Epoch: 444, Iter: 93350, Loss: 0.553, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:00:42,674: INFO: Epoch: 444, Iter: 93400, Loss: 1.375, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 22:01:48,861: INFO: Epoch: 445, Iter: 93450, Loss: 0.906, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:02:56,735: INFO: Epoch: 445, Iter: 93500, Loss: 0.897, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:04:03,712: INFO: Epoch: 445, Iter: 93550, Loss: 1.055, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:05:10,278: INFO: Epoch: 445, Iter: 93600, Loss: 1.145, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 22:06:17,121: INFO: Epoch: 445, Iter: 93650, Loss: 1.129, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 22:07:23,499: INFO: Epoch: 446, Iter: 93700, Loss: 1.314, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 22:08:30,539: INFO: Epoch: 446, Iter: 93750, Loss: 1.451, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 22:09:37,369: INFO: Epoch: 446, Iter: 93800, Loss: 0.430, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:10:43,910: INFO: Epoch: 446, Iter: 93850, Loss: 0.753, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:11:50,701: INFO: Epoch: 447, Iter: 93900, Loss: 0.759, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:12:58,666: INFO: Epoch: 447, Iter: 93950, Loss: 1.381, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 22:14:05,537: INFO: Epoch: 447, Iter: 94000, Loss: 1.036, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:15:11,753: INFO: Epoch: 447, Iter: 94050, Loss: 1.725, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 22:16:18,432: INFO: Epoch: 448, Iter: 94100, Loss: 1.426, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 22:17:25,430: INFO: Epoch: 448, Iter: 94150, Loss: 1.238, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 22:18:32,427: INFO: Epoch: 448, Iter: 94200, Loss: 1.144, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 22:19:38,446: INFO: Epoch: 448, Iter: 94250, Loss: 0.784, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:20:45,431: INFO: Epoch: 449, Iter: 94300, Loss: 0.468, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:21:52,568: INFO: Epoch: 449, Iter: 94350, Loss: 0.445, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:22:59,667: INFO: Epoch: 449, Iter: 94400, Loss: 2.071, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 22:24:05,958: INFO: Epoch: 449, Iter: 94450, Loss: 0.555, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:25:11,940: INFO: Epoch: 450, Iter: 94500, Loss: 0.591, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:26:18,777: INFO: Epoch: 450, Iter: 94550, Loss: 0.571, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:27:24,902: INFO: Epoch: 450, Iter: 94600, Loss: 0.595, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:28:32,578: INFO: Epoch: 450, Iter: 94650, Loss: 0.649, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:29:38,958: INFO: Epoch: 450, Iter: 94700, Loss: 0.786, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:30:45,426: INFO: Epoch: 451, Iter: 94750, Loss: 1.680, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 22:31:52,133: INFO: Epoch: 451, Iter: 94800, Loss: 0.365, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:32:58,840: INFO: Epoch: 451, Iter: 94850, Loss: 0.513, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:34:05,660: INFO: Epoch: 451, Iter: 94900, Loss: 2.199, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 22:35:12,416: INFO: Epoch: 452, Iter: 94950, Loss: 0.717, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:36:19,208: INFO: Epoch: 452, Iter: 95000, Loss: 1.424, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 22:37:26,004: INFO: Epoch: 452, Iter: 95050, Loss: 1.263, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 22:38:33,252: INFO: Epoch: 452, Iter: 95100, Loss: 1.377, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 22:39:40,125: INFO: Epoch: 453, Iter: 95150, Loss: 0.784, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:40:46,704: INFO: Epoch: 453, Iter: 95200, Loss: 1.192, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 22:41:53,551: INFO: Epoch: 453, Iter: 95250, Loss: 0.607, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:43:00,556: INFO: Epoch: 453, Iter: 95300, Loss: 0.513, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:44:07,104: INFO: Epoch: 454, Iter: 95350, Loss: 1.652, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 22:45:13,713: INFO: Epoch: 454, Iter: 95400, Loss: 1.593, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 22:46:20,893: INFO: Epoch: 454, Iter: 95450, Loss: 2.334, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 22:47:27,311: INFO: Epoch: 454, Iter: 95500, Loss: 0.960, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:48:34,212: INFO: Epoch: 455, Iter: 95550, Loss: 1.160, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 22:49:41,104: INFO: Epoch: 455, Iter: 95600, Loss: 0.871, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:50:47,879: INFO: Epoch: 455, Iter: 95650, Loss: 0.830, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 22:51:55,431: INFO: Epoch: 455, Iter: 95700, Loss: 0.872, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:53:02,089: INFO: Epoch: 455, Iter: 95750, Loss: 0.903, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:54:08,894: INFO: Epoch: 456, Iter: 95800, Loss: 0.892, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:55:15,007: INFO: Epoch: 456, Iter: 95850, Loss: 1.333, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 22:56:21,875: INFO: Epoch: 456, Iter: 95900, Loss: 1.331, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 22:57:28,440: INFO: Epoch: 456, Iter: 95950, Loss: 0.872, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:58:35,096: INFO: Epoch: 457, Iter: 96000, Loss: 0.827, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 22:59:41,424: INFO: Epoch: 457, Iter: 96050, Loss: 1.349, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:00:47,586: INFO: Epoch: 457, Iter: 96100, Loss: 0.790, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 23:01:54,191: INFO: Epoch: 457, Iter: 96150, Loss: 1.270, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:03:00,871: INFO: Epoch: 458, Iter: 96200, Loss: 1.432, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:04:07,497: INFO: Epoch: 458, Iter: 96250, Loss: 1.394, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:05:13,341: INFO: Epoch: 458, Iter: 96300, Loss: 1.281, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:06:19,682: INFO: Epoch: 458, Iter: 96350, Loss: 1.173, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:07:26,264: INFO: Epoch: 459, Iter: 96400, Loss: 1.121, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:08:33,204: INFO: Epoch: 459, Iter: 96450, Loss: 1.039, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:09:39,850: INFO: Epoch: 459, Iter: 96500, Loss: 1.016, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:10:46,594: INFO: Epoch: 459, Iter: 96550, Loss: 1.381, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:11:53,573: INFO: Epoch: 460, Iter: 96600, Loss: 1.209, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:13:00,286: INFO: Epoch: 460, Iter: 96650, Loss: 2.295, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:14:06,927: INFO: Epoch: 460, Iter: 96700, Loss: 1.411, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:15:14,164: INFO: Epoch: 460, Iter: 96750, Loss: 1.243, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:16:20,440: INFO: Epoch: 460, Iter: 96800, Loss: 1.241, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:17:27,161: INFO: Epoch: 461, Iter: 96850, Loss: 0.922, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 23:18:33,737: INFO: Epoch: 461, Iter: 96900, Loss: 0.813, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 23:19:43,593: INFO: Epoch: 461, Iter: 96950, Loss: 1.010, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:20:50,604: INFO: Epoch: 461, Iter: 97000, Loss: 1.016, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:21:57,334: INFO: Epoch: 462, Iter: 97050, Loss: 0.990, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:23:03,934: INFO: Epoch: 462, Iter: 97100, Loss: 0.979, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:24:10,938: INFO: Epoch: 462, Iter: 97150, Loss: 0.857, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 23:25:17,731: INFO: Epoch: 462, Iter: 97200, Loss: 0.737, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 23:26:25,271: INFO: Epoch: 463, Iter: 97250, Loss: 1.195, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:27:33,673: INFO: Epoch: 463, Iter: 97300, Loss: 0.673, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 23:28:40,768: INFO: Epoch: 463, Iter: 97350, Loss: 1.448, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:29:47,578: INFO: Epoch: 463, Iter: 97400, Loss: 0.793, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 23:30:55,850: INFO: Epoch: 464, Iter: 97450, Loss: 2.271, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:32:04,177: INFO: Epoch: 464, Iter: 97500, Loss: 0.468, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 23:33:12,621: INFO: Epoch: 464, Iter: 97550, Loss: 0.954, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 23:34:20,856: INFO: Epoch: 464, Iter: 97600, Loss: 0.463, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 23:35:33,689: INFO: Epoch: 465, Iter: 97650, Loss: 0.911, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 23:36:10,836: INFO: Keyboard Interrupt? Gracefully quitting
2017-10-31 23:36:10,837: INFO: The training is done.

2017-10-31 23:38:17,926: INFO: *** NEW RUN ***
2017-10-31 23:38:17,927: INFO: filename: trained_model_2017.10.31-23.38.17
2017-10-31 23:38:17,927: INFO: n_epochs: 1
2017-10-31 23:38:17,927: INFO: n_hidden: 32
2017-10-31 23:38:17,927: INFO: batch_size: 5
2017-10-31 23:38:17,928: INFO: n_layers: 3
2017-10-31 23:38:17,928: INFO: Normalization: False
2017-10-31 23:38:17,928: INFO: exp_decay_enabled: False
2017-10-31 23:38:17,928: INFO: static_lr_val: 0.050
2017-10-31 23:38:17,928: INFO: Reg Type: Dropout
2017-10-31 23:38:17,928: INFO:   Dropout Prob: 0.50
2017-10-31 23:38:17,929: INFO:   Beta: 0.010

2017-10-31 23:38:22,570: INFO: The training shall begin.
2017-10-31 23:38:34,649: INFO: Epoch: 0, Iter: 0, Loss: 1.009, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:40:02,733: INFO: Epoch: 0, Iter: 50, Loss: 0.324, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 23:41:30,894: INFO: Epoch: 0, Iter: 100, Loss: 0.030, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 23:42:56,695: INFO: Epoch: 0, Iter: 150, Loss: 0.701, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 23:44:17,508: INFO: Epoch: 0, Iter: 200, Loss: 0.941, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:45:39,562: INFO: Epoch: 1, Iter: 250, Loss: 3.682, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:47:02,967: INFO: Epoch: 1, Iter: 300, Loss: 2.923, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:48:14,312: INFO: Epoch: 1, Iter: 350, Loss: 4.888, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:49:23,410: INFO: Epoch: 1, Iter: 400, Loss: 0.605, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 23:50:34,938: INFO: Epoch: 2, Iter: 450, Loss: 0.889, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:51:49,279: INFO: Epoch: 2, Iter: 500, Loss: 0.090, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 23:52:59,678: INFO: Epoch: 2, Iter: 550, Loss: 2.312, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:54:06,784: INFO: Epoch: 2, Iter: 600, Loss: 0.787, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 23:55:14,287: INFO: Epoch: 3, Iter: 650, Loss: 1.829, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:56:22,617: INFO: Epoch: 3, Iter: 700, Loss: 0.961, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:57:30,217: INFO: Epoch: 3, Iter: 750, Loss: 3.095, Accuracy: 0.000, Learning Rate: 0.050
2017-10-31 23:58:37,745: INFO: Epoch: 3, Iter: 800, Loss: 0.803, Accuracy: 1.000, Learning Rate: 0.050
2017-10-31 23:59:45,188: INFO: Epoch: 4, Iter: 850, Loss: 0.692, Accuracy: 1.000, Learning Rate: 0.050
2017-11-01 00:00:52,960: INFO: Epoch: 4, Iter: 900, Loss: 0.558, Accuracy: 1.000, Learning Rate: 0.050
2017-11-01 00:02:00,356: INFO: Epoch: 4, Iter: 950, Loss: 1.235, Accuracy: 0.000, Learning Rate: 0.050
2017-11-01 00:03:07,668: INFO: Epoch: 4, Iter: 1000, Loss: 1.349, Accuracy: 0.000, Learning Rate: 0.050
2017-11-01 00:04:06,846: INFO: Cycled through epochs 1 times
2017-11-01 00:04:06,846: INFO: The training is done.

2017-11-02 01:32:21,768: INFO: *** NEW RUN ***
2017-11-02 01:32:21,770: INFO: filename: trained_model_2017.11.02-01.32.21
2017-11-02 01:32:21,770: INFO: n_epochs: 250
2017-11-02 01:32:21,770: INFO: n_hidden: 40
2017-11-02 01:32:21,771: INFO: batch_size: 10
2017-11-02 01:32:21,771: INFO: n_layers: 5
2017-11-02 01:32:21,771: INFO: Normalization: False
2017-11-02 01:32:21,771: INFO: exp_decay_enabled: False
2017-11-02 01:32:21,771: INFO: static_lr_val: 0.050
2017-11-02 01:32:21,771: INFO: Reg Type: Dropout
2017-11-02 01:32:21,771: INFO:   Dropout Prob: 0.50
2017-11-02 01:32:21,772: INFO:   Beta: 0.010

2017-11-02 01:32:27,783: INFO: The training shall begin.
2017-11-02 01:32:41,322: INFO: Epoch: 0, Iter: 0, Loss: 0.740, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 01:34:36,058: INFO: Epoch: 0, Iter: 100, Loss: 7.347, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 01:36:27,097: INFO: Epoch: 0, Iter: 200, Loss: 18.377, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 01:38:17,167: INFO: Epoch: 1, Iter: 300, Loss: 2.890, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 01:40:07,424: INFO: Epoch: 1, Iter: 400, Loss: 14.833, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 01:41:58,786: INFO: Epoch: 2, Iter: 500, Loss: 10.799, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 01:43:50,213: INFO: Epoch: 2, Iter: 600, Loss: 0.436, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 01:45:48,771: INFO: Epoch: 3, Iter: 700, Loss: 0.021, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 01:47:58,091: INFO: Epoch: 3, Iter: 800, Loss: 0.007, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 01:50:02,090: INFO: Epoch: 4, Iter: 900, Loss: 1.356, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 01:52:04,021: INFO: Epoch: 4, Iter: 1000, Loss: 1.855, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 01:54:06,177: INFO: Epoch: 5, Iter: 1100, Loss: 3.055, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 01:56:07,880: INFO: Epoch: 5, Iter: 1200, Loss: 0.180, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 01:58:09,301: INFO: Epoch: 6, Iter: 1300, Loss: 3.938, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 02:00:10,719: INFO: Epoch: 6, Iter: 1400, Loss: 0.928, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 02:02:12,186: INFO: Epoch: 7, Iter: 1500, Loss: 0.717, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 02:04:07,679: INFO: Epoch: 7, Iter: 1600, Loss: 0.185, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 02:05:58,519: INFO: Epoch: 8, Iter: 1700, Loss: 0.984, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 02:07:49,125: INFO: Epoch: 8, Iter: 1800, Loss: 2.420, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 02:09:39,183: INFO: Epoch: 9, Iter: 1900, Loss: 0.967, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 02:11:29,790: INFO: Epoch: 9, Iter: 2000, Loss: 0.405, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 02:13:20,985: INFO: Epoch: 10, Iter: 2100, Loss: 1.693, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 02:15:14,776: INFO: Epoch: 10, Iter: 2200, Loss: 0.531, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 02:17:10,065: INFO: Epoch: 10, Iter: 2300, Loss: 0.295, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 02:19:05,740: INFO: Epoch: 11, Iter: 2400, Loss: 2.082, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 02:21:00,897: INFO: Epoch: 11, Iter: 2500, Loss: 0.498, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 02:22:56,761: INFO: Epoch: 12, Iter: 2600, Loss: 0.545, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 02:24:49,362: INFO: Epoch: 12, Iter: 2700, Loss: 3.854, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 02:26:40,289: INFO: Epoch: 13, Iter: 2800, Loss: 0.547, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 02:28:31,530: INFO: Epoch: 13, Iter: 2900, Loss: 0.746, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 02:30:22,614: INFO: Epoch: 14, Iter: 3000, Loss: 0.062, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 02:32:13,424: INFO: Epoch: 14, Iter: 3100, Loss: 1.070, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 02:34:04,427: INFO: Epoch: 15, Iter: 3200, Loss: 0.637, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 02:35:54,791: INFO: Epoch: 15, Iter: 3300, Loss: 0.575, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 02:37:45,441: INFO: Epoch: 16, Iter: 3400, Loss: 0.263, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 02:39:36,308: INFO: Epoch: 16, Iter: 3500, Loss: 0.160, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 02:41:26,792: INFO: Epoch: 17, Iter: 3600, Loss: 0.703, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 02:43:19,153: INFO: Epoch: 17, Iter: 3700, Loss: 1.091, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 02:45:10,081: INFO: Epoch: 18, Iter: 3800, Loss: 0.246, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 02:47:00,904: INFO: Epoch: 18, Iter: 3900, Loss: 3.449, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 02:48:52,026: INFO: Epoch: 19, Iter: 4000, Loss: 0.572, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 02:50:42,961: INFO: Epoch: 19, Iter: 4100, Loss: 1.593, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 02:52:33,684: INFO: Epoch: 20, Iter: 4200, Loss: 1.869, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 02:54:24,611: INFO: Epoch: 20, Iter: 4300, Loss: 6.068, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 02:56:14,786: INFO: Epoch: 20, Iter: 4400, Loss: 1.705, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 02:58:06,418: INFO: Epoch: 21, Iter: 4500, Loss: 0.789, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 02:59:57,250: INFO: Epoch: 21, Iter: 4600, Loss: 2.657, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 03:01:48,165: INFO: Epoch: 22, Iter: 4700, Loss: 1.446, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 03:03:39,675: INFO: Epoch: 22, Iter: 4800, Loss: 1.476, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 03:05:30,487: INFO: Epoch: 23, Iter: 4900, Loss: 0.782, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 03:07:21,106: INFO: Epoch: 23, Iter: 5000, Loss: 3.460, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 03:09:12,237: INFO: Epoch: 24, Iter: 5100, Loss: 1.200, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 03:11:03,170: INFO: Epoch: 24, Iter: 5200, Loss: 2.617, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 03:12:54,446: INFO: Epoch: 25, Iter: 5300, Loss: 1.742, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 03:14:45,038: INFO: Epoch: 25, Iter: 5400, Loss: 0.259, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 03:16:35,707: INFO: Epoch: 26, Iter: 5500, Loss: 2.156, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 03:18:26,172: INFO: Epoch: 26, Iter: 5600, Loss: 2.506, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 03:20:17,240: INFO: Epoch: 27, Iter: 5700, Loss: 3.088, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 03:22:08,228: INFO: Epoch: 27, Iter: 5800, Loss: 1.317, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 03:23:59,729: INFO: Epoch: 28, Iter: 5900, Loss: 0.749, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 03:25:50,484: INFO: Epoch: 28, Iter: 6000, Loss: 0.498, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 03:27:41,366: INFO: Epoch: 29, Iter: 6100, Loss: 0.914, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 03:29:32,686: INFO: Epoch: 29, Iter: 6200, Loss: 1.429, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 03:31:23,500: INFO: Epoch: 30, Iter: 6300, Loss: 1.662, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 03:33:14,917: INFO: Epoch: 30, Iter: 6400, Loss: 0.230, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 03:35:05,994: INFO: Epoch: 30, Iter: 6500, Loss: 2.306, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 03:36:56,459: INFO: Epoch: 31, Iter: 6600, Loss: 0.729, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 03:38:47,567: INFO: Epoch: 31, Iter: 6700, Loss: 0.683, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 03:40:37,837: INFO: Epoch: 32, Iter: 6800, Loss: 0.540, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 03:42:28,770: INFO: Epoch: 32, Iter: 6900, Loss: 1.815, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 03:44:20,542: INFO: Epoch: 33, Iter: 7000, Loss: 3.136, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 03:46:11,117: INFO: Epoch: 33, Iter: 7100, Loss: 0.667, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 03:48:01,985: INFO: Epoch: 34, Iter: 7200, Loss: 1.439, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 03:49:52,479: INFO: Epoch: 34, Iter: 7300, Loss: 4.110, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 03:51:43,522: INFO: Epoch: 35, Iter: 7400, Loss: 1.555, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 03:53:34,578: INFO: Epoch: 35, Iter: 7500, Loss: 1.225, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 03:55:25,029: INFO: Epoch: 36, Iter: 7600, Loss: 1.689, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 03:57:15,414: INFO: Epoch: 36, Iter: 7700, Loss: 2.087, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 03:59:06,407: INFO: Epoch: 37, Iter: 7800, Loss: 1.549, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 04:00:56,961: INFO: Epoch: 37, Iter: 7900, Loss: 0.203, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 04:02:47,660: INFO: Epoch: 38, Iter: 8000, Loss: 2.827, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 04:04:39,249: INFO: Epoch: 38, Iter: 8100, Loss: 2.546, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 04:06:29,932: INFO: Epoch: 39, Iter: 8200, Loss: 0.021, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 04:08:20,747: INFO: Epoch: 39, Iter: 8300, Loss: 0.111, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 04:10:11,474: INFO: Epoch: 40, Iter: 8400, Loss: 0.285, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 04:12:02,616: INFO: Epoch: 40, Iter: 8500, Loss: 2.612, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 04:13:53,237: INFO: Epoch: 40, Iter: 8600, Loss: 0.389, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 04:15:43,809: INFO: Epoch: 41, Iter: 8700, Loss: 1.690, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 04:17:34,679: INFO: Epoch: 41, Iter: 8800, Loss: 0.694, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 04:19:25,590: INFO: Epoch: 42, Iter: 8900, Loss: 5.215, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 04:21:16,044: INFO: Epoch: 42, Iter: 9000, Loss: 1.459, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 04:23:07,650: INFO: Epoch: 43, Iter: 9100, Loss: 1.456, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 04:24:57,799: INFO: Epoch: 43, Iter: 9200, Loss: 2.690, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 04:26:48,317: INFO: Epoch: 44, Iter: 9300, Loss: 0.630, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 04:28:39,361: INFO: Epoch: 44, Iter: 9400, Loss: 2.302, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 04:30:30,275: INFO: Epoch: 45, Iter: 9500, Loss: 0.984, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 04:32:21,759: INFO: Epoch: 45, Iter: 9600, Loss: 1.360, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 04:34:12,500: INFO: Epoch: 46, Iter: 9700, Loss: 1.569, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 04:36:03,640: INFO: Epoch: 46, Iter: 9800, Loss: 1.009, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 04:37:54,316: INFO: Epoch: 47, Iter: 9900, Loss: 0.243, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 04:39:44,798: INFO: Epoch: 47, Iter: 10000, Loss: 1.240, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 04:41:35,289: INFO: Epoch: 48, Iter: 10100, Loss: 1.465, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 04:43:26,559: INFO: Epoch: 48, Iter: 10200, Loss: 0.813, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 04:45:17,397: INFO: Epoch: 49, Iter: 10300, Loss: 1.270, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 04:47:08,515: INFO: Epoch: 49, Iter: 10400, Loss: 0.170, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 04:48:59,976: INFO: Epoch: 50, Iter: 10500, Loss: 0.048, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 04:50:52,516: INFO: Epoch: 50, Iter: 10600, Loss: 1.305, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 04:52:44,446: INFO: Epoch: 50, Iter: 10700, Loss: 1.441, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 04:54:35,000: INFO: Epoch: 51, Iter: 10800, Loss: 0.689, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 04:56:25,351: INFO: Epoch: 51, Iter: 10900, Loss: 0.765, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 04:58:16,226: INFO: Epoch: 52, Iter: 11000, Loss: 1.152, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 05:00:07,280: INFO: Epoch: 52, Iter: 11100, Loss: 0.406, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 05:01:57,736: INFO: Epoch: 53, Iter: 11200, Loss: 1.279, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 05:03:48,769: INFO: Epoch: 53, Iter: 11300, Loss: 1.425, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 05:05:39,268: INFO: Epoch: 54, Iter: 11400, Loss: 2.010, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 05:07:29,747: INFO: Epoch: 54, Iter: 11500, Loss: 1.069, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 05:09:20,352: INFO: Epoch: 55, Iter: 11600, Loss: 1.056, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 05:11:11,329: INFO: Epoch: 55, Iter: 11700, Loss: 0.438, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 05:13:02,591: INFO: Epoch: 56, Iter: 11800, Loss: 0.930, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 05:14:53,462: INFO: Epoch: 56, Iter: 11900, Loss: 2.357, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 05:16:44,031: INFO: Epoch: 57, Iter: 12000, Loss: 0.515, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 05:18:34,861: INFO: Epoch: 57, Iter: 12100, Loss: 1.239, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 05:20:25,419: INFO: Epoch: 58, Iter: 12200, Loss: 1.282, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 05:22:16,316: INFO: Epoch: 58, Iter: 12300, Loss: 1.279, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 05:24:07,286: INFO: Epoch: 59, Iter: 12400, Loss: 3.450, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 05:25:57,816: INFO: Epoch: 59, Iter: 12500, Loss: 0.425, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 05:27:48,579: INFO: Epoch: 60, Iter: 12600, Loss: 1.020, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 05:29:39,464: INFO: Epoch: 60, Iter: 12700, Loss: 0.624, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 05:31:30,209: INFO: Epoch: 60, Iter: 12800, Loss: 1.977, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 05:33:21,075: INFO: Epoch: 61, Iter: 12900, Loss: 2.014, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 05:35:11,881: INFO: Epoch: 61, Iter: 13000, Loss: 0.455, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 05:37:02,529: INFO: Epoch: 62, Iter: 13100, Loss: 1.377, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 05:38:53,014: INFO: Epoch: 62, Iter: 13200, Loss: 0.856, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 05:40:44,017: INFO: Epoch: 63, Iter: 13300, Loss: 0.568, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 05:42:34,743: INFO: Epoch: 63, Iter: 13400, Loss: 0.653, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 05:44:25,574: INFO: Epoch: 64, Iter: 13500, Loss: 0.508, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 05:46:16,220: INFO: Epoch: 64, Iter: 13600, Loss: 2.248, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 05:48:08,339: INFO: Epoch: 65, Iter: 13700, Loss: 0.419, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 05:49:58,845: INFO: Epoch: 65, Iter: 13800, Loss: 1.090, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 05:51:49,572: INFO: Epoch: 66, Iter: 13900, Loss: 0.491, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 05:53:40,734: INFO: Epoch: 66, Iter: 14000, Loss: 0.262, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 05:55:30,958: INFO: Epoch: 67, Iter: 14100, Loss: 1.082, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 05:57:21,668: INFO: Epoch: 67, Iter: 14200, Loss: 0.719, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 05:59:12,696: INFO: Epoch: 68, Iter: 14300, Loss: 1.943, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 06:01:03,132: INFO: Epoch: 68, Iter: 14400, Loss: 0.662, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 06:02:54,734: INFO: Epoch: 69, Iter: 14500, Loss: 1.538, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 06:04:45,536: INFO: Epoch: 69, Iter: 14600, Loss: 0.245, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 06:06:36,245: INFO: Epoch: 70, Iter: 14700, Loss: 1.691, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 06:08:27,201: INFO: Epoch: 70, Iter: 14800, Loss: 0.325, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 06:10:18,195: INFO: Epoch: 70, Iter: 14900, Loss: 0.877, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 06:12:09,573: INFO: Epoch: 71, Iter: 15000, Loss: 2.132, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 06:14:00,730: INFO: Epoch: 71, Iter: 15100, Loss: 0.831, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 06:15:51,178: INFO: Epoch: 72, Iter: 15200, Loss: 1.122, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 06:17:41,825: INFO: Epoch: 72, Iter: 15300, Loss: 0.790, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 06:19:32,476: INFO: Epoch: 73, Iter: 15400, Loss: 2.157, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 06:21:23,624: INFO: Epoch: 73, Iter: 15500, Loss: 0.925, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 06:23:14,997: INFO: Epoch: 74, Iter: 15600, Loss: 0.080, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 06:25:06,086: INFO: Epoch: 74, Iter: 15700, Loss: 1.229, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 06:26:56,541: INFO: Epoch: 75, Iter: 15800, Loss: 1.029, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 06:28:47,567: INFO: Epoch: 75, Iter: 15900, Loss: 0.397, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 06:30:37,968: INFO: Epoch: 76, Iter: 16000, Loss: 2.971, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 06:32:29,042: INFO: Epoch: 76, Iter: 16100, Loss: 1.957, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 06:34:19,801: INFO: Epoch: 77, Iter: 16200, Loss: 1.322, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 06:36:11,060: INFO: Epoch: 77, Iter: 16300, Loss: 1.132, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 06:38:01,501: INFO: Epoch: 78, Iter: 16400, Loss: 1.632, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 06:39:52,156: INFO: Epoch: 78, Iter: 16500, Loss: 0.690, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 06:41:42,852: INFO: Epoch: 79, Iter: 16600, Loss: 1.307, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 06:43:34,018: INFO: Epoch: 79, Iter: 16700, Loss: 1.428, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 06:45:24,909: INFO: Epoch: 80, Iter: 16800, Loss: 0.556, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 06:47:15,591: INFO: Epoch: 80, Iter: 16900, Loss: 0.324, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 06:49:06,682: INFO: Epoch: 80, Iter: 17000, Loss: 2.383, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 06:50:57,891: INFO: Epoch: 81, Iter: 17100, Loss: 0.955, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 06:52:48,420: INFO: Epoch: 81, Iter: 17200, Loss: 1.645, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 06:54:38,810: INFO: Epoch: 82, Iter: 17300, Loss: 1.487, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 06:56:29,533: INFO: Epoch: 82, Iter: 17400, Loss: 1.490, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 06:58:20,313: INFO: Epoch: 83, Iter: 17500, Loss: 1.379, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 07:00:10,998: INFO: Epoch: 83, Iter: 17600, Loss: 0.727, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 07:02:01,880: INFO: Epoch: 84, Iter: 17700, Loss: 0.632, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 07:03:52,887: INFO: Epoch: 84, Iter: 17800, Loss: 1.315, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 07:05:43,791: INFO: Epoch: 85, Iter: 17900, Loss: 1.316, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 07:07:34,032: INFO: Epoch: 85, Iter: 18000, Loss: 1.800, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 07:09:24,848: INFO: Epoch: 86, Iter: 18100, Loss: 1.912, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 07:11:15,585: INFO: Epoch: 86, Iter: 18200, Loss: 1.287, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 07:13:06,994: INFO: Epoch: 87, Iter: 18300, Loss: 2.687, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 07:14:57,411: INFO: Epoch: 87, Iter: 18400, Loss: 1.455, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 07:16:47,977: INFO: Epoch: 88, Iter: 18500, Loss: 1.095, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 07:18:38,965: INFO: Epoch: 88, Iter: 18600, Loss: 0.913, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 07:20:29,277: INFO: Epoch: 89, Iter: 18700, Loss: 1.105, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 07:22:19,752: INFO: Epoch: 89, Iter: 18800, Loss: 1.288, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 07:24:10,410: INFO: Epoch: 90, Iter: 18900, Loss: 1.106, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 07:26:00,866: INFO: Epoch: 90, Iter: 19000, Loss: 1.342, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 07:27:51,420: INFO: Epoch: 90, Iter: 19100, Loss: 1.131, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 07:29:42,009: INFO: Epoch: 91, Iter: 19200, Loss: 0.693, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 07:31:32,862: INFO: Epoch: 91, Iter: 19300, Loss: 1.237, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 07:33:24,404: INFO: Epoch: 92, Iter: 19400, Loss: 2.649, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 07:35:15,040: INFO: Epoch: 92, Iter: 19500, Loss: 1.895, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 07:37:06,129: INFO: Epoch: 93, Iter: 19600, Loss: 1.704, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 07:38:57,244: INFO: Epoch: 93, Iter: 19700, Loss: 1.196, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 07:40:47,341: INFO: Epoch: 94, Iter: 19800, Loss: 2.295, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 07:42:38,729: INFO: Epoch: 94, Iter: 19900, Loss: 2.931, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 07:44:29,813: INFO: Epoch: 95, Iter: 20000, Loss: 0.576, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 07:46:20,390: INFO: Epoch: 95, Iter: 20100, Loss: 1.500, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 07:48:11,530: INFO: Epoch: 96, Iter: 20200, Loss: 1.302, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 07:50:02,365: INFO: Epoch: 96, Iter: 20300, Loss: 0.531, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 07:51:53,023: INFO: Epoch: 97, Iter: 20400, Loss: 0.767, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 07:53:44,409: INFO: Epoch: 97, Iter: 20500, Loss: 0.526, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 07:55:34,956: INFO: Epoch: 98, Iter: 20600, Loss: 2.021, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 07:57:25,890: INFO: Epoch: 98, Iter: 20700, Loss: 1.663, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 07:59:17,232: INFO: Epoch: 99, Iter: 20800, Loss: 0.835, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 08:01:07,881: INFO: Epoch: 99, Iter: 20900, Loss: 1.902, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 08:02:59,003: INFO: Epoch: 100, Iter: 21000, Loss: 1.159, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 08:04:49,736: INFO: Epoch: 100, Iter: 21100, Loss: 2.001, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 08:06:40,174: INFO: Epoch: 100, Iter: 21200, Loss: 1.647, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 08:08:30,614: INFO: Epoch: 101, Iter: 21300, Loss: 0.161, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 08:10:21,285: INFO: Epoch: 101, Iter: 21400, Loss: 0.561, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 08:12:12,420: INFO: Epoch: 102, Iter: 21500, Loss: 1.285, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 08:14:03,215: INFO: Epoch: 102, Iter: 21600, Loss: 1.280, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 08:15:53,917: INFO: Epoch: 103, Iter: 21700, Loss: 1.457, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 08:17:44,577: INFO: Epoch: 103, Iter: 21800, Loss: 1.583, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 08:19:35,463: INFO: Epoch: 104, Iter: 21900, Loss: 2.452, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 08:21:26,305: INFO: Epoch: 104, Iter: 22000, Loss: 0.656, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 08:23:17,791: INFO: Epoch: 105, Iter: 22100, Loss: 1.288, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 08:25:08,631: INFO: Epoch: 105, Iter: 22200, Loss: 0.489, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 08:26:59,125: INFO: Epoch: 106, Iter: 22300, Loss: 2.108, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 08:28:50,169: INFO: Epoch: 106, Iter: 22400, Loss: 0.996, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 08:30:40,862: INFO: Epoch: 107, Iter: 22500, Loss: 0.676, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 08:32:32,102: INFO: Epoch: 107, Iter: 22600, Loss: 2.465, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 08:34:23,398: INFO: Epoch: 108, Iter: 22700, Loss: 2.633, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 08:36:14,230: INFO: Epoch: 108, Iter: 22800, Loss: 1.371, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 08:38:05,178: INFO: Epoch: 109, Iter: 22900, Loss: 1.436, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 08:39:56,324: INFO: Epoch: 109, Iter: 23000, Loss: 0.717, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 08:41:46,700: INFO: Epoch: 110, Iter: 23100, Loss: 1.279, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 08:43:38,741: INFO: Epoch: 110, Iter: 23200, Loss: 1.271, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 08:45:29,527: INFO: Epoch: 110, Iter: 23300, Loss: 0.630, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 08:47:20,091: INFO: Epoch: 111, Iter: 23400, Loss: 0.969, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 08:49:11,113: INFO: Epoch: 111, Iter: 23500, Loss: 1.580, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 08:51:01,764: INFO: Epoch: 112, Iter: 23600, Loss: 1.143, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 08:52:54,875: INFO: Epoch: 112, Iter: 23700, Loss: 1.233, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 08:55:03,852: INFO: Epoch: 113, Iter: 23800, Loss: 0.496, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 08:57:11,914: INFO: Epoch: 113, Iter: 23900, Loss: 1.502, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 08:59:03,406: INFO: Epoch: 114, Iter: 24000, Loss: 0.892, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 09:00:53,552: INFO: Epoch: 114, Iter: 24100, Loss: 1.408, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 09:02:43,306: INFO: Epoch: 115, Iter: 24200, Loss: 0.790, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 09:04:33,883: INFO: Epoch: 115, Iter: 24300, Loss: 3.694, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 09:06:23,819: INFO: Epoch: 116, Iter: 24400, Loss: 1.702, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 09:08:13,671: INFO: Epoch: 116, Iter: 24500, Loss: 0.422, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 09:10:03,255: INFO: Epoch: 117, Iter: 24600, Loss: 1.489, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 09:11:53,152: INFO: Epoch: 117, Iter: 24700, Loss: 1.806, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 09:13:43,469: INFO: Epoch: 118, Iter: 24800, Loss: 1.648, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 09:15:33,451: INFO: Epoch: 118, Iter: 24900, Loss: 1.126, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 09:17:22,912: INFO: Epoch: 119, Iter: 25000, Loss: 0.639, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 09:19:12,719: INFO: Epoch: 119, Iter: 25100, Loss: 2.694, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 09:21:02,419: INFO: Epoch: 120, Iter: 25200, Loss: 2.037, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 09:22:52,129: INFO: Epoch: 120, Iter: 25300, Loss: 0.842, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 09:24:41,874: INFO: Epoch: 120, Iter: 25400, Loss: 2.016, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 09:26:31,127: INFO: Epoch: 121, Iter: 25500, Loss: 1.157, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 09:28:20,332: INFO: Epoch: 121, Iter: 25600, Loss: 1.412, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 09:30:10,063: INFO: Epoch: 122, Iter: 25700, Loss: 1.052, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 09:31:59,681: INFO: Epoch: 122, Iter: 25800, Loss: 0.306, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 09:33:49,893: INFO: Epoch: 123, Iter: 25900, Loss: 0.853, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 09:35:39,845: INFO: Epoch: 123, Iter: 26000, Loss: 0.432, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 09:37:28,881: INFO: Epoch: 124, Iter: 26100, Loss: 0.315, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 09:39:18,941: INFO: Epoch: 124, Iter: 26200, Loss: 0.912, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 09:41:08,750: INFO: Epoch: 125, Iter: 26300, Loss: 0.816, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 09:42:58,130: INFO: Epoch: 125, Iter: 26400, Loss: 2.685, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 09:44:47,957: INFO: Epoch: 126, Iter: 26500, Loss: 0.838, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 09:46:37,653: INFO: Epoch: 126, Iter: 26600, Loss: 1.365, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 09:48:27,180: INFO: Epoch: 127, Iter: 26700, Loss: 1.238, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 09:50:17,325: INFO: Epoch: 127, Iter: 26800, Loss: 0.721, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 09:52:07,186: INFO: Epoch: 128, Iter: 26900, Loss: 0.876, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 09:53:57,145: INFO: Epoch: 128, Iter: 27000, Loss: 0.665, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 09:55:46,431: INFO: Epoch: 129, Iter: 27100, Loss: 2.031, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 09:57:35,960: INFO: Epoch: 129, Iter: 27200, Loss: 2.086, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 09:59:25,880: INFO: Epoch: 130, Iter: 27300, Loss: 1.166, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 10:01:15,300: INFO: Epoch: 130, Iter: 27400, Loss: 1.934, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 10:03:05,159: INFO: Epoch: 130, Iter: 27500, Loss: 2.006, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 10:04:54,949: INFO: Epoch: 131, Iter: 27600, Loss: 2.239, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 10:06:44,640: INFO: Epoch: 131, Iter: 27700, Loss: 1.437, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 10:08:34,141: INFO: Epoch: 132, Iter: 27800, Loss: 1.386, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 10:10:23,580: INFO: Epoch: 132, Iter: 27900, Loss: 0.598, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 10:12:13,420: INFO: Epoch: 133, Iter: 28000, Loss: 0.681, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 10:14:03,359: INFO: Epoch: 133, Iter: 28100, Loss: 3.353, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 10:15:52,452: INFO: Epoch: 134, Iter: 28200, Loss: 0.765, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 10:17:41,981: INFO: Epoch: 134, Iter: 28300, Loss: 1.442, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 10:19:31,865: INFO: Epoch: 135, Iter: 28400, Loss: 1.807, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 10:21:21,665: INFO: Epoch: 135, Iter: 28500, Loss: 1.211, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 10:23:10,616: INFO: Epoch: 136, Iter: 28600, Loss: 2.466, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 10:25:00,727: INFO: Epoch: 136, Iter: 28700, Loss: 1.075, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 10:26:50,255: INFO: Epoch: 137, Iter: 28800, Loss: 0.434, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 10:28:39,841: INFO: Epoch: 137, Iter: 28900, Loss: 1.284, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 10:30:29,321: INFO: Epoch: 138, Iter: 29000, Loss: 1.287, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 10:32:18,993: INFO: Epoch: 138, Iter: 29100, Loss: 1.789, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 10:34:09,192: INFO: Epoch: 139, Iter: 29200, Loss: 0.827, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 10:35:58,933: INFO: Epoch: 139, Iter: 29300, Loss: 1.873, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 10:37:48,583: INFO: Epoch: 140, Iter: 29400, Loss: 2.703, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 10:39:38,020: INFO: Epoch: 140, Iter: 29500, Loss: 1.677, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 10:41:27,506: INFO: Epoch: 140, Iter: 29600, Loss: 1.136, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 10:43:17,616: INFO: Epoch: 141, Iter: 29700, Loss: 2.002, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 10:45:06,859: INFO: Epoch: 141, Iter: 29800, Loss: 1.089, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 10:46:56,026: INFO: Epoch: 142, Iter: 29900, Loss: 0.130, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 10:48:46,014: INFO: Epoch: 142, Iter: 30000, Loss: 1.562, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 10:50:35,222: INFO: Epoch: 143, Iter: 30100, Loss: 0.867, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 10:52:24,437: INFO: Epoch: 143, Iter: 30200, Loss: 1.408, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 10:54:16,068: INFO: Epoch: 144, Iter: 30300, Loss: 1.204, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 10:56:06,724: INFO: Epoch: 144, Iter: 30400, Loss: 0.511, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 10:57:56,125: INFO: Epoch: 145, Iter: 30500, Loss: 0.831, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 10:59:45,253: INFO: Epoch: 145, Iter: 30600, Loss: 1.476, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 11:01:34,325: INFO: Epoch: 146, Iter: 30700, Loss: 0.565, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 11:03:24,354: INFO: Epoch: 146, Iter: 30800, Loss: 1.493, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 11:05:13,704: INFO: Epoch: 147, Iter: 30900, Loss: 1.681, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 11:07:02,616: INFO: Epoch: 147, Iter: 31000, Loss: 1.519, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 11:08:52,565: INFO: Epoch: 148, Iter: 31100, Loss: 1.907, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 11:10:42,000: INFO: Epoch: 148, Iter: 31200, Loss: 2.187, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 11:12:31,695: INFO: Epoch: 149, Iter: 31300, Loss: 1.418, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 11:14:21,429: INFO: Epoch: 149, Iter: 31400, Loss: 0.699, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 11:16:10,820: INFO: Epoch: 150, Iter: 31500, Loss: 1.299, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 11:18:00,367: INFO: Epoch: 150, Iter: 31600, Loss: 1.779, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 11:19:49,883: INFO: Epoch: 150, Iter: 31700, Loss: 1.565, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 11:21:39,369: INFO: Epoch: 151, Iter: 31800, Loss: 0.668, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 11:23:29,766: INFO: Epoch: 151, Iter: 31900, Loss: 1.355, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 11:25:20,225: INFO: Epoch: 152, Iter: 32000, Loss: 0.976, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 11:27:09,483: INFO: Epoch: 152, Iter: 32100, Loss: 0.231, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 11:28:59,045: INFO: Epoch: 153, Iter: 32200, Loss: 1.988, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 11:30:48,407: INFO: Epoch: 153, Iter: 32300, Loss: 0.289, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 11:32:38,103: INFO: Epoch: 154, Iter: 32400, Loss: 2.068, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 11:34:28,507: INFO: Epoch: 154, Iter: 32500, Loss: 0.801, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 11:36:17,987: INFO: Epoch: 155, Iter: 32600, Loss: 1.107, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 11:38:06,987: INFO: Epoch: 155, Iter: 32700, Loss: 1.935, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 11:39:56,466: INFO: Epoch: 156, Iter: 32800, Loss: 3.108, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 11:41:46,588: INFO: Epoch: 156, Iter: 32900, Loss: 1.030, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 11:43:37,003: INFO: Epoch: 157, Iter: 33000, Loss: 1.017, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 11:45:26,751: INFO: Epoch: 157, Iter: 33100, Loss: 1.471, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 11:47:16,163: INFO: Epoch: 158, Iter: 33200, Loss: 1.070, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 11:49:05,864: INFO: Epoch: 158, Iter: 33300, Loss: 1.830, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 11:50:54,996: INFO: Epoch: 159, Iter: 33400, Loss: 0.835, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 11:52:44,464: INFO: Epoch: 159, Iter: 33500, Loss: 1.206, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 11:54:34,299: INFO: Epoch: 160, Iter: 33600, Loss: 1.006, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 11:56:23,959: INFO: Epoch: 160, Iter: 33700, Loss: 0.274, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 11:58:13,825: INFO: Epoch: 160, Iter: 33800, Loss: 1.762, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 12:00:03,238: INFO: Epoch: 161, Iter: 33900, Loss: 1.369, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 12:01:52,603: INFO: Epoch: 161, Iter: 34000, Loss: 0.788, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 12:03:42,199: INFO: Epoch: 162, Iter: 34100, Loss: 0.390, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 12:05:31,846: INFO: Epoch: 162, Iter: 34200, Loss: 2.307, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 12:07:21,469: INFO: Epoch: 163, Iter: 34300, Loss: 0.919, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 12:09:11,342: INFO: Epoch: 163, Iter: 34400, Loss: 0.674, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 12:11:01,415: INFO: Epoch: 164, Iter: 34500, Loss: 0.390, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 12:12:50,920: INFO: Epoch: 164, Iter: 34600, Loss: 0.322, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 12:14:40,749: INFO: Epoch: 165, Iter: 34700, Loss: 2.950, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 12:16:29,765: INFO: Epoch: 165, Iter: 34800, Loss: 1.570, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 12:18:19,652: INFO: Epoch: 166, Iter: 34900, Loss: 1.289, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 12:20:08,883: INFO: Epoch: 166, Iter: 35000, Loss: 1.474, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 12:21:58,385: INFO: Epoch: 167, Iter: 35100, Loss: 0.964, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 12:23:49,203: INFO: Epoch: 167, Iter: 35200, Loss: 1.066, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 12:25:38,754: INFO: Epoch: 168, Iter: 35300, Loss: 0.347, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 12:27:28,078: INFO: Epoch: 168, Iter: 35400, Loss: 0.926, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 12:29:19,742: INFO: Epoch: 169, Iter: 35500, Loss: 1.824, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 12:31:09,575: INFO: Epoch: 169, Iter: 35600, Loss: 1.699, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 12:32:59,917: INFO: Epoch: 170, Iter: 35700, Loss: 2.219, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 12:34:49,801: INFO: Epoch: 170, Iter: 35800, Loss: 0.612, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 12:36:39,908: INFO: Epoch: 170, Iter: 35900, Loss: 0.903, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 12:38:29,996: INFO: Epoch: 171, Iter: 36000, Loss: 1.863, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 12:40:19,621: INFO: Epoch: 171, Iter: 36100, Loss: 1.707, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 12:42:09,170: INFO: Epoch: 172, Iter: 36200, Loss: 2.687, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 12:43:59,289: INFO: Epoch: 172, Iter: 36300, Loss: 0.849, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 12:45:48,643: INFO: Epoch: 173, Iter: 36400, Loss: 1.786, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 12:47:37,846: INFO: Epoch: 173, Iter: 36500, Loss: 2.445, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 12:49:27,582: INFO: Epoch: 174, Iter: 36600, Loss: 0.889, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 12:51:17,078: INFO: Epoch: 174, Iter: 36700, Loss: 0.907, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 12:53:06,104: INFO: Epoch: 175, Iter: 36800, Loss: 0.953, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 12:54:55,639: INFO: Epoch: 175, Iter: 36900, Loss: 0.384, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 12:56:45,289: INFO: Epoch: 176, Iter: 37000, Loss: 0.761, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 12:58:35,851: INFO: Epoch: 176, Iter: 37100, Loss: 1.377, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 13:00:25,160: INFO: Epoch: 177, Iter: 37200, Loss: 1.715, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 13:02:14,833: INFO: Epoch: 177, Iter: 37300, Loss: 1.351, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 13:04:04,925: INFO: Epoch: 178, Iter: 37400, Loss: 1.343, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 13:05:54,577: INFO: Epoch: 178, Iter: 37500, Loss: 1.760, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 13:07:44,409: INFO: Epoch: 179, Iter: 37600, Loss: 1.238, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 13:09:34,027: INFO: Epoch: 179, Iter: 37700, Loss: 1.453, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 13:11:22,938: INFO: Epoch: 180, Iter: 37800, Loss: 0.446, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 13:13:12,842: INFO: Epoch: 180, Iter: 37900, Loss: 0.827, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 13:15:02,755: INFO: Epoch: 180, Iter: 38000, Loss: 0.061, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 13:16:52,880: INFO: Epoch: 181, Iter: 38100, Loss: 0.252, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 13:18:42,485: INFO: Epoch: 181, Iter: 38200, Loss: 1.116, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 13:20:31,861: INFO: Epoch: 182, Iter: 38300, Loss: 1.463, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 13:22:21,729: INFO: Epoch: 182, Iter: 38400, Loss: 1.413, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 13:24:12,502: INFO: Epoch: 183, Iter: 38500, Loss: 1.869, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 13:26:01,906: INFO: Epoch: 183, Iter: 38600, Loss: 0.768, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 13:27:51,966: INFO: Epoch: 184, Iter: 38700, Loss: 0.532, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 13:29:41,220: INFO: Epoch: 184, Iter: 38800, Loss: 0.482, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 13:31:30,903: INFO: Epoch: 185, Iter: 38900, Loss: 1.088, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 13:33:20,665: INFO: Epoch: 185, Iter: 39000, Loss: 0.780, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 13:35:10,161: INFO: Epoch: 186, Iter: 39100, Loss: 2.601, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 13:37:00,014: INFO: Epoch: 186, Iter: 39200, Loss: 1.596, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 13:38:58,885: INFO: Epoch: 187, Iter: 39300, Loss: 1.511, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 13:40:47,768: INFO: Epoch: 187, Iter: 39400, Loss: 2.367, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 13:42:37,087: INFO: Epoch: 188, Iter: 39500, Loss: 0.698, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 13:44:28,830: INFO: Epoch: 188, Iter: 39600, Loss: 0.421, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 13:46:18,599: INFO: Epoch: 189, Iter: 39700, Loss: 1.348, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 13:48:08,662: INFO: Epoch: 189, Iter: 39800, Loss: 0.700, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 13:49:58,341: INFO: Epoch: 190, Iter: 39900, Loss: 2.191, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 13:51:47,805: INFO: Epoch: 190, Iter: 40000, Loss: 1.822, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 13:53:37,396: INFO: Epoch: 190, Iter: 40100, Loss: 1.385, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 13:55:26,415: INFO: Epoch: 191, Iter: 40200, Loss: 0.823, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 13:57:15,701: INFO: Epoch: 191, Iter: 40300, Loss: 3.097, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 13:59:05,006: INFO: Epoch: 192, Iter: 40400, Loss: 0.586, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 14:00:54,868: INFO: Epoch: 192, Iter: 40500, Loss: 1.229, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 14:02:45,090: INFO: Epoch: 193, Iter: 40600, Loss: 1.179, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 14:04:35,936: INFO: Epoch: 193, Iter: 40700, Loss: 1.162, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 14:06:25,559: INFO: Epoch: 194, Iter: 40800, Loss: 0.180, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 14:08:14,754: INFO: Epoch: 194, Iter: 40900, Loss: 0.116, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 14:10:03,873: INFO: Epoch: 195, Iter: 41000, Loss: 2.499, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 14:11:53,373: INFO: Epoch: 195, Iter: 41100, Loss: 1.359, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 14:13:43,313: INFO: Epoch: 196, Iter: 41200, Loss: 1.026, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 14:15:32,914: INFO: Epoch: 196, Iter: 41300, Loss: 1.954, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 14:17:22,845: INFO: Epoch: 197, Iter: 41400, Loss: 2.301, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 14:19:12,806: INFO: Epoch: 197, Iter: 41500, Loss: 0.945, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 14:21:02,474: INFO: Epoch: 198, Iter: 41600, Loss: 0.816, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 14:22:52,164: INFO: Epoch: 198, Iter: 41700, Loss: 1.878, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 14:24:42,826: INFO: Epoch: 199, Iter: 41800, Loss: 2.045, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 14:26:32,074: INFO: Epoch: 199, Iter: 41900, Loss: 2.215, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 14:28:21,633: INFO: Epoch: 200, Iter: 42000, Loss: 0.788, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 14:30:11,400: INFO: Epoch: 200, Iter: 42100, Loss: 1.195, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 14:32:00,974: INFO: Epoch: 200, Iter: 42200, Loss: 1.313, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 14:33:50,557: INFO: Epoch: 201, Iter: 42300, Loss: 0.648, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 14:35:40,129: INFO: Epoch: 201, Iter: 42400, Loss: 1.589, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 14:37:29,789: INFO: Epoch: 202, Iter: 42500, Loss: 2.550, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 14:39:19,606: INFO: Epoch: 202, Iter: 42600, Loss: 0.564, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 14:41:08,967: INFO: Epoch: 203, Iter: 42700, Loss: 0.471, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 14:42:58,183: INFO: Epoch: 203, Iter: 42800, Loss: 1.843, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 14:44:48,028: INFO: Epoch: 204, Iter: 42900, Loss: 0.874, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 14:46:37,440: INFO: Epoch: 204, Iter: 43000, Loss: 2.140, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 14:48:26,800: INFO: Epoch: 205, Iter: 43100, Loss: 0.970, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 14:50:16,090: INFO: Epoch: 205, Iter: 43200, Loss: 1.516, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 14:52:06,153: INFO: Epoch: 206, Iter: 43300, Loss: 0.732, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 14:53:55,642: INFO: Epoch: 206, Iter: 43400, Loss: 2.106, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 14:55:44,985: INFO: Epoch: 207, Iter: 43500, Loss: 0.204, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 14:57:34,337: INFO: Epoch: 207, Iter: 43600, Loss: 1.652, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 14:59:23,700: INFO: Epoch: 208, Iter: 43700, Loss: 0.910, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 15:01:13,253: INFO: Epoch: 208, Iter: 43800, Loss: 2.035, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 15:03:02,939: INFO: Epoch: 209, Iter: 43900, Loss: 0.915, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 15:04:53,091: INFO: Epoch: 209, Iter: 44000, Loss: 1.479, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 15:06:42,734: INFO: Epoch: 210, Iter: 44100, Loss: 1.703, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 15:08:31,933: INFO: Epoch: 210, Iter: 44200, Loss: 3.294, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 15:10:21,363: INFO: Epoch: 210, Iter: 44300, Loss: 3.012, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 15:12:11,040: INFO: Epoch: 211, Iter: 44400, Loss: 1.288, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 15:14:01,075: INFO: Epoch: 211, Iter: 44500, Loss: 1.962, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 15:15:50,632: INFO: Epoch: 212, Iter: 44600, Loss: 1.021, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 15:17:40,050: INFO: Epoch: 212, Iter: 44700, Loss: 1.169, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 15:19:30,289: INFO: Epoch: 213, Iter: 44800, Loss: 1.479, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 15:21:19,511: INFO: Epoch: 213, Iter: 44900, Loss: 1.245, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 15:23:09,122: INFO: Epoch: 214, Iter: 45000, Loss: 0.693, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 15:24:58,387: INFO: Epoch: 214, Iter: 45100, Loss: 0.591, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 15:26:47,731: INFO: Epoch: 215, Iter: 45200, Loss: 0.691, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 15:28:37,570: INFO: Epoch: 215, Iter: 45300, Loss: 2.657, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 15:30:26,633: INFO: Epoch: 216, Iter: 45400, Loss: 0.414, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 15:32:15,978: INFO: Epoch: 216, Iter: 45500, Loss: 0.335, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 15:34:05,698: INFO: Epoch: 217, Iter: 45600, Loss: 1.325, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 15:35:55,883: INFO: Epoch: 217, Iter: 45700, Loss: 1.293, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 15:37:45,388: INFO: Epoch: 218, Iter: 45800, Loss: 0.903, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 15:39:35,090: INFO: Epoch: 218, Iter: 45900, Loss: 0.760, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 15:41:24,492: INFO: Epoch: 219, Iter: 46000, Loss: 1.769, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 15:43:14,460: INFO: Epoch: 219, Iter: 46100, Loss: 1.574, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 15:45:04,315: INFO: Epoch: 220, Iter: 46200, Loss: 0.763, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 15:46:53,719: INFO: Epoch: 220, Iter: 46300, Loss: 4.300, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 15:48:43,610: INFO: Epoch: 220, Iter: 46400, Loss: 0.823, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 15:50:33,001: INFO: Epoch: 221, Iter: 46500, Loss: 0.906, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 15:52:22,132: INFO: Epoch: 221, Iter: 46600, Loss: 3.054, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 15:54:12,228: INFO: Epoch: 222, Iter: 46700, Loss: 0.540, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 15:56:01,897: INFO: Epoch: 222, Iter: 46800, Loss: 0.550, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 15:57:51,682: INFO: Epoch: 223, Iter: 46900, Loss: 2.113, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 15:59:40,767: INFO: Epoch: 223, Iter: 47000, Loss: 1.052, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 16:01:30,211: INFO: Epoch: 224, Iter: 47100, Loss: 0.923, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 16:03:20,098: INFO: Epoch: 224, Iter: 47200, Loss: 2.017, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 16:05:09,568: INFO: Epoch: 225, Iter: 47300, Loss: 1.466, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 16:06:59,032: INFO: Epoch: 225, Iter: 47400, Loss: 2.106, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 16:08:49,005: INFO: Epoch: 226, Iter: 47500, Loss: 0.439, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 16:10:38,389: INFO: Epoch: 226, Iter: 47600, Loss: 1.582, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 16:12:27,725: INFO: Epoch: 227, Iter: 47700, Loss: 0.848, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 16:14:17,607: INFO: Epoch: 227, Iter: 47800, Loss: 1.320, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 16:16:07,151: INFO: Epoch: 228, Iter: 47900, Loss: 0.728, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 16:17:57,069: INFO: Epoch: 228, Iter: 48000, Loss: 0.996, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 16:19:46,914: INFO: Epoch: 229, Iter: 48100, Loss: 0.249, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 16:21:35,989: INFO: Epoch: 229, Iter: 48200, Loss: 0.043, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 16:23:26,169: INFO: Epoch: 230, Iter: 48300, Loss: 1.311, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 16:25:16,252: INFO: Epoch: 230, Iter: 48400, Loss: 0.766, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 16:27:05,718: INFO: Epoch: 230, Iter: 48500, Loss: 1.213, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 16:28:55,353: INFO: Epoch: 231, Iter: 48600, Loss: 3.375, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 16:30:45,010: INFO: Epoch: 231, Iter: 48700, Loss: 2.241, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 16:32:34,949: INFO: Epoch: 232, Iter: 48800, Loss: 1.531, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 16:34:24,713: INFO: Epoch: 232, Iter: 48900, Loss: 0.636, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 16:36:14,690: INFO: Epoch: 233, Iter: 49000, Loss: 1.835, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 16:38:04,718: INFO: Epoch: 233, Iter: 49100, Loss: 0.978, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 16:39:54,710: INFO: Epoch: 234, Iter: 49200, Loss: 0.553, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 16:41:44,543: INFO: Epoch: 234, Iter: 49300, Loss: 1.547, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 16:43:34,897: INFO: Epoch: 235, Iter: 49400, Loss: 0.402, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 16:45:24,746: INFO: Epoch: 235, Iter: 49500, Loss: 1.754, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 16:47:14,196: INFO: Epoch: 236, Iter: 49600, Loss: 0.369, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 16:49:03,556: INFO: Epoch: 236, Iter: 49700, Loss: 0.496, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 16:50:53,339: INFO: Epoch: 237, Iter: 49800, Loss: 0.754, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 16:52:42,657: INFO: Epoch: 237, Iter: 49900, Loss: 1.612, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 16:54:32,325: INFO: Epoch: 238, Iter: 50000, Loss: 0.591, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 16:56:21,796: INFO: Epoch: 238, Iter: 50100, Loss: 0.813, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 16:58:12,733: INFO: Epoch: 239, Iter: 50200, Loss: 1.253, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 17:00:02,485: INFO: Epoch: 239, Iter: 50300, Loss: 1.561, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 17:01:51,849: INFO: Epoch: 240, Iter: 50400, Loss: 0.462, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 17:03:41,414: INFO: Epoch: 240, Iter: 50500, Loss: 0.484, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 17:05:30,914: INFO: Epoch: 240, Iter: 50600, Loss: 0.763, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 17:07:20,556: INFO: Epoch: 241, Iter: 50700, Loss: 1.338, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 17:09:10,617: INFO: Epoch: 241, Iter: 50800, Loss: 0.420, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 17:11:00,167: INFO: Epoch: 242, Iter: 50900, Loss: 0.510, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 17:12:49,619: INFO: Epoch: 242, Iter: 51000, Loss: 0.664, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 17:14:39,801: INFO: Epoch: 243, Iter: 51100, Loss: 1.509, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 17:16:28,931: INFO: Epoch: 243, Iter: 51200, Loss: 1.307, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 17:18:18,948: INFO: Epoch: 244, Iter: 51300, Loss: 0.472, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 17:20:08,272: INFO: Epoch: 244, Iter: 51400, Loss: 1.279, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 17:21:57,592: INFO: Epoch: 245, Iter: 51500, Loss: 1.750, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 17:23:47,580: INFO: Epoch: 245, Iter: 51600, Loss: 0.553, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 17:25:37,017: INFO: Epoch: 246, Iter: 51700, Loss: 0.569, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 17:27:26,620: INFO: Epoch: 246, Iter: 51800, Loss: 1.431, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 17:29:16,633: INFO: Epoch: 247, Iter: 51900, Loss: 2.562, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 17:31:06,393: INFO: Epoch: 247, Iter: 52000, Loss: 0.855, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 17:32:56,222: INFO: Epoch: 248, Iter: 52100, Loss: 0.445, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 17:34:45,802: INFO: Epoch: 248, Iter: 52200, Loss: 0.681, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 17:36:34,934: INFO: Epoch: 249, Iter: 52300, Loss: 1.046, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 17:38:24,788: INFO: Epoch: 249, Iter: 52400, Loss: 1.237, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 17:40:14,559: INFO: Epoch: 250, Iter: 52500, Loss: 0.460, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 17:42:04,226: INFO: Epoch: 250, Iter: 52600, Loss: 0.514, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 17:43:53,736: INFO: Epoch: 250, Iter: 52700, Loss: 0.745, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 17:45:42,847: INFO: Epoch: 251, Iter: 52800, Loss: 1.255, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 17:47:32,009: INFO: Epoch: 251, Iter: 52900, Loss: 1.011, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 17:49:22,542: INFO: Epoch: 252, Iter: 53000, Loss: 1.437, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 17:51:11,810: INFO: Epoch: 252, Iter: 53100, Loss: 1.604, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 17:53:01,170: INFO: Epoch: 253, Iter: 53200, Loss: 1.253, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 17:54:50,652: INFO: Epoch: 253, Iter: 53300, Loss: 0.727, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 17:56:40,114: INFO: Epoch: 254, Iter: 53400, Loss: 0.684, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 17:58:30,537: INFO: Epoch: 254, Iter: 53500, Loss: 0.385, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 18:00:19,988: INFO: Epoch: 255, Iter: 53600, Loss: 0.540, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 18:02:09,151: INFO: Epoch: 255, Iter: 53700, Loss: 1.137, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 18:03:58,834: INFO: Epoch: 256, Iter: 53800, Loss: 0.711, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 18:05:48,530: INFO: Epoch: 256, Iter: 53900, Loss: 1.082, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 18:07:38,257: INFO: Epoch: 257, Iter: 54000, Loss: 0.667, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 18:09:28,166: INFO: Epoch: 257, Iter: 54100, Loss: 0.563, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 18:11:17,873: INFO: Epoch: 258, Iter: 54200, Loss: 1.412, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 18:13:07,673: INFO: Epoch: 258, Iter: 54300, Loss: 1.365, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 18:14:57,634: INFO: Epoch: 259, Iter: 54400, Loss: 1.358, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 18:16:47,098: INFO: Epoch: 259, Iter: 54500, Loss: 1.433, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 18:18:36,675: INFO: Epoch: 260, Iter: 54600, Loss: 0.528, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 18:20:26,047: INFO: Epoch: 260, Iter: 54700, Loss: 0.615, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 18:22:15,612: INFO: Epoch: 260, Iter: 54800, Loss: 0.582, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 18:24:05,079: INFO: Epoch: 261, Iter: 54900, Loss: 0.813, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 18:25:54,777: INFO: Epoch: 261, Iter: 55000, Loss: 0.607, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 18:27:43,968: INFO: Epoch: 262, Iter: 55100, Loss: 1.452, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 18:29:34,144: INFO: Epoch: 262, Iter: 55200, Loss: 0.310, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 18:31:23,454: INFO: Epoch: 263, Iter: 55300, Loss: 1.346, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 18:33:13,765: INFO: Epoch: 263, Iter: 55400, Loss: 1.092, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 18:35:03,505: INFO: Epoch: 264, Iter: 55500, Loss: 1.326, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 18:36:53,092: INFO: Epoch: 264, Iter: 55600, Loss: 1.425, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 18:38:42,834: INFO: Epoch: 265, Iter: 55700, Loss: 0.606, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 18:40:31,971: INFO: Epoch: 265, Iter: 55800, Loss: 2.177, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 18:42:21,222: INFO: Epoch: 266, Iter: 55900, Loss: 0.748, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 18:44:11,103: INFO: Epoch: 266, Iter: 56000, Loss: 0.386, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 18:46:01,025: INFO: Epoch: 267, Iter: 56100, Loss: 1.370, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 18:47:50,735: INFO: Epoch: 267, Iter: 56200, Loss: 1.575, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 18:49:40,525: INFO: Epoch: 268, Iter: 56300, Loss: 0.364, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 18:51:29,836: INFO: Epoch: 268, Iter: 56400, Loss: 0.486, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 18:53:19,665: INFO: Epoch: 269, Iter: 56500, Loss: 1.815, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 18:55:09,471: INFO: Epoch: 269, Iter: 56600, Loss: 0.619, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 18:56:58,610: INFO: Epoch: 270, Iter: 56700, Loss: 3.533, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 18:58:49,099: INFO: Epoch: 270, Iter: 56800, Loss: 1.174, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 19:00:38,668: INFO: Epoch: 270, Iter: 56900, Loss: 0.865, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 19:02:28,075: INFO: Epoch: 271, Iter: 57000, Loss: 1.551, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 19:04:17,641: INFO: Epoch: 271, Iter: 57100, Loss: 0.573, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 19:06:07,447: INFO: Epoch: 272, Iter: 57200, Loss: 0.519, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 19:07:57,399: INFO: Epoch: 272, Iter: 57300, Loss: 1.340, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 19:09:47,199: INFO: Epoch: 273, Iter: 57400, Loss: 1.278, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 19:11:36,620: INFO: Epoch: 273, Iter: 57500, Loss: 1.403, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 19:13:26,959: INFO: Epoch: 274, Iter: 57600, Loss: 1.253, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 19:15:16,809: INFO: Epoch: 274, Iter: 57700, Loss: 0.523, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 19:17:06,578: INFO: Epoch: 275, Iter: 57800, Loss: 0.958, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 19:18:57,628: INFO: Epoch: 275, Iter: 57900, Loss: 0.739, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 19:20:47,458: INFO: Epoch: 276, Iter: 58000, Loss: 1.139, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 19:22:37,324: INFO: Epoch: 276, Iter: 58100, Loss: 0.912, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 19:24:26,873: INFO: Epoch: 277, Iter: 58200, Loss: 0.550, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 19:26:16,408: INFO: Epoch: 277, Iter: 58300, Loss: 1.308, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 19:28:06,266: INFO: Epoch: 278, Iter: 58400, Loss: 0.427, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 19:29:55,979: INFO: Epoch: 278, Iter: 58500, Loss: 2.096, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 19:31:45,922: INFO: Epoch: 279, Iter: 58600, Loss: 1.361, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 19:33:36,479: INFO: Epoch: 279, Iter: 58700, Loss: 0.663, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 19:35:26,222: INFO: Epoch: 280, Iter: 58800, Loss: 0.252, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 19:37:15,645: INFO: Epoch: 280, Iter: 58900, Loss: 0.748, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 19:39:05,561: INFO: Epoch: 280, Iter: 59000, Loss: 0.669, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 19:40:55,348: INFO: Epoch: 281, Iter: 59100, Loss: 0.458, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 19:42:44,907: INFO: Epoch: 281, Iter: 59200, Loss: 1.807, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 19:44:34,245: INFO: Epoch: 282, Iter: 59300, Loss: 1.132, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 19:46:23,960: INFO: Epoch: 282, Iter: 59400, Loss: 0.837, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 19:48:13,750: INFO: Epoch: 283, Iter: 59500, Loss: 1.375, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 19:50:03,244: INFO: Epoch: 283, Iter: 59600, Loss: 0.862, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 19:51:52,657: INFO: Epoch: 284, Iter: 59700, Loss: 1.122, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 19:53:42,915: INFO: Epoch: 284, Iter: 59800, Loss: 0.798, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 19:55:32,341: INFO: Epoch: 285, Iter: 59900, Loss: 0.968, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 19:57:21,521: INFO: Epoch: 285, Iter: 60000, Loss: 2.070, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 19:59:10,814: INFO: Epoch: 286, Iter: 60100, Loss: 1.314, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 20:00:59,676: INFO: Epoch: 286, Iter: 60200, Loss: 1.056, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 20:02:49,509: INFO: Epoch: 287, Iter: 60300, Loss: 2.016, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 20:04:39,098: INFO: Epoch: 287, Iter: 60400, Loss: 1.811, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 20:06:27,974: INFO: Epoch: 288, Iter: 60500, Loss: 1.766, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 20:08:18,138: INFO: Epoch: 288, Iter: 60600, Loss: 1.415, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 20:10:07,573: INFO: Epoch: 289, Iter: 60700, Loss: 0.386, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 20:11:57,102: INFO: Epoch: 289, Iter: 60800, Loss: 0.432, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 20:13:46,948: INFO: Epoch: 290, Iter: 60900, Loss: 1.193, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 20:15:36,665: INFO: Epoch: 290, Iter: 61000, Loss: 0.603, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 20:17:25,679: INFO: Epoch: 290, Iter: 61100, Loss: 1.808, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 20:19:15,590: INFO: Epoch: 291, Iter: 61200, Loss: 2.239, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 20:21:04,774: INFO: Epoch: 291, Iter: 61300, Loss: 1.645, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 20:22:54,446: INFO: Epoch: 292, Iter: 61400, Loss: 1.592, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 20:24:44,121: INFO: Epoch: 292, Iter: 61500, Loss: 1.363, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 20:26:33,566: INFO: Epoch: 293, Iter: 61600, Loss: 0.643, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 20:28:23,254: INFO: Epoch: 293, Iter: 61700, Loss: 1.192, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 20:30:12,658: INFO: Epoch: 294, Iter: 61800, Loss: 0.525, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 20:32:02,219: INFO: Epoch: 294, Iter: 61900, Loss: 1.298, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 20:33:51,661: INFO: Epoch: 295, Iter: 62000, Loss: 1.166, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 20:35:41,417: INFO: Epoch: 295, Iter: 62100, Loss: 0.024, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 20:37:31,588: INFO: Epoch: 296, Iter: 62200, Loss: 0.682, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 20:39:21,392: INFO: Epoch: 296, Iter: 62300, Loss: 0.595, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 20:41:11,162: INFO: Epoch: 297, Iter: 62400, Loss: 0.554, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 20:43:00,620: INFO: Epoch: 297, Iter: 62500, Loss: 0.813, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 20:44:50,256: INFO: Epoch: 298, Iter: 62600, Loss: 0.530, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 20:46:39,978: INFO: Epoch: 298, Iter: 62700, Loss: 1.680, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 20:48:29,497: INFO: Epoch: 299, Iter: 62800, Loss: 1.176, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 20:50:18,706: INFO: Epoch: 299, Iter: 62900, Loss: 0.937, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 20:52:08,408: INFO: Epoch: 300, Iter: 63000, Loss: 0.731, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 20:53:57,838: INFO: Epoch: 300, Iter: 63100, Loss: 1.286, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 20:55:47,258: INFO: Epoch: 300, Iter: 63200, Loss: 1.015, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 20:57:36,633: INFO: Epoch: 301, Iter: 63300, Loss: 0.319, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 20:59:26,364: INFO: Epoch: 301, Iter: 63400, Loss: 1.341, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 21:01:15,554: INFO: Epoch: 302, Iter: 63500, Loss: 1.792, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 21:03:05,069: INFO: Epoch: 302, Iter: 63600, Loss: 1.145, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 21:04:54,621: INFO: Epoch: 303, Iter: 63700, Loss: 2.318, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 21:06:43,909: INFO: Epoch: 303, Iter: 63800, Loss: 1.000, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 21:08:33,603: INFO: Epoch: 304, Iter: 63900, Loss: 1.619, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 21:10:22,763: INFO: Epoch: 304, Iter: 64000, Loss: 0.754, Accuracy: 1.000, Learning Rate: 0.050
2017-11-02 21:12:12,304: INFO: Epoch: 305, Iter: 64100, Loss: 0.890, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 21:14:02,205: INFO: Epoch: 305, Iter: 64200, Loss: 1.163, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 21:15:51,932: INFO: Epoch: 306, Iter: 64300, Loss: 1.177, Accuracy: 0.000, Learning Rate: 0.050
2017-11-02 21:16:56,219: INFO: Keyboard Interrupt? Gracefully quitting
2017-11-02 21:16:56,219: INFO: The training is done.

2017-11-04 14:25:23,206: INFO: *** NEW RUN ***
2017-11-04 14:25:23,207: INFO: filename: trained_model_2017.11.04-14.25.22
2017-11-04 14:25:23,207: INFO: n_epochs: 2
2017-11-04 14:25:23,207: INFO: n_hidden: 40
2017-11-04 14:25:23,207: INFO: batch_size: 10
2017-11-04 14:25:23,208: INFO: n_layers: 5
2017-11-04 14:25:23,208: INFO: Normalization: False
2017-11-04 14:25:23,208: INFO: exp_decay_enabled: False
2017-11-04 14:25:23,208: INFO: static_lr_val: 0.050
2017-11-04 14:25:23,208: INFO: Reg Type: Dropout
2017-11-04 14:25:23,208: INFO:   Dropout Prob: 0.50
2017-11-04 14:25:23,208: INFO:   Beta: 0.010

2017-11-04 14:25:29,118: INFO: The training shall begin.
2017-11-04 14:25:42,126: INFO: Epoch: 0, Iter: 0, Loss: 1.094, Accuracy: 0.000, Learning Rate: 0.050
2017-11-04 14:27:39,814: INFO: Epoch: 0, Iter: 100, Loss: 0.048, Accuracy: 1.000, Learning Rate: 0.050
2017-11-04 14:29:41,703: INFO: Epoch: 0, Iter: 200, Loss: 1.665, Accuracy: 0.000, Learning Rate: 0.050
2017-11-04 14:31:40,995: INFO: Epoch: 1, Iter: 300, Loss: 9.401, Accuracy: 0.000, Learning Rate: 0.050
2017-11-04 14:33:37,895: INFO: Epoch: 1, Iter: 400, Loss: 0.787, Accuracy: 0.000, Learning Rate: 0.050
2017-11-04 14:35:39,009: INFO: Epoch: 2, Iter: 500, Loss: 0.006, Accuracy: 1.000, Learning Rate: 0.050
2017-11-04 14:37:36,782: INFO: Epoch: 2, Iter: 600, Loss: 0.458, Accuracy: 1.000, Learning Rate: 0.050
2017-11-04 14:39:36,955: INFO: Epoch: 3, Iter: 700, Loss: 0.613, Accuracy: 1.000, Learning Rate: 0.050
2017-11-04 14:41:40,137: INFO: Epoch: 3, Iter: 800, Loss: 0.385, Accuracy: 1.000, Learning Rate: 0.050
2017-11-04 14:43:52,014: INFO: Epoch: 4, Iter: 900, Loss: 1.767, Accuracy: 0.000, Learning Rate: 0.050
2017-11-04 14:45:42,646: INFO: Keyboard Interrupt? Gracefully quitting
2017-11-04 14:45:42,646: INFO: The training is done.

2017-11-04 14:45:51,960: INFO: *** NEW RUN ***
2017-11-04 14:45:51,961: INFO: filename: trained_model_2017.11.04-14.45.51
2017-11-04 14:45:51,961: INFO: n_epochs: 1
2017-11-04 14:45:51,961: INFO: n_hidden: 40
2017-11-04 14:45:51,961: INFO: batch_size: 10
2017-11-04 14:45:51,962: INFO: n_layers: 5
2017-11-04 14:45:51,962: INFO: Normalization: False
2017-11-04 14:45:51,962: INFO: exp_decay_enabled: False
2017-11-04 14:45:51,962: INFO: static_lr_val: 0.050
2017-11-04 14:45:51,962: INFO: Reg Type: Dropout
2017-11-04 14:45:51,963: INFO:   Dropout Prob: 0.50
2017-11-04 14:45:51,963: INFO:   Beta: 0.010

2017-11-04 14:45:57,875: INFO: The training shall begin.
2017-11-04 14:46:11,412: INFO: Epoch: 0, Iter: 0, Loss: 1.473, Accuracy: 0.000, Learning Rate: 0.050
2017-11-04 14:48:01,706: INFO: Epoch: 0, Iter: 100, Loss: 9.682, Accuracy: 0.000, Learning Rate: 0.050
2017-11-04 14:50:05,637: INFO: Epoch: 0, Iter: 200, Loss: 0.550, Accuracy: 1.000, Learning Rate: 0.050
2017-11-04 14:50:17,189: INFO: The training is done.

2017-11-04 16:24:54,880: INFO: *** NEW RUN ***
2017-11-04 16:24:54,882: INFO: filename: trained_model_2017.11.04-16.24.54
2017-11-04 16:24:54,882: INFO: n_epochs: 1
2017-11-04 16:24:54,882: INFO: n_hidden: 40
2017-11-04 16:24:54,882: INFO: batch_size: 10
2017-11-04 16:24:54,883: INFO: n_layers: 5
2017-11-04 16:24:54,883: INFO: Normalization: False
2017-11-04 16:24:54,883: INFO: exp_decay_enabled: False
2017-11-04 16:24:54,883: INFO: static_lr_val: 0.050
2017-11-04 16:24:54,883: INFO: Reg Type: Dropout
2017-11-04 16:24:54,884: INFO:   Dropout Prob: 0.50
2017-11-04 16:24:54,884: INFO:   Beta: 0.010

2017-11-04 16:25:46,265: INFO: *** NEW RUN ***
2017-11-04 16:25:46,265: INFO: filename: trained_model_2017.11.04-16.25.46
2017-11-04 16:25:46,265: INFO: n_epochs: 1
2017-11-04 16:25:46,265: INFO: n_hidden: 40
2017-11-04 16:25:46,266: INFO: batch_size: 10
2017-11-04 16:25:46,266: INFO: n_layers: 5
2017-11-04 16:25:46,266: INFO: Normalization: False
2017-11-04 16:25:46,266: INFO: exp_decay_enabled: False
2017-11-04 16:25:46,266: INFO: static_lr_val: 0.050
2017-11-04 16:25:46,267: INFO: Reg Type: Dropout
2017-11-04 16:25:46,267: INFO:   Dropout Prob: 0.50
2017-11-04 16:25:46,267: INFO:   Beta: 0.010

2017-11-04 16:25:52,228: INFO: The training shall begin.
2017-11-04 16:25:52,229: INFO: The training is done.

2017-11-04 16:26:30,974: INFO: *** NEW RUN ***
2017-11-04 16:26:30,975: INFO: filename: trained_model_2017.11.04-16.26.30
2017-11-04 16:26:30,975: INFO: n_epochs: 1
2017-11-04 16:26:30,975: INFO: n_hidden: 40
2017-11-04 16:26:30,976: INFO: batch_size: 10
2017-11-04 16:26:30,976: INFO: n_layers: 5
2017-11-04 16:26:30,976: INFO: Normalization: False
2017-11-04 16:26:30,976: INFO: exp_decay_enabled: False
2017-11-04 16:26:30,976: INFO: static_lr_val: 0.050
2017-11-04 16:26:30,976: INFO: Reg Type: Dropout
2017-11-04 16:26:30,977: INFO:   Dropout Prob: 0.50
2017-11-04 16:26:30,977: INFO:   Beta: 0.010

2017-11-04 16:26:37,127: INFO: The training shall begin.
2017-11-04 16:26:37,128: INFO: The training is done.

2017-11-04 16:31:04,532: INFO: *** NEW RUN ***
2017-11-04 16:31:04,532: INFO: filename: trained_model_2017.11.04-16.31.04
2017-11-04 16:31:04,533: INFO: n_epochs: 1
2017-11-04 16:31:04,533: INFO: n_hidden: 40
2017-11-04 16:31:04,533: INFO: batch_size: 10
2017-11-04 16:31:04,533: INFO: n_layers: 5
2017-11-04 16:31:04,533: INFO: Normalization: False
2017-11-04 16:31:04,533: INFO: exp_decay_enabled: False
2017-11-04 16:31:04,534: INFO: static_lr_val: 0.050
2017-11-04 16:31:04,534: INFO: Reg Type: Dropout
2017-11-04 16:31:04,534: INFO:   Dropout Prob: 0.50
2017-11-04 16:31:04,534: INFO:   Beta: 0.010

2017-11-04 16:31:11,069: INFO: The training shall begin.
2017-11-04 16:31:24,831: INFO: Epoch: 0, Iter: 0, Loss: 1.375, Accuracy: 0.000, Learning Rate: 0.050
2017-11-04 16:33:15,054: INFO: Epoch: 0, Iter: 100, Loss: 1.137, Accuracy: 0.000, Learning Rate: 0.050
2017-11-04 16:35:04,753: INFO: Epoch: 0, Iter: 200, Loss: 6.645, Accuracy: 0.000, Learning Rate: 0.050
2017-11-04 16:35:04,754: INFO: The training is done.

2017-11-04 16:42:34,696: INFO: *** NEW RUN ***
2017-11-04 16:42:34,697: INFO: filename: trained_model_2017.11.04-16.42.34
2017-11-04 16:42:34,697: INFO: n_epochs: 1
2017-11-04 16:42:34,698: INFO: n_hidden: 40
2017-11-04 16:42:34,698: INFO: batch_size: 10
2017-11-04 16:42:34,698: INFO: n_layers: 5
2017-11-04 16:42:34,698: INFO: Normalization: False
2017-11-04 16:42:34,698: INFO: exp_decay_enabled: False
2017-11-04 16:42:34,699: INFO: static_lr_val: 0.050
2017-11-04 16:42:34,699: INFO: Reg Type: Dropout
2017-11-04 16:42:34,699: INFO:   Dropout Prob: 0.50
2017-11-04 16:42:34,699: INFO:   Beta: 0.010

2017-11-04 16:42:40,895: INFO: The training shall begin.
2017-11-04 16:42:54,647: INFO: Epoch: 0, Iter: 0, Loss: 0.823, Accuracy: 1.000, Learning Rate: 0.050
2017-11-04 16:44:56,681: INFO: Epoch: 0, Iter: 100, Loss: 12.372, Accuracy: 0.000, Learning Rate: 0.050
2017-11-04 16:46:53,452: INFO: Epoch: 0, Iter: 200, Loss: 7.923, Accuracy: 0.000, Learning Rate: 0.050
2017-11-04 16:47:04,327: INFO: The training is done.

2017-11-04 16:56:29,939: INFO: *** NEW RUN ***
2017-11-04 16:56:29,941: INFO: filename: trained_model_2017.11.04-16.56.29
2017-11-04 16:56:29,941: INFO: n_epochs: 1
2017-11-04 16:56:29,941: INFO: n_hidden: 40
2017-11-04 16:56:29,941: INFO: batch_size: 10
2017-11-04 16:56:29,942: INFO: n_layers: 5
2017-11-04 16:56:29,942: INFO: Normalization: False
2017-11-04 16:56:29,942: INFO: exp_decay_enabled: False
2017-11-04 16:56:29,942: INFO: static_lr_val: 0.050
2017-11-04 16:56:29,942: INFO: Reg Type: Dropout
2017-11-04 16:56:29,943: INFO:   Dropout Prob: 0.50
2017-11-04 16:56:29,943: INFO:   Beta: 0.010

2017-11-04 16:56:36,109: INFO: The training shall begin.
2017-11-04 16:56:49,567: INFO: Epoch: 0, Iter: 0, Loss: 1.672, Accuracy: 0.000, Learning Rate: 0.050
2017-11-04 17:00:35,944: INFO: Epoch: 1, Iter: 210, Loss: 2.658, Accuracy: 0.000, Learning Rate: 0.050
2017-11-04 17:00:35,949: INFO: The training is done.

2017-11-04 17:06:37,835: INFO: *** NEW RUN ***
2017-11-04 17:06:37,835: INFO: filename: trained_model_2017.11.04-17.06.37
2017-11-04 17:06:37,835: INFO: n_epochs: 2
2017-11-04 17:06:37,836: INFO: n_hidden: 40
2017-11-04 17:06:37,836: INFO: batch_size: 10
2017-11-04 17:06:37,836: INFO: n_layers: 5
2017-11-04 17:06:37,836: INFO: Normalization: False
2017-11-04 17:06:37,836: INFO: exp_decay_enabled: False
2017-11-04 17:06:37,837: INFO: static_lr_val: 0.050
2017-11-04 17:06:37,837: INFO: Reg Type: Dropout
2017-11-04 17:06:37,837: INFO:   Dropout Prob: 0.50
2017-11-04 17:06:37,837: INFO:   Beta: 0.010

2017-11-04 17:06:44,070: INFO: The training shall begin.
2017-11-04 17:06:57,419: INFO: Epoch: 0, Iter: 0, Loss: 0.931, Accuracy: 1.000, Learning Rate: 0.050
2017-11-04 17:07:08,319: INFO: Keyboard Interrupt? Gracefully quitting
2017-11-04 17:07:08,320: INFO: The training is done.

2017-11-04 17:11:52,521: INFO: *** NEW RUN ***
2017-11-04 17:11:52,522: INFO: filename: trained_model_2017.11.04-17.11.52
2017-11-04 17:11:52,522: INFO: n_epochs: 2
2017-11-04 17:11:52,522: INFO: n_hidden: 40
2017-11-04 17:11:52,522: INFO: batch_size: 10
2017-11-04 17:11:52,522: INFO: n_layers: 5
2017-11-04 17:11:52,523: INFO: Normalization: False
2017-11-04 17:11:52,523: INFO: exp_decay_enabled: False
2017-11-04 17:11:52,523: INFO: static_lr_val: 0.050
2017-11-04 17:11:52,523: INFO: Reg Type: Dropout
2017-11-04 17:11:52,523: INFO:   Dropout Prob: 0.50
2017-11-04 17:11:52,523: INFO:   Beta: 0.010

2017-11-04 17:11:58,633: INFO: The training shall begin.
2017-11-04 17:12:12,162: INFO: Epoch: 0, Loss: 0.441, Accuracy: 1.000, Learning Rate: 0.050
2017-11-04 17:16:06,369: INFO: Epoch: 1, Loss: 0.042, Accuracy: 1.000, Learning Rate: 0.050
2017-11-04 17:19:56,274: INFO: Epoch: 2, Loss: 2.013, Accuracy: 0.000, Learning Rate: 0.050
2017-11-04 17:20:07,059: INFO: The training is done.

2017-11-04 17:38:17,365: INFO: *** NEW RUN ***
2017-11-04 17:38:17,366: INFO: filename: trained_model_2017.11.04-17.38.17
2017-11-04 17:38:17,366: INFO: n_epochs: 2
2017-11-04 17:38:17,366: INFO: n_hidden: 40
2017-11-04 17:38:17,366: INFO: batch_size: 10
2017-11-04 17:38:17,367: INFO: n_layers: 5
2017-11-04 17:38:17,367: INFO: Normalization: False
2017-11-04 17:38:17,367: INFO: exp_decay_enabled: False
2017-11-04 17:38:17,367: INFO: static_lr_val: 0.050
2017-11-04 17:38:17,367: INFO: Reg Type: Dropout
2017-11-04 17:38:17,367: INFO:   Dropout Prob: 0.50
2017-11-04 17:38:17,368: INFO:   Beta: 0.010

2017-11-04 17:38:25,168: INFO: The training shall begin.
2017-11-04 17:38:40,299: INFO: Epoch: 0, Loss: 1.789, Accuracy: 0.000, Learning Rate: 0.050
2017-11-04 17:42:31,938: INFO: Epoch: 1, Loss: 0.006, Accuracy: 1.000, Learning Rate: 0.050
2017-11-04 17:47:00,153: INFO: Epoch: 2, Loss: 0.124, Accuracy: 1.000, Learning Rate: 0.050
2017-11-04 17:47:13,151: INFO: The training is done.

2017-11-05 17:18:52,177: INFO: *** NEW RUN ***
2017-11-05 17:18:52,179: INFO: filename: trained_model_2017.11.05-17.18.51
2017-11-05 17:18:52,179: INFO: n_epochs: 2
2017-11-05 17:18:52,179: INFO: n_hidden: 40
2017-11-05 17:18:52,179: INFO: batch_size: 10
2017-11-05 17:18:52,180: INFO: n_layers: 5
2017-11-05 17:18:52,180: INFO: Normalization: False
2017-11-05 17:18:52,180: INFO: exp_decay_enabled: False
2017-11-05 17:18:52,180: INFO: static_lr_val: 0.050
2017-11-05 17:18:52,180: INFO: Reg Type: Dropout
2017-11-05 17:18:52,180: INFO:   Dropout Prob: 0.50
2017-11-05 17:18:52,181: INFO:   Beta: 0.010

2017-11-05 17:18:58,839: INFO: The training shall begin.
2017-11-05 17:19:14,956: INFO: Epoch: 0, Loss: 1.599, Accuracy: 0.300, Learning Rate: 0.050
2017-11-05 17:24:16,825: INFO: Epoch: 1, Loss: 1.267, Accuracy: 0.500, Learning Rate: 0.050
2017-11-05 17:28:50,919: INFO: Cycled through epochs 2 times
2017-11-05 17:28:50,921: INFO: The training is done.

2017-11-05 17:39:00,205: INFO: *** NEW RUN ***
2017-11-05 17:39:00,206: INFO: filename: trained_model_2017.11.05-17.38.59
2017-11-05 17:39:00,207: INFO: n_epochs: 20
2017-11-05 17:39:00,208: INFO: n_hidden: 40
2017-11-05 17:39:00,208: INFO: batch_size: 10
2017-11-05 17:39:00,209: INFO: n_layers: 5
2017-11-05 17:39:00,209: INFO: Normalization: False
2017-11-05 17:39:00,209: INFO: exp_decay_enabled: False
2017-11-05 17:39:00,209: INFO: static_lr_val: 0.050
2017-11-05 17:39:00,209: INFO: Reg Type: Dropout
2017-11-05 17:39:00,209: INFO:   Dropout Prob: 0.50
2017-11-05 17:39:00,210: INFO:   Beta: 0.010

2017-11-05 17:39:07,384: INFO: The training shall begin.
2017-11-05 17:39:24,652: INFO: Epoch: 0, Loss: 1.099, Accuracy: 0.300, Learning Rate: 0.050
2017-11-05 17:44:15,500: INFO: Epoch: 1, Loss: 1.488, Accuracy: 0.400, Learning Rate: 0.050
2017-11-05 17:49:14,050: INFO: Epoch: 2, Loss: 1.085, Accuracy: 0.400, Learning Rate: 0.050
2017-11-05 17:53:59,200: INFO: Epoch: 3, Loss: 0.979, Accuracy: 0.600, Learning Rate: 0.050
2017-11-05 17:58:40,058: INFO: Epoch: 4, Loss: 1.010, Accuracy: 0.500, Learning Rate: 0.050
2017-11-05 18:01:29,220: INFO: Keyboard Interrupt? Gracefully quitting
2017-11-05 18:01:29,222: INFO: The training is done.

2017-11-05 18:56:25,167: INFO: *** NEW RUN ***
2017-11-05 18:56:25,170: INFO: filename: trained_model_2017.11.05-18.56.24
2017-11-05 18:56:25,170: INFO: n_epochs: 20
2017-11-05 18:56:25,170: INFO: n_hidden: 40
2017-11-05 18:56:25,171: INFO: batch_size: 10
2017-11-05 18:56:25,171: INFO: n_layers: 5
2017-11-05 18:56:25,171: INFO: Normalization: False
2017-11-05 18:56:25,171: INFO: exp_decay_enabled: False
2017-11-05 18:56:25,172: INFO: static_lr_val: 0.050
2017-11-05 18:56:25,172: INFO: Reg Type: Dropout
2017-11-05 18:56:25,172: INFO:   Dropout Prob: 0.50
2017-11-05 18:56:25,172: INFO:   Beta: 0.010

2017-11-05 21:01:19,376: INFO: *** NEW RUN ***
2017-11-05 21:01:19,379: INFO: filename: trained_model_2017.11.05-21.01.18
2017-11-05 21:01:19,380: INFO: n_epochs: 20
2017-11-05 21:01:19,380: INFO: n_hidden: 40
2017-11-05 21:01:19,380: INFO: batch_size: 10
2017-11-05 21:01:19,381: INFO: n_layers: 5
2017-11-05 21:01:19,381: INFO: Normalization: False
2017-11-05 21:01:19,381: INFO: exp_decay_enabled: False
2017-11-05 21:01:19,381: INFO: static_lr_val: 0.050
2017-11-05 21:01:19,381: INFO: Reg Type: Dropout
2017-11-05 21:01:19,381: INFO:   Dropout Prob: 0.50
2017-11-05 21:01:19,382: INFO:   Beta: 0.010

2017-11-05 21:01:24,207: INFO: Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled
	 [[Node: Input_Batch/input_producer/input_producer_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_STRING], timeout_ms=-1, _device="/job:localhost/replica:0/task:0/cpu:0"](Input_Batch/input_producer, Input_Batch/input_producer/limit_epochs)]]
